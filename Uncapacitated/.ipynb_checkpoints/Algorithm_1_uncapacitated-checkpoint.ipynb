{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64752e1-d39a-4f4a-aca6-337d221779f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Algorithm 1 (Semi Cross‐Validation) Results ===\n",
      "                              Method  Precision (%)  Cost  Recall (%)  \\\n",
      "0                 Constant Threshold      76.923077   276   95.238095   \n",
      "1                Dynamic Threshold-R      17.500000   990  100.000000   \n",
      "2                   Linear Threshold     100.000000   204  100.000000   \n",
      "3                      Wait Till End     100.000000   399  100.000000   \n",
      "4  Dynamic Threshold-DP (DataDriven)     100.000000   141  100.000000   \n",
      "\n",
      "   Treatment Time  \n",
      "0        6.384615  \n",
      "1        0.000000  \n",
      "2        9.714286  \n",
      "3       19.000000  \n",
      "4        6.714286  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "###############################################################################\n",
    "# 1. GLOBAL PARAMETERS\n",
    "###############################################################################\n",
    "FP_COST = 10\n",
    "FN_COST = 50\n",
    "D_COST  = 1\n",
    "GAMMA   = 0.99\n",
    "T_MAX   = 20  \n",
    "\n",
    "###############################################################################\n",
    "# 2. HELPER FUNCTIONS: splitting, simulation, etc.\n",
    "###############################################################################\n",
    "def make_folds(df, n_folds=5, seed=0):\n",
    "    \"\"\"\n",
    "    Algorithm 1 requires dividing the dataset into n_folds folds.\n",
    "    Here, we do n_folds TOTALLY, meaning the last fold is \"test set\"\n",
    "    and the first (n_folds-1) folds do the cross-validation.\n",
    "    Example: n_folds=5 => G1, G2, G3, G4, G5\n",
    "        - We'll treat G1..G4 for the semi cross-val,\n",
    "        - G5 is final test set.\n",
    "    Adjust as you wish.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    # We'll shuffle patient IDs, then chunk them into n_folds groups\n",
    "    unique_pts = df['patient_id'].unique()\n",
    "    rng.shuffle(unique_pts)\n",
    "    \n",
    "    folds = []\n",
    "    fold_size = int(np.ceil(len(unique_pts) / n_folds))\n",
    "    \n",
    "    start_idx = 0\n",
    "    for k in range(n_folds):\n",
    "        end_idx = min(start_idx + fold_size, len(unique_pts))\n",
    "        fold_pids = unique_pts[start_idx:end_idx]\n",
    "        folds.append(set(fold_pids))\n",
    "        start_idx = end_idx\n",
    "    \n",
    "    # If n_folds is large or does not divide the data exactly, \n",
    "    # the last fold might be smaller or empty; adapt as needed.\n",
    "    return folds\n",
    "\n",
    "def filter_by_group(df, pid_set):\n",
    "    return df[df['patient_id'].isin(pid_set)].copy()\n",
    "\n",
    "def simulate_policy(df, policy_func):\n",
    "    \"\"\"\n",
    "    Same as the previous examples:\n",
    "      - policy_func(patient_rows) -> treat_time in [0..T_MAX-1] or None\n",
    "    Returns cost, precision, recall, avg_treatment_time\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for pid, patient_rows in df.groupby('patient_id'):\n",
    "        patient_rows = patient_rows.sort_values('time')\n",
    "        \n",
    "        label = patient_rows['label'].iloc[0]  # 0 or 1\n",
    "        treat_time = policy_func(patient_rows)\n",
    "        \n",
    "        if treat_time is None:\n",
    "            # never treated\n",
    "            treated_flag = 0\n",
    "            if label == 1:\n",
    "                cost = FN_COST\n",
    "            else:\n",
    "                cost = 0\n",
    "            tp = 0\n",
    "            fp = 0\n",
    "            tt = None\n",
    "        else:\n",
    "            treated_flag = 1\n",
    "            if label == 1:\n",
    "                cost = D_COST * treat_time\n",
    "                tp = 1\n",
    "                fp = 0\n",
    "            else:\n",
    "                cost = FP_COST\n",
    "                tp = 0\n",
    "                fp = 1\n",
    "            tt = treat_time\n",
    "        \n",
    "        results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': treated_flag,\n",
    "            'treat_time': tt,\n",
    "            'cost': cost,\n",
    "            'tp': tp,\n",
    "            'fp': fp\n",
    "        })\n",
    "    \n",
    "    df_res = pd.DataFrame(results)\n",
    "    total_cost = df_res['cost'].sum()\n",
    "    \n",
    "    treated_df = df_res[df_res['treated'] == 1]\n",
    "    tp_sum = treated_df['tp'].sum()\n",
    "    fp_sum = treated_df['fp'].sum()\n",
    "    if len(treated_df) > 0:\n",
    "        precision = tp_sum / (tp_sum + fp_sum)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "    \n",
    "    sick_df = df_res[df_res['label'] == 1]\n",
    "    total_sick = len(sick_df)\n",
    "    if total_sick > 0:\n",
    "        recall = tp_sum / total_sick\n",
    "    else:\n",
    "        recall = 0.0\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        valid_tt = treated_df['treat_time'].dropna()\n",
    "        avg_tt = valid_tt.mean() if len(valid_tt) > 0 else 0.0\n",
    "    else:\n",
    "        avg_tt = 0.0\n",
    "    \n",
    "    return {\n",
    "        'cost': total_cost,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'avg_treatment_time': avg_tt\n",
    "    }\n",
    "\n",
    "###############################################################################\n",
    "# 3. BENCHMARK POLICIES\n",
    "###############################################################################\n",
    "def constant_threshold_search(df, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0, 1, 21)\n",
    "    best_thr, best_cost, best_stats = None, float('inf'), None\n",
    "    \n",
    "    for thr in thresholds:\n",
    "        def policy_func(patient_rows):\n",
    "            for _, row in patient_rows.iterrows():\n",
    "                if row['risk_score'] >= thr:\n",
    "                    return int(row['time'])\n",
    "            return None\n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_thr = thr\n",
    "            best_stats = stats\n",
    "    \n",
    "    return best_thr, best_stats\n",
    "\n",
    "def make_constant_threshold_policy(thr):\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            if row['risk_score'] >= thr:\n",
    "                return int(row['time'])\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def dynamic_threshold_random_search(df,\n",
    "                                    time_steps=20,\n",
    "                                    threshold_candidates=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "                                    n_samples=200,\n",
    "                                    seed=0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    best_vec = None\n",
    "    best_cost = float('inf')\n",
    "    best_stats = None\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        thr_vec = rng.choice(threshold_candidates, size=time_steps)\n",
    "        \n",
    "        def policy_func(patient_rows):\n",
    "            for _, row in patient_rows.iterrows():\n",
    "                t = int(row['time'])\n",
    "                if t < time_steps and row['risk_score'] >= thr_vec[t]:\n",
    "                    return t\n",
    "            return None\n",
    "        \n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_vec = thr_vec.copy()\n",
    "            best_stats = stats\n",
    "    \n",
    "    return best_vec, best_stats\n",
    "\n",
    "def make_dynamic_threshold_policy(thr_vec):\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = int(row['time'])\n",
    "            if t < len(thr_vec):\n",
    "                if row['risk_score'] >= thr_vec[t]:\n",
    "                    return t\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def linear_threshold_search(df, A_candidates=None, B_candidates=None):\n",
    "    if A_candidates is None:\n",
    "        A_candidates = np.linspace(-0.05, 0.05, 11)\n",
    "    if B_candidates is None:\n",
    "        B_candidates = np.linspace(0, 1, 11)\n",
    "    best_A, best_B = None, None\n",
    "    best_cost, best_stats = float('inf'), None\n",
    "    \n",
    "    for A in A_candidates:\n",
    "        for B in B_candidates:\n",
    "            def policy_func(patient_rows):\n",
    "                for _, row in patient_rows.iterrows():\n",
    "                    t = row['time']\n",
    "                    thr = A * t + B\n",
    "                    thr = max(0, min(1, thr))\n",
    "                    if row['risk_score'] >= thr:\n",
    "                        return int(t)\n",
    "                return None\n",
    "            \n",
    "            stats = simulate_policy(df, policy_func)\n",
    "            if stats['cost'] < best_cost:\n",
    "                best_cost = stats['cost']\n",
    "                best_A = A\n",
    "                best_B = B\n",
    "                best_stats = stats\n",
    "    \n",
    "    return (best_A, best_B), best_stats\n",
    "\n",
    "def make_linear_threshold_policy(A, B):\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = row['time']\n",
    "            thr = A*t + B\n",
    "            thr = max(0, min(1, thr))\n",
    "            if row['risk_score'] >= thr:\n",
    "                return int(t)\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def wait_till_end_search(df, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0,1,21)\n",
    "    best_thr, best_cost, best_stats = None, float('inf'), None\n",
    "    \n",
    "    for thr in thresholds:\n",
    "        def policy_func(patient_rows):\n",
    "            final_row = patient_rows.loc[patient_rows['time'].idxmax()]\n",
    "            if final_row['risk_score'] >= thr:\n",
    "                return int(final_row['time'])\n",
    "            return None\n",
    "        \n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_thr = thr\n",
    "            best_stats = stats\n",
    "    \n",
    "    return best_thr, best_stats\n",
    "\n",
    "def make_wait_till_end_policy(thr):\n",
    "    def policy_func(patient_rows):\n",
    "        final_row = patient_rows.loc[patient_rows['time'].idxmax()]\n",
    "        if final_row['risk_score'] >= thr:\n",
    "            return int(final_row['time'])\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "###############################################################################\n",
    "# 4. DATA-DRIVEN DP (Unconstrained) Example\n",
    "###############################################################################\n",
    "def estimate_transition_and_sick_probs(df_train, T=20, n_buckets=5):\n",
    "    \"\"\"\n",
    "    We'll do a simple approach:\n",
    "      p_sick[t,b] = fraction of df_train rows that have (time=t, bucket=b) AND label=1\n",
    "      p_trans[t,b,b'] = fraction of patients at (t,b) who go to (t+1,b') ...\n",
    "    (But for the unconstrained scenario, we might also just do a simpler policy.)\n",
    "    \"\"\"\n",
    "    transition_counts = np.zeros((T-1, n_buckets, n_buckets), dtype=float)\n",
    "    bucket_counts     = np.zeros((T, n_buckets), dtype=float)\n",
    "    sick_counts       = np.zeros((T, n_buckets), dtype=float)\n",
    "\n",
    "    df_sorted = df_train.sort_values(['patient_id','time'])\n",
    "    \n",
    "    for pid, grp in df_sorted.groupby('patient_id'):\n",
    "        grp = grp.sort_values('time')\n",
    "        rows = grp.to_dict('records')\n",
    "        \n",
    "        for i in range(len(rows)):\n",
    "            t  = int(rows[i]['time'])\n",
    "            b  = int(rows[i]['risk_bucket'])\n",
    "            lb = int(rows[i]['label'])  # 0 or 1\n",
    "            if t < T:\n",
    "                bucket_counts[t, b] += 1\n",
    "                sick_counts[t, b]   += lb\n",
    "            \n",
    "            if i < len(rows) - 1:\n",
    "                t_next = int(rows[i+1]['time'])\n",
    "                b_next = int(rows[i+1]['risk_bucket'])\n",
    "                if t_next == t+1 and t < T-1:\n",
    "                    transition_counts[t, b, b_next] += 1.0\n",
    "\n",
    "    # Prob of transitions\n",
    "    p_trans = np.zeros((T-1, n_buckets, n_buckets), dtype=float)\n",
    "    for t_ in range(T-1):\n",
    "        for b_ in range(n_buckets):\n",
    "            denom = transition_counts[t_, b_, :].sum()\n",
    "            if denom > 0:\n",
    "                p_trans[t_, b_, :] = transition_counts[t_, b_, :] / denom\n",
    "            else:\n",
    "                p_trans[t_, b_, b_] = 1.0  # default identity\n",
    "\n",
    "    # Probability of sick in (t,b)\n",
    "    p_sick = np.zeros((T, n_buckets), dtype=float)\n",
    "    for t_ in range(T):\n",
    "        for b_ in range(n_buckets):\n",
    "            denom = bucket_counts[t_, b_]\n",
    "            if denom > 0:\n",
    "                p_sick[t_, b_] = sick_counts[t_, b_] / denom\n",
    "            else:\n",
    "                p_sick[t_, b_] = 0.0\n",
    "    return p_trans, p_sick\n",
    "\n",
    "def train_data_driven_dp_unconstrained(p_trans, p_sick, \n",
    "                                       FP=10, FN=50, D=1, gamma=0.99, T=20):\n",
    "    \"\"\"\n",
    "    Similar to the code shown previously for an *expected-cost DP* \n",
    "    but focusing on \"treat vs. wait\" in state (t,bucket).\n",
    "    We do a single chain for all patients => only p_sick used.\n",
    "    \"\"\"\n",
    "    n_buckets = p_sick.shape[1]\n",
    "    V = np.zeros((T+1, n_buckets))\n",
    "    pi_ = np.zeros((T, n_buckets), dtype=int)\n",
    "    \n",
    "    # boundary at t=T\n",
    "    for b in range(n_buckets):\n",
    "        cost_treat  = p_sick[T-1,b]*(D*(T-1)) + (1-p_sick[T-1,b])*FP\n",
    "        cost_notreat= p_sick[T-1,b]*FN\n",
    "        V[T,b] = min(cost_treat, cost_notreat)\n",
    "    \n",
    "    for t in reversed(range(T)):\n",
    "        for b in range(n_buckets):\n",
    "            cost_treat = p_sick[t,b]*(D*t) + (1-p_sick[t,b])*FP\n",
    "            # cost_wait\n",
    "            if t == T-1:\n",
    "                # next step is T => no transitions => V[T,b]\n",
    "                exp_future = V[T,b]\n",
    "            else:\n",
    "                exp_future = 0.0\n",
    "                for b_next in range(n_buckets):\n",
    "                    exp_future += p_trans[t,b,b_next]*V[t+1,b_next]\n",
    "            cost_wait = gamma * exp_future\n",
    "            \n",
    "            if cost_treat <= cost_wait:\n",
    "                V[t,b] = cost_treat\n",
    "                pi_[t,b] = 1\n",
    "            else:\n",
    "                V[t,b] = cost_wait\n",
    "                pi_[t,b] = 0\n",
    "    return V, pi_\n",
    "\n",
    "def make_data_driven_dp_policy_unconstrained(V, pi_, T=20):\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = int(row['time'])\n",
    "            b = int(row['risk_bucket'])\n",
    "            if t < T:\n",
    "                if pi_[t,b] == 1:\n",
    "                    return t\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 5. ALGORITHM 1: SEMI CROSS-VALIDATION\n",
    "###############################################################################\n",
    "def semi_crossval_unconstrained(df_all, n_folds=5, seed=0):\n",
    "    r\"\"\"\n",
    "    This implements the \"Algorithm 1\" idea for the unconstrained scenario.\n",
    "\n",
    "    Steps:\n",
    "     1) Partition df_all into n_folds folds: G1..G_{n_folds}.\n",
    "     2) Let G_{n_folds} = final test set.\n",
    "     3) For each j in [0..(n_folds-2)] (the \"CV folds\"):\n",
    "         - Validation set = G_j\n",
    "         - Training set = union of G_k for k != j\n",
    "           => pick best hyperparams for benchmark (like constant threshold, etc.)\n",
    "           => pick best hyperparams for DP\n",
    "       We store the best hyperparams from each fold j.\n",
    "     4) Combine or choose a final hyperparam set from these folds.\n",
    "     5) Evaluate on the final fold G_{n_folds}.\n",
    "    \"\"\"\n",
    "    # 1) Create folds\n",
    "    folds = make_folds(df_all, n_folds=n_folds, seed=seed)\n",
    "    # folds[0], folds[1], ..., folds[n_folds-1]\n",
    "    \n",
    "    # We'll treat folds[n_folds-1] as G_{n_folds} (the final test).\n",
    "    test_fold_pid = folds[-1]\n",
    "    \n",
    "    # The first (n_folds-1) folds are used for the cross-validation.\n",
    "    cv_folds = folds[:-1]\n",
    "    \n",
    "    # We'll collect best hyperparams for each fold j in [0..n_folds-2].\n",
    "    best_thr_const_list = []\n",
    "    best_dyn_vec_list   = []\n",
    "    best_linAB_list     = []\n",
    "    best_thr_wait_list  = []\n",
    "   \n",
    "    \n",
    "    for j in range(len(cv_folds)):\n",
    "        # Validation fold = j\n",
    "        val_pid = cv_folds[j]\n",
    "        # Training = union of all other folds except j\n",
    "        train_pid = set()\n",
    "        for k in range(len(cv_folds)):\n",
    "            if k != j:\n",
    "                train_pid = train_pid.union(cv_folds[k])\n",
    "        \n",
    "        df_train = filter_by_group(df_all, train_pid)\n",
    "        df_val   = filter_by_group(df_all, val_pid)\n",
    "        \n",
    "        # 1) Constant threshold\n",
    "        thr_c, _ = constant_threshold_search(df_train)\n",
    "        \n",
    "        best_thr_const_list.append(thr_c)\n",
    "        \n",
    "        # 2) Dynamic threshold\n",
    "        thr_vec, _ = dynamic_threshold_random_search(\n",
    "            df_train, \n",
    "            time_steps=T_MAX,\n",
    "            threshold_candidates=[0,0.2,0.4,0.6,0.8,1.0],\n",
    "            n_samples=200,\n",
    "            seed=j\n",
    "        )\n",
    "        best_dyn_vec_list.append(thr_vec)\n",
    "        \n",
    "        # 3) Linear threshold\n",
    "        (A,B), _ = linear_threshold_search(df_train)\n",
    "        best_linAB_list.append((A,B))\n",
    "        \n",
    "        # 4) Wait till end\n",
    "        thr_wte, _ = wait_till_end_search(df_train)\n",
    "        best_thr_wait_list.append(thr_wte)\n",
    "        \n",
    "    \n",
    "    \n",
    "    # constant threshold average:\n",
    "    thr_const_final = np.mean(best_thr_const_list)\n",
    "    \n",
    "    # dynamic threshold => pick the \"middle\" fold's threshold\n",
    "    mid_idx = len(best_dyn_vec_list)//2\n",
    "    thr_dyn_final = best_dyn_vec_list[mid_idx]\n",
    "    \n",
    "    # linear threshold => average (A, B)\n",
    "    A_ave = np.mean([ab[0] for ab in best_linAB_list])\n",
    "    B_ave = np.mean([ab[1] for ab in best_linAB_list])\n",
    "    \n",
    "    thr_wait_final = np.mean(best_thr_wait_list)\n",
    "    \n",
    "    train_pid_all = set()\n",
    "    for j in range(len(cv_folds)):\n",
    "        train_pid_all = train_pid_all.union(cv_folds[j])\n",
    "    df_train_cv = filter_by_group(df_all, train_pid_all)\n",
    "    \n",
    "    p_trans, p_sick = estimate_transition_and_sick_probs(\n",
    "        df_train_cv, T=T_MAX, n_buckets=5\n",
    "    )\n",
    "    V, pi_ = train_data_driven_dp_unconstrained(\n",
    "        p_trans, p_sick, FP=FP_COST, FN=FN_COST, D=D_COST, gamma=GAMMA, T=T_MAX\n",
    "    )\n",
    "    dp_policy_func = make_data_driven_dp_policy_unconstrained(V, pi_, T=T_MAX)\n",
    "    \n",
    "    # Now evaluate everything on final test fold folds[-1].\n",
    "    df_test = filter_by_group(df_all, test_fold_pid)\n",
    "    \n",
    "    # Build final policies\n",
    "    const_policy = make_constant_threshold_policy(thr_const_final)\n",
    "    dyn_policy   = make_dynamic_threshold_policy(thr_dyn_final)\n",
    "    lin_policy   = make_linear_threshold_policy(A_ave, B_ave)\n",
    "    wte_policy   = make_wait_till_end_policy(thr_wait_final)\n",
    "    \n",
    "    stats_const_test = simulate_policy(df_test, const_policy)\n",
    "    stats_dyn_test   = simulate_policy(df_test, dyn_policy)\n",
    "    stats_lin_test   = simulate_policy(df_test, lin_policy)\n",
    "    stats_wte_test   = simulate_policy(df_test, wte_policy)\n",
    "    stats_dp_test    = simulate_policy(df_test, dp_policy_func)\n",
    "    \n",
    "    # Summarize\n",
    "    table = pd.DataFrame({\n",
    "        'Method': [\n",
    "            'Constant Threshold',\n",
    "            'Dynamic Threshold-R',\n",
    "            'Linear Threshold',\n",
    "            'Wait Till End',\n",
    "            'Dynamic Threshold-DP (DataDriven)'\n",
    "        ],\n",
    "        'Precision (%)': [\n",
    "            100*stats_const_test['precision'],\n",
    "            100*stats_dyn_test['precision'],\n",
    "            100*stats_lin_test['precision'],\n",
    "            100*stats_wte_test['precision'],\n",
    "            100*stats_dp_test['precision'],\n",
    "        ],\n",
    "        'Cost': [\n",
    "            stats_const_test['cost'],\n",
    "            stats_dyn_test['cost'],\n",
    "            stats_lin_test['cost'],\n",
    "            stats_wte_test['cost'],\n",
    "            stats_dp_test['cost'],\n",
    "        ],\n",
    "        'Recall (%)': [\n",
    "            100*stats_const_test['recall'],\n",
    "            100*stats_dyn_test['recall'],\n",
    "            100*stats_lin_test['recall'],\n",
    "            100*stats_wte_test['recall'],\n",
    "            100*stats_dp_test['recall'],\n",
    "        ],\n",
    "        'Treatment Time': [\n",
    "            stats_const_test['avg_treatment_time'],\n",
    "            stats_dyn_test['avg_treatment_time'],\n",
    "            stats_lin_test['avg_treatment_time'],\n",
    "            stats_wte_test['avg_treatment_time'],\n",
    "            stats_dp_test['avg_treatment_time'],\n",
    "        ]\n",
    "    })\n",
    "    return table\n",
    "\n",
    "###############################################################################\n",
    "# 6. MAIN: read CSV, run Algorithm 1\n",
    "###############################################################################\n",
    "def main():\n",
    "    df_all = pd.read_csv(\"synthetic_patients_with_features.csv\")\n",
    "    df_all = df_all[df_all['time'] < T_MAX].copy()\n",
    "    \n",
    "    n_folds = 5\n",
    "    \n",
    "    result_table = semi_crossval_unconstrained(df_all, n_folds=n_folds, seed=42)\n",
    "    \n",
    "    print(\"\\n=== Algorithm 1 (Semi Cross‐Validation) Results ===\")\n",
    "    print(result_table)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3624f2a0-0dcd-499d-a4fd-367105d4a8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Replication 1/30...\n",
      "Running Replication 2/30...\n",
      "Running Replication 3/30...\n",
      "Running Replication 4/30...\n",
      "Running Replication 5/30...\n",
      "Running Replication 6/30...\n",
      "Running Replication 7/30...\n",
      "Running Replication 8/30...\n",
      "Running Replication 9/30...\n",
      "Running Replication 10/30...\n",
      "Running Replication 11/30...\n",
      "Running Replication 12/30...\n",
      "Running Replication 13/30...\n",
      "Running Replication 14/30...\n",
      "Running Replication 15/30...\n",
      "Running Replication 16/30...\n",
      "Running Replication 17/30...\n",
      "Running Replication 18/30...\n",
      "Running Replication 19/30...\n",
      "Running Replication 20/30...\n",
      "Running Replication 21/30...\n",
      "Running Replication 22/30...\n",
      "Running Replication 23/30...\n",
      "Running Replication 24/30...\n",
      "Running Replication 25/30...\n",
      "Running Replication 26/30...\n",
      "Running Replication 27/30...\n",
      "Running Replication 28/30...\n",
      "Running Replication 29/30...\n",
      "Running Replication 30/30...\n",
      "\n",
      "=== Algorithm 1 (Semi Cross-Validation) Results (Mean ± Std Dev over 30 Replications) ===\n",
      "                 Method  Precision (%)            Cost     Recall (%)  \\\n",
      "0    Constant Threshold   71.73 ± 6.04  384.40 ± 56.87   96.20 ± 0.02   \n",
      "1   Dynamic Threshold-R   21.03 ± 3.05  958.20 ± 38.10  100.00 ± 0.00   \n",
      "2      Linear Threshold  100.00 ± 0.00  267.77 ± 40.63  100.00 ± 0.00   \n",
      "3         Wait Till End  100.00 ± 0.00  476.90 ± 67.68  100.00 ± 0.00   \n",
      "4  Dynamic Threshold-DP  100.00 ± 0.00  205.17 ± 34.49  100.00 ± 0.00   \n",
      "\n",
      "  Treatment Time  \n",
      "0    7.18 ± 1.03  \n",
      "1    0.45 ± 0.96  \n",
      "2   10.67 ± 0.49  \n",
      "3   19.00 ± 0.00  \n",
      "4    8.16 ± 0.58  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "###############################################################################\n",
    "# 1. GLOBAL PARAMETERS\n",
    "###############################################################################\n",
    "FP_COST = 10\n",
    "FN_COST = 50\n",
    "D_COST  = 1\n",
    "GAMMA   = 0.99\n",
    "T_MAX   = 20\n",
    "\n",
    "###############################################################################\n",
    "# 2. HELPER FUNCTIONS: splitting, simulation, etc.\n",
    "###############################################################################\n",
    "def make_folds(df, n_folds=5, seed=0):\n",
    "    \"\"\"\n",
    "    Algorithm 1 requires dividing the dataset into n_folds folds.\n",
    "    Here, we do n_folds TOTALLY, meaning the last fold is \"test set\"\n",
    "    and the first (n_folds-1) folds do the cross-validation.\n",
    "    Example: n_folds=5 => G1, G2, G3, G4, G5\n",
    "        - We'll treat G1..G4 for the semi cross-val,\n",
    "        - G5 is final test set.\n",
    "    Adjust as you wish.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    # We'll shuffle patient IDs, then chunk them into n_folds groups\n",
    "    unique_pts = df['patient_id'].unique()\n",
    "    rng.shuffle(unique_pts)\n",
    "\n",
    "    folds = []\n",
    "    fold_size = int(np.ceil(len(unique_pts) / n_folds))\n",
    "\n",
    "    start_idx = 0\n",
    "    for k in range(n_folds):\n",
    "        end_idx = min(start_idx + fold_size, len(unique_pts))\n",
    "        fold_pids = unique_pts[start_idx:end_idx]\n",
    "        folds.append(set(fold_pids))\n",
    "        start_idx = end_idx\n",
    "\n",
    "    # If n_folds is large or does not divide the data exactly,\n",
    "    # the last fold might be smaller or empty; adapt as needed.\n",
    "    return folds\n",
    "\n",
    "def filter_by_group(df, pid_set):\n",
    "    return df[df['patient_id'].isin(pid_set)].copy()\n",
    "\n",
    "def simulate_policy(df, policy_func):\n",
    "    \"\"\"\n",
    "    Same as the previous examples:\n",
    "      - policy_func(patient_rows) -> treat_time in [0..T_MAX-1] or None\n",
    "    Returns cost, precision, recall, avg_treatment_time\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for pid, patient_rows in df.groupby('patient_id'):\n",
    "        patient_rows = patient_rows.sort_values('time')\n",
    "\n",
    "        label = patient_rows['label'].iloc[0]  # 0 or 1\n",
    "        treat_time = policy_func(patient_rows)\n",
    "\n",
    "        if treat_time is None:\n",
    "            # never treated\n",
    "            treated_flag = 0\n",
    "            if label == 1:\n",
    "                cost = FN_COST\n",
    "            else:\n",
    "                cost = 0\n",
    "            tp = 0\n",
    "            fp = 0\n",
    "            tt = None\n",
    "        else:\n",
    "            treated_flag = 1\n",
    "            if label == 1:\n",
    "                cost = D_COST * treat_time\n",
    "                tp = 1\n",
    "                fp = 0\n",
    "            else:\n",
    "                cost = FP_COST\n",
    "                tp = 0\n",
    "                fp = 1\n",
    "            tt = treat_time\n",
    "\n",
    "        results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': treated_flag,\n",
    "            'treat_time': tt,\n",
    "            'cost': cost,\n",
    "            'tp': tp,\n",
    "            'fp': fp\n",
    "        })\n",
    "\n",
    "    df_res = pd.DataFrame(results)\n",
    "    total_cost = df_res['cost'].sum()\n",
    "\n",
    "    treated_df = df_res[df_res['treated'] == 1]\n",
    "    tp_sum = treated_df['tp'].sum()\n",
    "    fp_sum = treated_df['fp'].sum()\n",
    "    if len(treated_df) > 0:\n",
    "        precision = tp_sum / (tp_sum + fp_sum)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "\n",
    "    sick_df = df_res[df_res['label'] == 1]\n",
    "    total_sick = len(sick_df)\n",
    "    if total_sick > 0:\n",
    "        recall = tp_sum / total_sick\n",
    "    else:\n",
    "        recall = 0.0\n",
    "\n",
    "    if len(treated_df) > 0:\n",
    "        valid_tt = treated_df['treat_time'].dropna()\n",
    "        avg_tt = valid_tt.mean() if len(valid_tt) > 0 else 0.0\n",
    "    else:\n",
    "        avg_tt = 0.0\n",
    "\n",
    "    return {\n",
    "        'cost': total_cost,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'avg_treatment_time': avg_tt\n",
    "    }\n",
    "\n",
    "###############################################################################\n",
    "# 3. BENCHMARK POLICIES\n",
    "###############################################################################\n",
    "def constant_threshold_search(df, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0, 1, 21)\n",
    "    best_thr, best_cost, best_stats = None, float('inf'), None\n",
    "\n",
    "    for thr in thresholds:\n",
    "        def policy_func(patient_rows):\n",
    "            for _, row in patient_rows.iterrows():\n",
    "                if row['risk_score'] >= thr:\n",
    "                    return int(row['time'])\n",
    "            return None\n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_thr = thr\n",
    "            best_stats = stats\n",
    "\n",
    "    return best_thr, best_stats\n",
    "\n",
    "def make_constant_threshold_policy(thr):\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            if row['risk_score'] >= thr:\n",
    "                return int(row['time'])\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def dynamic_threshold_random_search(df,\n",
    "                                    time_steps=20,\n",
    "                                    threshold_candidates=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "                                    n_samples=200,\n",
    "                                    seed=0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    best_vec = None\n",
    "    best_cost = float('inf')\n",
    "    best_stats = None\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        thr_vec = rng.choice(threshold_candidates, size=time_steps)\n",
    "\n",
    "        def policy_func(patient_rows):\n",
    "            for _, row in patient_rows.iterrows():\n",
    "                t = int(row['time'])\n",
    "                if t < time_steps and row['risk_score'] >= thr_vec[t]:\n",
    "                    return t\n",
    "            return None\n",
    "\n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_vec = thr_vec.copy()\n",
    "            best_stats = stats\n",
    "\n",
    "    return best_vec, best_stats\n",
    "\n",
    "def make_dynamic_threshold_policy(thr_vec):\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = int(row['time'])\n",
    "            if t < len(thr_vec):\n",
    "                if row['risk_score'] >= thr_vec[t]:\n",
    "                    return t\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def linear_threshold_search(df, A_candidates=None, B_candidates=None):\n",
    "    if A_candidates is None:\n",
    "        A_candidates = np.linspace(-0.05, 0.05, 11)\n",
    "    if B_candidates is None:\n",
    "        B_candidates = np.linspace(0, 1, 11)\n",
    "    best_A, best_B = None, None\n",
    "    best_cost, best_stats = float('inf'), None\n",
    "\n",
    "    for A in A_candidates:\n",
    "        for B in B_candidates:\n",
    "            def policy_func(patient_rows):\n",
    "                for _, row in patient_rows.iterrows():\n",
    "                    t = row['time']\n",
    "                    thr = A * t + B\n",
    "                    thr = max(0, min(1, thr))\n",
    "                    if row['risk_score'] >= thr:\n",
    "                        return int(t)\n",
    "                return None\n",
    "\n",
    "            stats = simulate_policy(df, policy_func)\n",
    "            if stats['cost'] < best_cost:\n",
    "                best_cost = stats['cost']\n",
    "                best_A = A\n",
    "                best_B = B\n",
    "                best_stats = stats\n",
    "\n",
    "    return (best_A, best_B), best_stats\n",
    "\n",
    "def make_linear_threshold_policy(A, B):\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = row['time']\n",
    "            thr = A*t + B\n",
    "            thr = max(0, min(1, thr))\n",
    "            if row['risk_score'] >= thr:\n",
    "                return int(t)\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def wait_till_end_search(df, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0,1,21)\n",
    "    best_thr, best_cost, best_stats = None, float('inf'), None\n",
    "\n",
    "    for thr in thresholds:\n",
    "        def policy_func(patient_rows):\n",
    "            final_row = patient_rows.loc[patient_rows['time'].idxmax()]\n",
    "            if final_row['risk_score'] >= thr:\n",
    "                return int(final_row['time'])\n",
    "            return None\n",
    "\n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_thr = thr\n",
    "            best_stats = stats\n",
    "\n",
    "    return best_thr, best_stats\n",
    "\n",
    "def make_wait_till_end_policy(thr):\n",
    "    def policy_func(patient_rows):\n",
    "        final_row = patient_rows.loc[patient_rows['time'].idxmax()]\n",
    "        if final_row['risk_score'] >= thr:\n",
    "            return int(final_row['time'])\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "###############################################################################\n",
    "# 4. DATA-DRIVEN DP (Unconstrained) Example\n",
    "###############################################################################\n",
    "def estimate_transition_and_sick_probs(df_train, T=20, n_buckets=5):\n",
    "    \"\"\"\n",
    "    We'll do a simple approach:\n",
    "      p_sick[t,b] = fraction of df_train rows that have (time=t, bucket=b) AND label=1\n",
    "      p_trans[t,b,b'] = fraction of patients at (t,b) who go to (t+1,b') ...\n",
    "    \"\"\"\n",
    "    transition_counts = np.zeros((T-1, n_buckets, n_buckets), dtype=float)\n",
    "    bucket_counts     = np.zeros((T, n_buckets), dtype=float)\n",
    "    sick_counts       = np.zeros((T, n_buckets), dtype=float)\n",
    "\n",
    "    df_sorted = df_train.sort_values(['patient_id','time'])\n",
    "\n",
    "    for pid, grp in df_sorted.groupby('patient_id'):\n",
    "        grp = grp.sort_values('time')\n",
    "        rows = grp.to_dict('records')\n",
    "\n",
    "        for i in range(len(rows)):\n",
    "            t  = int(rows[i]['time'])\n",
    "            b  = int(rows[i]['risk_bucket'])\n",
    "            lb = int(rows[i]['label'])  # 0 or 1\n",
    "            if t < T:\n",
    "                bucket_counts[t, b] += 1\n",
    "                sick_counts[t, b]   += lb\n",
    "\n",
    "            if i < len(rows) - 1:\n",
    "                t_next = int(rows[i+1]['time'])\n",
    "                b_next = int(rows[i+1]['risk_bucket'])\n",
    "                if t_next == t+1 and t < T-1:\n",
    "                    transition_counts[t, b, b_next] += 1.0\n",
    "\n",
    "    # Prob of transitions\n",
    "    p_trans = np.zeros((T-1, n_buckets, n_buckets), dtype=float)\n",
    "    for t_ in range(T-1):\n",
    "        for b_ in range(n_buckets):\n",
    "            denom = transition_counts[t_, b_, :].sum()\n",
    "            if denom > 0:\n",
    "                p_trans[t_, b_, :] = transition_counts[t_, b_, :] / denom\n",
    "            else:\n",
    "                p_trans[t_, b_, b_] = 1.0  # default identity\n",
    "\n",
    "    # Probability of sick in (t,b)\n",
    "    p_sick = np.zeros((T, n_buckets), dtype=float)\n",
    "    for t_ in range(T):\n",
    "        for b_ in range(n_buckets):\n",
    "            denom = bucket_counts[t_, b_]\n",
    "            if denom > 0:\n",
    "                p_sick[t_, b_] = sick_counts[t_, b_] / denom\n",
    "            else:\n",
    "                p_sick[t_, b_] = 0.0\n",
    "    return p_trans, p_sick\n",
    "\n",
    "def train_data_driven_dp_unconstrained(p_trans, p_sick,\n",
    "                                       FP=10, FN=50, D=1, gamma=0.99, T=20):\n",
    "    \"\"\"\n",
    "    DP for unconstrained problem.\n",
    "    \"\"\"\n",
    "    n_buckets = p_sick.shape[1]\n",
    "    V = np.zeros((T+1, n_buckets))\n",
    "    pi_ = np.zeros((T, n_buckets), dtype=int)\n",
    "\n",
    "    # boundary at t=T\n",
    "    for b in range(n_buckets):\n",
    "        cost_treat  = p_sick[T-1,b]*(D*(T-1)) + (1-p_sick[T-1,b])*FP\n",
    "        cost_notreat= p_sick[T-1,b]*FN\n",
    "        V[T,b] = min(cost_treat, cost_notreat)\n",
    "\n",
    "    for t in reversed(range(T)):\n",
    "        for b in range(n_buckets):\n",
    "            cost_treat = p_sick[t,b]*(D*t) + (1-p_sick[t,b])*FP\n",
    "            # cost_wait\n",
    "            if t == T-1:\n",
    "                exp_future = V[T,b]\n",
    "            else:\n",
    "                exp_future = 0.0\n",
    "                for b_next in range(n_buckets):\n",
    "                    exp_future += p_trans[t,b,b_next]*V[t+1,b_next]\n",
    "            cost_wait = gamma * exp_future\n",
    "\n",
    "            if cost_treat <= cost_wait:\n",
    "                V[t,b] = cost_treat\n",
    "                pi_[t,b] = 1\n",
    "            else:\n",
    "                V[t,b] = cost_wait\n",
    "                pi_[t,b] = 0\n",
    "    return V, pi_\n",
    "\n",
    "def make_data_driven_dp_policy_unconstrained(V, pi_, T=20):\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = int(row['time'])\n",
    "            b = int(row['risk_bucket'])\n",
    "            if t < T:\n",
    "                if pi_[t,b] == 1:\n",
    "                    return t\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 5. ALGORITHM 1: SEMI CROSS-VALIDATION\n",
    "###############################################################################\n",
    "def semi_crossval_unconstrained(df_all, n_folds=5, seed=0):\n",
    "    r\"\"\"\n",
    "    This implements the \"Algorithm 1\" idea for the unconstrained scenario.\n",
    "\n",
    "    Steps:\n",
    "     1) Partition df_all into n_folds folds: G1..G_{n_folds}.\n",
    "     2) Let G_{n_folds} = final test set.\n",
    "     3) For each j in [0..(n_folds-2)] (the \"CV folds\"):\n",
    "         - Validation set = G_j\n",
    "         - Training set = union of G_k for k != j\n",
    "           => pick best hyperparams for benchmark (like constant threshold, etc.)\n",
    "           => pick best hyperparams for DP\n",
    "       We store the best hyperparams from each fold j.\n",
    "     4) Combine or choose a final hyperparam set from these folds.\n",
    "     5) Evaluate on the final fold G_{n_folds}.\n",
    "    \"\"\"\n",
    "    # 1) Create folds\n",
    "    folds = make_folds(df_all, n_folds=n_folds, seed=seed)\n",
    "    # folds[0], folds[1], ..., folds[n_folds-1]\n",
    "\n",
    "    # We'll treat folds[n_folds-1] as G_{n_folds} (the final test).\n",
    "    test_fold_pid = folds[-1]\n",
    "\n",
    "    # The first (n_folds-1) folds are used for the cross-validation.\n",
    "    cv_folds = folds[:-1]\n",
    "\n",
    "    # We'll collect best hyperparams for each fold j in [0..n_folds-2].\n",
    "    best_thr_const_list = []\n",
    "    best_dyn_vec_list   = []\n",
    "    best_linAB_list     = []\n",
    "    best_thr_wait_list  = []\n",
    "\n",
    "\n",
    "    for j in range(len(cv_folds)):\n",
    "        # Validation fold = j\n",
    "        val_pid = cv_folds[j]\n",
    "        # Training = union of all other folds except j\n",
    "        train_pid = set()\n",
    "        for k in range(len(cv_folds)):\n",
    "            if k != j:\n",
    "                train_pid = train_pid.union(cv_folds[k])\n",
    "\n",
    "        df_train = filter_by_group(df_all, train_pid)\n",
    "        df_val   = filter_by_group(df_all, val_pid)\n",
    "\n",
    "        # 1) Constant threshold\n",
    "        thr_c, _ = constant_threshold_search(df_train)\n",
    "\n",
    "        best_thr_const_list.append(thr_c)\n",
    "\n",
    "        # 2) Dynamic threshold\n",
    "        thr_vec, _ = dynamic_threshold_random_search(\n",
    "            df_train,\n",
    "            time_steps=T_MAX,\n",
    "            threshold_candidates=[0,0.2,0.4,0.6,0.8,1.0],\n",
    "            n_samples=200,\n",
    "            seed=j\n",
    "        )\n",
    "        best_dyn_vec_list.append(thr_vec)\n",
    "\n",
    "        # 3) Linear threshold\n",
    "        (A,B), _ = linear_threshold_search(df_train)\n",
    "        best_linAB_list.append((A,B))\n",
    "\n",
    "        # 4) Wait till end\n",
    "        thr_wte, _ = wait_till_end_search(df_train)\n",
    "        best_thr_wait_list.append(thr_wte)\n",
    "\n",
    "        # DP - if we had DP hyperparam search, we would do it here.\n",
    "\n",
    "    # Now we have \"best\" hyperparams from each fold.\n",
    "    # For simplicity, let's just pick some aggregator: average or median, etc.\n",
    "\n",
    "    # constant threshold average:\n",
    "    thr_const_final = np.mean(best_thr_const_list)\n",
    "\n",
    "    # dynamic threshold => pick the \"middle\" fold's threshold\n",
    "    mid_idx = len(best_dyn_vec_list)//2\n",
    "    thr_dyn_final = best_dyn_vec_list[mid_idx]\n",
    "\n",
    "    # linear threshold => average (A, B)\n",
    "    A_ave = np.mean([ab[0] for ab in best_linAB_list])\n",
    "    B_ave = np.mean([ab[1] for ab in best_linAB_list])\n",
    "\n",
    "    # wait => average\n",
    "    thr_wait_final = np.mean(best_thr_wait_list)\n",
    "\n",
    "    # Next, build the data-driven DP with all CV folds combined (except test).\n",
    "    train_pid_all = set()\n",
    "    for j in range(len(cv_folds)):\n",
    "        train_pid_all = train_pid_all.union(cv_folds[j])\n",
    "    df_train_cv = filter_by_group(df_all, train_pid_all)\n",
    "\n",
    "    p_trans, p_sick = estimate_transition_and_sick_probs(\n",
    "        df_train_cv, T=T_MAX, n_buckets=5\n",
    "    )\n",
    "    V, pi_ = train_data_driven_dp_unconstrained(\n",
    "        p_trans, p_sick, FP=FP_COST, FN=FN_COST, D=D_COST, gamma=GAMMA, T=T_MAX\n",
    "    )\n",
    "    dp_policy_func = make_data_driven_dp_policy_unconstrained(V, pi_, T=T_MAX)\n",
    "\n",
    "    # Now evaluate everything on final test fold folds[-1].\n",
    "    df_test = filter_by_group(df_all, test_fold_pid)\n",
    "\n",
    "    # Build final policies\n",
    "    const_policy = make_constant_threshold_policy(thr_const_final)\n",
    "    dyn_policy   = make_dynamic_threshold_policy(thr_dyn_final)\n",
    "    lin_policy   = make_linear_threshold_policy(A_ave, B_ave)\n",
    "    wte_policy   = make_wait_till_end_policy(thr_wait_final)\n",
    "\n",
    "    stats_const_test = simulate_policy(df_test, const_policy)\n",
    "    stats_dyn_test   = simulate_policy(df_test, dyn_policy)\n",
    "    stats_lin_test   = simulate_policy(df_test, lin_policy)\n",
    "    stats_wte_test   = simulate_policy(df_test, wte_policy)\n",
    "    stats_dp_test    = simulate_policy(df_test, dp_policy_func)\n",
    "\n",
    "    # Summarize\n",
    "    test_stats_results = { # Changed to return a dictionary for easier processing later\n",
    "        'Constant Threshold': stats_const_test,\n",
    "        'Dynamic Threshold-R': stats_dyn_test,\n",
    "        'Linear Threshold': stats_lin_test,\n",
    "        'Wait Till End': stats_wte_test,\n",
    "        'Dynamic Threshold-DP': stats_dp_test\n",
    "    }\n",
    "    return test_stats_results # Return the dictionary\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 6. MAIN: read CSV, run Algorithm 1 and repeat 30 times\n",
    "###############################################################################\n",
    "def main():\n",
    "    df_all = pd.read_csv(\"synthetic_patients_with_features.csv\")\n",
    "    df_all = df_all[df_all['time'] < T_MAX].copy()\n",
    "\n",
    "    num_replications = 30\n",
    "    all_replication_results = []\n",
    "\n",
    "    for rep_idx in range(num_replications):\n",
    "        print(f\"Running Replication {rep_idx+1}/{num_replications}...\")\n",
    "        replication_stats = semi_crossval_unconstrained(df_all, n_folds=5, seed=rep_idx) # Run Algorithm 1 with different seed\n",
    "        all_replication_results.append(replication_stats) # Store results of each replication\n",
    "\n",
    "    # Process and print final results (mean and std dev)\n",
    "    method_names = list(all_replication_results[0].keys())\n",
    "    final_summary_data = []\n",
    "\n",
    "    for method_name in method_names:\n",
    "        precision_values = [res[method_name]['precision'] for res in all_replication_results]\n",
    "        cost_values      = [res[method_name]['cost']      for res in all_replication_results]\n",
    "        recall_values    = [res[method_name]['recall']    for res in all_replication_results]\n",
    "        tt_values      = [res[method_name]['avg_treatment_time'] for res in all_replication_results]\n",
    "\n",
    "        final_summary_data.append({\n",
    "            'Method': method_name,\n",
    "            'Precision (%)': f\"{np.mean(precision_values)*100:.2f} ± {np.std(precision_values)*100:.2f}\",\n",
    "            'Cost':          f\"{np.mean(cost_values):.2f} ± {np.std(cost_values):.2f}\",\n",
    "            'Recall (%)':    f\"{np.mean(recall_values)*100:.2f} ± {np.std(recall_values):.2f}\",\n",
    "            'Treatment Time':f\"{np.mean(tt_values):.2f} ± {np.std(tt_values):.2f}\",\n",
    "        })\n",
    "\n",
    "    result_table_final = pd.DataFrame(final_summary_data)\n",
    "\n",
    "    print(\"\\n=== Algorithm 1 (Semi Cross-Validation) Results (Mean ± Std Dev over 30 Replications) ===\")\n",
    "    print(result_table_final)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c873627-3c23-4f35-8e5d-322e1c9e1775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Algorithm 1 (Semi Cross-Validation) Results (Unconstrained) ===\n",
      "                 Method  Precision (%)  Cost  Recall (%)  Treatment Time\n",
      "0    Constant Threshold      52.500000   282  100.000000        2.350000\n",
      "1   Dynamic Threshold-R      53.846154   278  100.000000        5.846154\n",
      "2      Linear Threshold      75.000000   174  100.000000        4.428571\n",
      "3         Wait Till End     100.000000   450   95.238095       20.000000\n",
      "4  Dynamic Threshold-DP      80.769231   149  100.000000        4.384615\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SEMI CROSS-VALIDATION (ALGORITHM 1) FOR UNCONSTRAINED HEMORRHAGE DIAGNOSIS & TREATMENT\n",
    "\n",
    "Requirements:\n",
    "  pip install numpy pandas scikit-learn catboost\n",
    "\n",
    "Data assumptions:\n",
    "  - CSV file has columns:\n",
    "      patient_id, time, risk_bucket, risk_score, EIT, NIRS, EIS, label\n",
    "    where:\n",
    "      - 'patient_id' identifies each synthetic patient\n",
    "      - 'time' is an integer time step (0..T_max)\n",
    "      - 'risk_bucket' is an integer bucket (0..4 or 1..5)\n",
    "      - 'EIT', 'NIRS', 'EIS' are numeric features\n",
    "      - 'label' is 0=healthy, 1=sick\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Sklearn models, metrics, etc.\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "# CatBoost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "###############################################################################\n",
    "# 1. GLOBAL PARAMETERS\n",
    "###############################################################################\n",
    "FP_COST = 10\n",
    "FN_COST = 50\n",
    "D_COST  = 1\n",
    "GAMMA   = 0.99\n",
    "T_MAX   = 21   # maximum discrete time steps (0..T_MAX-1)\n",
    "\n",
    "# For demonstration, we'll search a small set of hyperparameters for each ML model.\n",
    "# You can expand these as needed.\n",
    "RF_PARAM_GRID = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "GB_PARAM_GRID = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "CATBOOST_PARAM_GRID = {\n",
    "    'iterations': [50, 100],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'depth': [3, 5]\n",
    "}\n",
    "\n",
    "###############################################################################\n",
    "# 2. HELPER FUNCTIONS: splitting, ML training, DP, etc.\n",
    "###############################################################################\n",
    "def make_folds(df, n_folds=5, seed=0):\n",
    "    \"\"\"\n",
    "    Semi Cross-Validation approach:\n",
    "      - We'll produce n_folds separate sets: G1, G2, ..., G_{n_folds}.\n",
    "      - We'll treat the last fold G_{n_folds} as the final holdout test.\n",
    "      - The first (n_folds - 1) folds are used in the \"semi cross-val\" loops.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    # We'll shuffle patient IDs, then chunk them into n_folds groups\n",
    "    unique_pts = df['patient_id'].unique()\n",
    "    rng.shuffle(unique_pts)\n",
    "    \n",
    "    folds = []\n",
    "    fold_size = int(np.ceil(len(unique_pts) / n_folds))\n",
    "    \n",
    "    start_idx = 0\n",
    "    for k in range(n_folds):\n",
    "        end_idx = min(start_idx + fold_size, len(unique_pts))\n",
    "        fold_pids = unique_pts[start_idx:end_idx]\n",
    "        folds.append(set(fold_pids))\n",
    "        start_idx = end_idx\n",
    "    \n",
    "    return folds\n",
    "\n",
    "def filter_by_group(df, pid_set):\n",
    "    \"\"\"Returns the subset of df whose patient_id is in pid_set.\"\"\"\n",
    "    return df[df['patient_id'].isin(pid_set)].copy()\n",
    "\n",
    "def compute_auc_score(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    Safe AUC computation. If all y_true are the same class,\n",
    "    AUC is not well-defined, so we'll return 0.5 by default.\n",
    "    \"\"\"\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return 0.5\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def train_and_select_best_model(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Trains multiple models (RandomForest, GradientBoosting, CatBoost)\n",
    "    over small hyperparameter grids, picks the best by AUC on (X_val,y_val).\n",
    "    \n",
    "    Returns:\n",
    "        best_model   (fitted model with best AUC)\n",
    "        best_auc     (float)\n",
    "        best_model_name (str, e.g. \"RandomForest\")\n",
    "    \"\"\"\n",
    "    best_auc = -1.0\n",
    "    best_model = None\n",
    "    best_name  = None\n",
    "    \n",
    "    # 1) RandomForest\n",
    "    for params in ParameterGrid(RF_PARAM_GRID):\n",
    "        rf = RandomForestClassifier(random_state=0, **params)\n",
    "        rf.fit(X_train, y_train)\n",
    "        val_prob = rf.predict_proba(X_val)[:,1]\n",
    "        auc_val  = compute_auc_score(y_val, val_prob)\n",
    "        if auc_val > best_auc:\n",
    "            best_auc = auc_val\n",
    "            best_model = rf\n",
    "            best_name  = f\"RandomForest_{params}\"\n",
    "    \n",
    "    # 2) GradientBoosting\n",
    "    for params in ParameterGrid(GB_PARAM_GRID):\n",
    "        gb = GradientBoostingClassifier(random_state=0, **params)\n",
    "        gb.fit(X_train, y_train)\n",
    "        val_prob = gb.predict_proba(X_val)[:,1]\n",
    "        auc_val  = compute_auc_score(y_val, val_prob)\n",
    "        if auc_val > best_auc:\n",
    "            best_auc = auc_val\n",
    "            best_model = gb\n",
    "            best_name  = f\"GradientBoosting_{params}\"\n",
    "    \n",
    "    # 3) CatBoost\n",
    "    for params in ParameterGrid(CATBOOST_PARAM_GRID):\n",
    "        # silent mode\n",
    "        cb = CatBoostClassifier(verbose=0, random_state=0, **params)\n",
    "        cb.fit(X_train, y_train, eval_set=(X_val,y_val), verbose=0)\n",
    "        val_prob = cb.predict_proba(X_val)[:,1]\n",
    "        auc_val  = compute_auc_score(y_val, val_prob)\n",
    "        if auc_val > best_auc:\n",
    "            best_auc = auc_val\n",
    "            best_model = cb\n",
    "            best_name  = f\"CatBoost_{params}\"\n",
    "    \n",
    "    return best_model, best_auc, best_name\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 3. POLICY SIMULATION (Unconstrained) \n",
    "###############################################################################\n",
    "def simulate_policy(df, policy_func):\n",
    "    \"\"\"\n",
    "    Evaluate total cost, precision, recall, avg_treatment_time under a \n",
    "    given policy_func. The policy_func is a function taking \n",
    "       policy_func(subDF_of_single_patient) -> treat_time or None\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for pid, patient_rows in df.groupby('patient_id'):\n",
    "        patient_rows = patient_rows.sort_values('time')\n",
    "        \n",
    "        label = patient_rows['label'].iloc[0]  # 0 or 1\n",
    "        treat_time = policy_func(patient_rows)\n",
    "        \n",
    "        if treat_time is None:\n",
    "            # never treated\n",
    "            if label == 1:\n",
    "                cost = FN_COST\n",
    "                tp   = 0\n",
    "            else:\n",
    "                cost = 0\n",
    "                tp   = 0\n",
    "            fp = 0\n",
    "            treated_flag = 0\n",
    "            tt = None\n",
    "        else:\n",
    "            treated_flag = 1\n",
    "            if label == 1:\n",
    "                cost = D_COST * treat_time  # delay cost\n",
    "                tp = 1\n",
    "                fp = 0\n",
    "            else:\n",
    "                cost = FP_COST\n",
    "                tp = 0\n",
    "                fp = 1\n",
    "            tt = treat_time\n",
    "        \n",
    "        results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': treated_flag,\n",
    "            'treat_time': tt,\n",
    "            'cost': cost,\n",
    "            'tp': tp,\n",
    "            'fp': fp\n",
    "        })\n",
    "    \n",
    "    df_res = pd.DataFrame(results)\n",
    "    total_cost = df_res['cost'].sum()\n",
    "    \n",
    "    treated_df = df_res[df_res['treated'] == 1]\n",
    "    tp_sum = treated_df['tp'].sum()\n",
    "    fp_sum = treated_df['fp'].sum()\n",
    "    if len(treated_df) > 0:\n",
    "        precision = tp_sum / (tp_sum + fp_sum)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "    \n",
    "    sick_df = df_res[df_res['label'] == 1]\n",
    "    total_sick = len(sick_df)\n",
    "    if total_sick > 0:\n",
    "        recall = tp_sum / total_sick\n",
    "    else:\n",
    "        recall = 0.0\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        valid_tt = treated_df['treat_time'].dropna()\n",
    "        avg_tt = valid_tt.mean() if len(valid_tt) > 0 else 0.0\n",
    "    else:\n",
    "        avg_tt = 0.0\n",
    "    \n",
    "    return {\n",
    "        'cost': total_cost,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'avg_treatment_time': avg_tt\n",
    "    }\n",
    "\n",
    "###############################################################################\n",
    "# 4. BENCHMARK POLICIES (Threshold-based)\n",
    "###############################################################################\n",
    "def constant_threshold_search(df, thresholds=None):\n",
    "    \"\"\"Grid search over a set of constant thresholds.\"\"\"\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0, 1, 21)\n",
    "    best_thr, best_cost, best_stats = None, float('inf'), None\n",
    "    \n",
    "    for thr in thresholds:\n",
    "        def policy_func(patient_rows):\n",
    "            for _, row in patient_rows.iterrows():\n",
    "                if row['risk_score'] >= thr:\n",
    "                    return int(row['time'])\n",
    "            return None\n",
    "        \n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_thr = thr\n",
    "            best_stats = stats\n",
    "    \n",
    "    return best_thr, best_stats\n",
    "\n",
    "def make_constant_threshold_policy(thr):\n",
    "    \"\"\"Creates a policy that treats the patient at the first time whose risk_score >= thr.\"\"\"\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            if row['risk_score'] >= thr:\n",
    "                return int(row['time'])\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def dynamic_threshold_random_search(df,\n",
    "                                    time_steps=20,\n",
    "                                    threshold_candidates=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "                                    n_samples=200,\n",
    "                                    seed=0):\n",
    "    \"\"\"\n",
    "    Randomly sample vectors of length time_steps from threshold_candidates,\n",
    "    pick the best by cost on df.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    best_vec = None\n",
    "    best_cost = float('inf')\n",
    "    best_stats = None\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        thr_vec = rng.choice(threshold_candidates, size=time_steps)\n",
    "        \n",
    "        def policy_func(patient_rows):\n",
    "            for _, row in patient_rows.iterrows():\n",
    "                t = int(row['time'])\n",
    "                if t < time_steps and row['risk_score'] >= thr_vec[t]:\n",
    "                    return t\n",
    "            return None\n",
    "        \n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_vec = thr_vec.copy()\n",
    "            best_stats = stats\n",
    "    \n",
    "    return best_vec, best_stats\n",
    "\n",
    "def make_dynamic_threshold_policy(thr_vec):\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = int(row['time'])\n",
    "            if t < len(thr_vec):\n",
    "                if row['risk_score'] >= thr_vec[t]:\n",
    "                    return t\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def linear_threshold_search(df, A_candidates=None, B_candidates=None):\n",
    "    \"\"\"\n",
    "    threshold(t) = clamp( A*t + B, [0,1] )\n",
    "    do grid search\n",
    "    \"\"\"\n",
    "    if A_candidates is None:\n",
    "        A_candidates = np.linspace(-0.05, 0.05, 11)\n",
    "    if B_candidates is None:\n",
    "        B_candidates = np.linspace(0, 1, 11)\n",
    "    \n",
    "    best_A, best_B = None, None\n",
    "    best_cost, best_stats = float('inf'), None\n",
    "    \n",
    "    for A in A_candidates:\n",
    "        for B in B_candidates:\n",
    "            def policy_func(patient_rows):\n",
    "                for _, row in patient_rows.iterrows():\n",
    "                    t = row['time']\n",
    "                    thr = A*t + B\n",
    "                    thr = max(0, min(1, thr))\n",
    "                    if row['risk_score'] >= thr:\n",
    "                        return int(t)\n",
    "                return None\n",
    "            \n",
    "            stats = simulate_policy(df, policy_func)\n",
    "            if stats['cost'] < best_cost:\n",
    "                best_cost = stats['cost']\n",
    "                best_A = A\n",
    "                best_B = B\n",
    "                best_stats = stats\n",
    "    \n",
    "    return (best_A, best_B), best_stats\n",
    "\n",
    "def make_linear_threshold_policy(A, B):\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = row['time']\n",
    "            thr = A*t + B\n",
    "            thr = max(0, min(1, thr))\n",
    "            if row['risk_score'] >= thr:\n",
    "                return int(t)\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def wait_till_end_search(df, thresholds=None):\n",
    "    \"\"\"\n",
    "    Evaluate policy: treat only at final time if risk_score >= thr.\n",
    "    \"\"\"\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0,1,21)\n",
    "    best_thr, best_cost, best_stats = None, float('inf'), None\n",
    "    \n",
    "    for thr in thresholds:\n",
    "        def policy_func(patient_rows):\n",
    "            # final row:\n",
    "            final_t = patient_rows['time'].max()\n",
    "            final_row = patient_rows[patient_rows['time']==final_t].iloc[0]\n",
    "            if final_row['risk_score'] >= thr:\n",
    "                return int(final_t)\n",
    "            return None\n",
    "        \n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_thr = thr\n",
    "            best_stats = stats\n",
    "    \n",
    "    return best_thr, best_stats\n",
    "\n",
    "def make_wait_till_end_policy(thr):\n",
    "    def policy_func(patient_rows):\n",
    "        final_t = patient_rows['time'].max()\n",
    "        final_row = patient_rows[patient_rows['time']==final_t].iloc[0]\n",
    "        if final_row['risk_score'] >= thr:\n",
    "            return int(final_t)\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "###############################################################################\n",
    "# 5. DATA-DRIVEN DP (Unconstrained)\n",
    "###############################################################################\n",
    "def estimate_transition_and_sick_probs(df_train, T=20, n_buckets=5):\n",
    "    \"\"\"\n",
    "    We'll estimate:\n",
    "      p_trans[t, b, b_next]: Probability that a patient in risk-bucket b at time t\n",
    "                             transitions to bucket b_next at time t+1\n",
    "      p_sick[t, b]: Probability that a patient is sick given that they are in bucket b at time t.\n",
    "    This is a naive aggregator (assuming Markov wrt bucket).\n",
    "    \"\"\"\n",
    "    transition_counts = np.zeros((T-1, n_buckets, n_buckets), dtype=float)\n",
    "    bucket_counts     = np.zeros((T, n_buckets), dtype=float)\n",
    "    sick_counts       = np.zeros((T, n_buckets), dtype=float)\n",
    "\n",
    "    df_sorted = df_train.sort_values(['patient_id','time'])\n",
    "    \n",
    "    for pid, grp in df_sorted.groupby('patient_id'):\n",
    "        grp = grp.sort_values('time')\n",
    "        rows = grp.to_dict('records')\n",
    "        \n",
    "        for i in range(len(rows)):\n",
    "            t  = int(rows[i]['time'])\n",
    "            b  = int(rows[i]['risk_bucket'])\n",
    "            lb = int(rows[i]['label'])  # 0 or 1\n",
    "            if t < T:\n",
    "                bucket_counts[t, b] += 1\n",
    "                sick_counts[t, b]   += lb\n",
    "            \n",
    "            if i < len(rows) - 1:\n",
    "                # consider the next row if it's exactly t+1\n",
    "                t_next = int(rows[i+1]['time'])\n",
    "                b_next = int(rows[i+1]['risk_bucket'])\n",
    "                if (t_next == t+1) and (t < T-1):\n",
    "                    transition_counts[t, b, b_next] += 1.0\n",
    "\n",
    "    # p_trans\n",
    "    n_buckets = bucket_counts.shape[1]\n",
    "    p_trans = np.zeros((T-1, n_buckets, n_buckets), dtype=float)\n",
    "    for t_ in range(T-1):\n",
    "        for b_ in range(n_buckets):\n",
    "            denom = transition_counts[t_, b_, :].sum()\n",
    "            if denom > 0:\n",
    "                p_trans[t_, b_, :] = transition_counts[t_, b_, :] / denom\n",
    "            else:\n",
    "                # if no data, fallback to identity\n",
    "                p_trans[t_, b_, b_] = 1.0\n",
    "    \n",
    "    # p_sick\n",
    "    p_sick = np.zeros((T, n_buckets), dtype=float)\n",
    "    for t_ in range(T):\n",
    "        for b_ in range(n_buckets):\n",
    "            denom = bucket_counts[t_, b_]\n",
    "            if denom > 0:\n",
    "                p_sick[t_, b_] = sick_counts[t_, b_] / denom\n",
    "            else:\n",
    "                p_sick[t_, b_] = 0.0\n",
    "    \n",
    "    return p_trans, p_sick\n",
    "\n",
    "def train_data_driven_dp_unconstrained(p_trans, p_sick, \n",
    "                                       FP=10, FN=50, D=1, gamma=0.99, T=20):\n",
    "    \"\"\"\n",
    "    We define states as (t, bucket), and actions: 0=wait, 1=treat now.\n",
    "    We'll do a simple backward recursion:\n",
    "       V[t,b] = min( cost_of_treat_now, cost_of_wait )\n",
    "    cost_of_treat_now = p_sick[t,b]* (D*t) + (1-p_sick[t,b])* FP\n",
    "    cost_of_wait      = gamma * E_{b_next}[ V[t+1, b_next] ]\n",
    "    At t=T, we define cost if not treated:\n",
    "       => p_sick[T-1,b]*FN  vs. cost_of_treat_now at T-1\n",
    "    We'll store the policy in pi_[t,b].\n",
    "    \"\"\"\n",
    "    n_buckets = p_sick.shape[1]\n",
    "    # Note: We'll define V[t,b] for t in [0..T], b in [0..n_buckets-1].\n",
    "    # But we actually only have transitions up to T-1 in p_trans.\n",
    "    V = np.zeros((T+1, n_buckets))\n",
    "    pi_ = np.zeros((T, n_buckets), dtype=int)\n",
    "    \n",
    "    # boundary at t=T: if we haven't treated yet, the cost is:\n",
    "    # min( treat at T, not treat at all ).\n",
    "    # But let's define it simply as \"if not treat => FN\" or \"if treat => cost_treatNow\".\n",
    "    for b in range(n_buckets):\n",
    "        # \"treat now at time T\" => D*T?? but actually t goes up to T-1. \n",
    "        # We'll define an effective \"t = T\" as if it's the final step.\n",
    "        # so cost_treat = p_sick[T-1,b]*(D*(T-1)) + (1-p_sick[T-1,b])*FP\n",
    "        # cost_notreat  = p_sick[T-1,b]*FN\n",
    "        # We'll just do that here:\n",
    "        cost_treat  = p_sick[T-1,b]*(D*(T-1)) + (1 - p_sick[T-1,b])*FP\n",
    "        cost_notreat= p_sick[T-1,b]*FN\n",
    "        V[T,b] = min(cost_treat, cost_notreat)\n",
    "    \n",
    "    # now go backward:\n",
    "    for t in reversed(range(T)):\n",
    "        for b in range(n_buckets):\n",
    "            # cost if treat now\n",
    "            cost_treat = p_sick[t,b]*(D*t) + (1 - p_sick[t,b])*FP\n",
    "            \n",
    "            # cost if wait\n",
    "            if t == T-1:\n",
    "                # if wait at T-1, next is T => no transitions => V[T,b]\n",
    "                cost_wait = gamma * V[T,b]\n",
    "            else:\n",
    "                # compute expected cost from next state\n",
    "                exp_future = 0.0\n",
    "                for b_next in range(n_buckets):\n",
    "                    exp_future += p_trans[t,b,b_next]*V[t+1,b_next]\n",
    "                cost_wait = gamma * exp_future\n",
    "            \n",
    "            if cost_treat <= cost_wait:\n",
    "                V[t,b] = cost_treat\n",
    "                pi_[t,b] = 1\n",
    "            else:\n",
    "                V[t,b] = cost_wait\n",
    "                pi_[t,b] = 0\n",
    "    \n",
    "    return V, pi_\n",
    "\n",
    "def make_data_driven_dp_policy_unconstrained(V, pi_, T=20):\n",
    "    \"\"\"\n",
    "    Creates a function that iterates over time steps of a patient.\n",
    "    As soon as DP says \"treat\" at (t,b), we do so and stop.\n",
    "    \"\"\"\n",
    "    def policy_func(patient_rows):\n",
    "        # naive approach: read each row in chronological order\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = int(row['time'])\n",
    "            b = int(row['risk_bucket'])\n",
    "            if t < T:\n",
    "                if pi_[t,b] == 1:\n",
    "                    return t\n",
    "        # if we never treat => None\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "###############################################################################\n",
    "# 6. ALGORITHM 1: SEMI CROSS-VALIDATION (Unconstrained)\n",
    "###############################################################################\n",
    "def semi_crossval_unconstrained(df_all, n_folds=5, seed=0):\n",
    "    \"\"\"\n",
    "    Implements the \"semi cross-validation\" approach for ML + DP \n",
    "    in the unconstrained scenario (Algorithm 1).\n",
    "    \n",
    "    Steps (schematic):\n",
    "      1) Create n_folds. \n",
    "         Let G_{n_folds} be final holdout. G_1..G_{n_folds-1} for \"semi-CV\".\n",
    "      2) For j in [1..(n_folds-1)]:\n",
    "          - Validation fold = G_j\n",
    "          - Training fold = union of G_k for k != j\n",
    "          - Among that \"training fold,\" we do an (n_folds-2)-fold approach \n",
    "            to select best ML hyperparams (AUC).\n",
    "            (In a simpler \"semi\" approach, we might skip an inner fold and just train ML on train set.)\n",
    "          - Evaluate DP hyperparams on G_j, store best result.\n",
    "      3) Aggregate or pick final hyperparams from these folds.\n",
    "      4) Retrain ML + DP on union G_1..G_{n_folds-1}, evaluate on G_{n_folds}.\n",
    "\n",
    "    For brevity, we do a simpler version:\n",
    "      - For each j in 0..(n_folds-2):\n",
    "         * Train ML on (all except G_j),\n",
    "         * Evaluate best threshold or best DP on G_j\n",
    "      - Then average or pick the median. \n",
    "      - Finally, evaluate on G_{n_folds-1} as holdout.\n",
    "    \"\"\"\n",
    "    folds = make_folds(df_all, n_folds=n_folds, seed=seed)\n",
    "    # final test:\n",
    "    test_fold_pid = folds[-1]\n",
    "    # the first n_folds-1 are the \"CV folds\"\n",
    "    cv_folds = folds[:-1]\n",
    "    \n",
    "    # We'll store each fold's best ML model among {RF,GB,CatBoost}\n",
    "    # Then we'll store the best threshold or DP approach.\n",
    "    # In a \"true\" Algorithm 1, you'd do an \"inner loop\" for each fold as well, \n",
    "    # but we’ll keep it simpler for demonstration.\n",
    "\n",
    "    # Lists to store benchmark hyperparams found in each fold j\n",
    "    best_thr_const_list = []\n",
    "    best_dyn_vec_list   = []\n",
    "    best_linAB_list     = []\n",
    "    best_thr_wait_list  = []\n",
    "    best_dp_policies    = []\n",
    "    \n",
    "    for j, val_pid in enumerate(cv_folds):\n",
    "        # Validation fold j => G_j\n",
    "        df_val   = filter_by_group(df_all, val_pid)\n",
    "        \n",
    "        # Training = union of all other folds except j\n",
    "        train_pid = set()\n",
    "        for k, fold_pids in enumerate(cv_folds):\n",
    "            if k != j:\n",
    "                train_pid = train_pid.union(fold_pids)\n",
    "        df_train = filter_by_group(df_all, train_pid)\n",
    "        \n",
    "        # ============== (A) Train ML model on df_train => pick best by AUC on the same df_train ==============\n",
    "        # (In a real approach, you'd do a smaller sub-fold split or separate val for ML only, \n",
    "        #  but here we do \"semi\" for brevity.)\n",
    "        X_train = df_train[['EIT','NIRS','EIS']].values\n",
    "        y_train = df_train['label'].values\n",
    "        \n",
    "        # Just do a train/val = we can do a small split inside df_train, or \n",
    "        # let's do the entire df_train for training and the same df_train for ML selection \n",
    "        # (not ideal, but simpler).\n",
    "        X_val = df_train[['EIT','NIRS','EIS']].values\n",
    "        y_val = df_train['label'].values\n",
    "        \n",
    "        ml_model, best_auc, best_mname = train_and_select_best_model(X_train, y_train, X_val, y_val)\n",
    "        \n",
    "        # Now, we apply this trained model to produce a risk_score for ALL ROWS in df_train+df_val\n",
    "        # So we can do threshold tuning, DP, etc.\n",
    "        # We'll store them back in the main df so we can do the policy searches.\n",
    "        # But be careful not to pollute folds with each other => for demonstration, it's simpler \n",
    "        # to do it just for df_val \"on the fly\" for cost evaluation.\n",
    "\n",
    "        # (B) Evaluate on VAL fold => get risk scores\n",
    "        X_val_fold = df_val[['EIT','NIRS','EIS']].values\n",
    "        val_probs  = ml_model.predict_proba(X_val_fold)[:,1]\n",
    "        df_val.loc[:,'risk_score'] = val_probs  # set the model-based risk\n",
    "\n",
    "        # We do the same for df_train because we need to estimate Markov transitions for the DP\n",
    "        X_train_fold = df_train[['EIT','NIRS','EIS']].values\n",
    "        train_probs  = ml_model.predict_proba(X_train_fold)[:,1]\n",
    "        df_train.loc[:,'risk_score'] = train_probs\n",
    "\n",
    "        # Also discretize into risk buckets again, e.g. 5 equally sized:\n",
    "        # We'll do a simple approach:  (0,0.2)->0, [0.2,0.4)->1, ...\n",
    "        def to_bucket(p):\n",
    "            return min(int(p*5), 4)\n",
    "        df_train.loc[:,'risk_bucket'] = df_train['risk_score'].apply(to_bucket)\n",
    "        df_val.loc[:,'risk_bucket']   = df_val['risk_score'].apply(to_bucket)\n",
    "\n",
    "        # ============= (C) Benchmark Policies on VAL fold =============\n",
    "        #  (C.1) Constant threshold\n",
    "        thr_c, _ = constant_threshold_search(df_train)  # or do it on df_train\n",
    "        best_thr_const_list.append(thr_c)\n",
    "        \n",
    "        #  (C.2) Dynamic threshold\n",
    "        thr_vec, _ = dynamic_threshold_random_search(df_train, \n",
    "                                                     time_steps=T_MAX,\n",
    "                                                     threshold_candidates=[0,0.2,0.4,0.6,0.8,1.0],\n",
    "                                                     n_samples=200,\n",
    "                                                     seed=j)\n",
    "        best_dyn_vec_list.append(thr_vec)\n",
    "        \n",
    "        #  (C.3) Linear threshold\n",
    "        (A,B), _ = linear_threshold_search(df_train)\n",
    "        best_linAB_list.append((A,B))\n",
    "        \n",
    "        #  (C.4) Wait till end\n",
    "        thr_wte, _ = wait_till_end_search(df_train)\n",
    "        best_thr_wait_list.append(thr_wte)\n",
    "        \n",
    "        # ============= (D) DP Approach =============\n",
    "        # We'll fit the Markov chain from df_train => p_trans, p_sick\n",
    "        p_trans, p_sick = estimate_transition_and_sick_probs(df_train, T=T_MAX, n_buckets=5)\n",
    "        V, pi_ = train_data_driven_dp_unconstrained(p_trans, p_sick, \n",
    "                                                    FP=FP_COST, FN=FN_COST, \n",
    "                                                    D=D_COST, gamma=GAMMA, T=T_MAX)\n",
    "        best_dp_policies.append((V, pi_))\n",
    "        \n",
    "        # (In a full search for DP hyperparams, you might loop over gamma in {0.95,0.99}, \n",
    "        #  or vary cost ratios, etc. For brevity, we only use the above.)\n",
    "        \n",
    "        # End of fold j\n",
    "\n",
    "    # ----- (E) Combine or pick final hyperparams from these folds ------\n",
    "    # For demonstration, let's pick the average or the median from the sets we found:\n",
    "\n",
    "    thr_const_final = np.mean(best_thr_const_list)\n",
    "    \n",
    "    mid_idx = len(best_dyn_vec_list)//2\n",
    "    thr_dyn_final = best_dyn_vec_list[mid_idx]  # pick the \"middle\" one\n",
    "    \n",
    "    A_ave = np.mean([ab[0] for ab in best_linAB_list])\n",
    "    B_ave = np.mean([ab[1] for ab in best_linAB_list])\n",
    "    \n",
    "    thr_wait_final = np.mean(best_thr_wait_list)\n",
    "    \n",
    "    # For DP, let's pick the last fold's (V, pi_). \n",
    "    # Or we could store them all and pick the one with minimal val cost. \n",
    "    # We'll just pick the last for demonstration:\n",
    "    V_final, pi_final = best_dp_policies[-1]\n",
    "    \n",
    "    # ========== (F) Retrain ML model on all CV folds except test fold => final model ==========\n",
    "    train_pid_all = set()\n",
    "    for fold_pid in cv_folds:\n",
    "        train_pid_all = train_pid_all.union(fold_pid)\n",
    "    df_train_cv = filter_by_group(df_all, train_pid_all)\n",
    "    \n",
    "    X_train_cv = df_train_cv[['EIT','NIRS','EIS']].values\n",
    "    y_train_cv = df_train_cv['label'].values\n",
    "    \n",
    "    # We'll do the same \"train_and_select_best_model\" approach \n",
    "    # but we have no separate val set, so we'll just reuse X_train_cv for selection:\n",
    "    final_model, _, _ = train_and_select_best_model(X_train_cv, y_train_cv,\n",
    "                                                    X_train_cv, y_train_cv)\n",
    "    \n",
    "    # We'll produce final risk scores for test set G_{n_folds}.\n",
    "    df_test = filter_by_group(df_all, test_fold_pid).copy()\n",
    "    \n",
    "    X_test  = df_test[['EIT','NIRS','EIS']].values\n",
    "    test_probs = final_model.predict_proba(X_test)[:,1]\n",
    "    df_test.loc[:,'risk_score'] = test_probs\n",
    "    \n",
    "    # Re-bucket for DP or threshold logic\n",
    "    def to_bucket(p):\n",
    "        return min(int(p*5), 4)\n",
    "    df_test.loc[:,'risk_bucket'] = df_test['risk_score'].apply(to_bucket)\n",
    "    \n",
    "    # (F.1) Build final policies from the chosen final hyperparams:\n",
    "    const_policy = make_constant_threshold_policy(thr_const_final)\n",
    "    dyn_policy   = make_dynamic_threshold_policy(thr_dyn_final)\n",
    "    lin_policy   = make_linear_threshold_policy(A_ave, B_ave)\n",
    "    wte_policy   = make_wait_till_end_policy(thr_wait_final)\n",
    "    dp_policy    = make_data_driven_dp_policy_unconstrained(V_final, pi_final, T=T_MAX)\n",
    "    \n",
    "    # (F.2) Evaluate on test set\n",
    "    stats_const = simulate_policy(df_test, const_policy)\n",
    "    stats_dyn   = simulate_policy(df_test, dyn_policy)\n",
    "    stats_lin   = simulate_policy(df_test, lin_policy)\n",
    "    stats_wte   = simulate_policy(df_test, wte_policy)\n",
    "    stats_dp    = simulate_policy(df_test, dp_policy)\n",
    "    \n",
    "    table = pd.DataFrame({\n",
    "        'Method': [\n",
    "            'Constant Threshold',\n",
    "            'Dynamic Threshold-R',\n",
    "            'Linear Threshold',\n",
    "            'Wait Till End',\n",
    "            'Dynamic Threshold-DP'\n",
    "        ],\n",
    "        'Precision (%)': [\n",
    "            100*stats_const['precision'],\n",
    "            100*stats_dyn['precision'],\n",
    "            100*stats_lin['precision'],\n",
    "            100*stats_wte['precision'],\n",
    "            100*stats_dp['precision']\n",
    "        ],\n",
    "        'Cost': [\n",
    "            stats_const['cost'],\n",
    "            stats_dyn['cost'],\n",
    "            stats_lin['cost'],\n",
    "            stats_wte['cost'],\n",
    "            stats_dp['cost']\n",
    "        ],\n",
    "        'Recall (%)': [\n",
    "            100*stats_const['recall'],\n",
    "            100*stats_dyn['recall'],\n",
    "            100*stats_lin['recall'],\n",
    "            100*stats_wte['recall'],\n",
    "            100*stats_dp['recall']\n",
    "        ],\n",
    "        'Treatment Time': [\n",
    "            stats_const['avg_treatment_time'],\n",
    "            stats_dyn['avg_treatment_time'],\n",
    "            stats_lin['avg_treatment_time'],\n",
    "            stats_wte['avg_treatment_time'],\n",
    "            stats_dp['avg_treatment_time']\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    return table\n",
    "\n",
    "###############################################################################\n",
    "# 7. MAIN\n",
    "###############################################################################\n",
    "def main():\n",
    "    # Load your CSV file (should have columns patient_id, time, risk_bucket, risk_score, EIT, NIRS, EIS, label)\n",
    "    df_all = pd.read_csv(\"synthetic_patients_with_features.csv\")\n",
    "    # Possibly filter to time < T_MAX if your dataset has more time steps\n",
    "    df_all = df_all[df_all['time'] < T_MAX].copy()\n",
    "    \n",
    "    # Just ensure columns exist:\n",
    "    required_cols = {'patient_id','time','risk_bucket','risk_score','EIT','NIRS','EIS','label'}\n",
    "    missing = required_cols - set(df_all.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Your CSV is missing columns: {missing}\")\n",
    "    \n",
    "    n_folds = 5\n",
    "    seed = 42\n",
    "    \n",
    "    result_table = semi_crossval_unconstrained(df_all, n_folds=n_folds, seed=seed)\n",
    "    \n",
    "    print(\"\\n=== Algorithm 1 (Semi Cross-Validation) Results (Unconstrained) ===\")\n",
    "    print(result_table)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728c923c-b7e8-4d9b-8fb6-25d47e538c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
