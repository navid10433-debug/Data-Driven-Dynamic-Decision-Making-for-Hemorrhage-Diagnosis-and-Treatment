{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96af517c-eb75-469f-81a0-29427e02e24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ALGORITHM 5 (SPSA) + 50% CAP ON SICK, FINAL HOLDOUT ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1063      34.146341   48.275862        1.048780\n",
      "Dynamic Threshold-R  1450       0.000000    0.000000        0.000000\n",
      "   Linear Threshold  1109      29.787234   48.275862        0.829787\n",
      "      Wait Till End  1030     100.000000   48.275862       20.000000\n",
      "    DP-based (SPSA)   842      77.777778   48.275862        4.833333\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ALGORITHM 4 (SPSA) + BENCHMARK TABLE\n",
    "WITH 50% CAP ON SICK PATIENTS .\n",
    "\n",
    "Requirements:\n",
    "  pip install numpy pandas scikit-learn catboost\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Sklearn models, metrics, etc.\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "# CatBoost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "###############################################################################\n",
    "# 1. GLOBAL PARAMETERS\n",
    "###############################################################################\n",
    "FP_COST = 10\n",
    "FN_COST = 50\n",
    "D_COST  = 1\n",
    "T_MAX   = 21   # maximum discrete time steps (0..T_MAX-1)\n",
    "\n",
    "###############################################################################\n",
    "# 2. HELPER FUNCTIONS\n",
    "###############################################################################\n",
    "def split_into_four_groups(df, seed=0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    unique_pids = df['patient_id'].unique()\n",
    "    rng.shuffle(unique_pids)\n",
    "    \n",
    "    n = len(unique_pids)\n",
    "    i1 = int(0.25 * n)\n",
    "    i2 = int(0.50 * n)\n",
    "    i3 = int(0.75 * n)\n",
    "    \n",
    "    G1_pids = unique_pids[: i1]\n",
    "    G2_pids = unique_pids[i1 : i2]\n",
    "    G3_pids = unique_pids[i2 : i3]\n",
    "    G4_pids = unique_pids[i3 : ]\n",
    "    \n",
    "    G1 = df[df['patient_id'].isin(G1_pids)].copy()\n",
    "    G2 = df[df['patient_id'].isin(G2_pids)].copy()\n",
    "    G3 = df[df['patient_id'].isin(G3_pids)].copy()\n",
    "    G4 = df[df['patient_id'].isin(G4_pids)].copy()\n",
    "    return G1, G2, G3, G4\n",
    "\n",
    "def k_plus_1_splits(df, k=3, seed=0):\n",
    "    \"\"\"\n",
    "    For Algorithm 5 (SPSA), we often split the data into k+1 groups:\n",
    "      G1, G2, ..., Gk, G_{k+1}.\n",
    "    This is a k-fold style partition plus one final holdout.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    unique_pids = df['patient_id'].unique()\n",
    "    rng.shuffle(unique_pids)\n",
    "    \n",
    "    n = len(unique_pids)\n",
    "    fold_size = int(n/(k+1))\n",
    "    \n",
    "    groups = []\n",
    "    start = 0\n",
    "    for i in range(k):\n",
    "        pids_fold = unique_pids[start : start+fold_size]\n",
    "        start += fold_size\n",
    "        g = df[df['patient_id'].isin(pids_fold)].copy()\n",
    "        groups.append(g)\n",
    "    \n",
    "    # final group is everything leftover\n",
    "    pids_fold = unique_pids[start:]\n",
    "    g = df[df['patient_id'].isin(pids_fold)].copy()\n",
    "    groups.append(g)\n",
    "    return groups\n",
    "\n",
    "def compute_auc_score(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return 0.5\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "###############################################################################\n",
    "# 3. POLICY SIMULATION (WITH & WITHOUT CAPACITY)\n",
    "###############################################################################\n",
    "def simulate_policy(df, policy_func):\n",
    "    \"\"\"\n",
    "    Unconstrained simulation (no limit on how many sick get treated).\n",
    "    df must have columns: patient_id, time, risk_score, label.\n",
    "    policy_func(patient_rows) -> treat_time (int) or None\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for pid, grp in df.groupby('patient_id'):\n",
    "        grp = grp.sort_values('time')\n",
    "        label = grp['label'].iloc[0]\n",
    "        \n",
    "        treat_time = policy_func(grp)\n",
    "        \n",
    "        if treat_time is None:\n",
    "            # never treated\n",
    "            if label == 1:\n",
    "                cost = FN_COST\n",
    "                tp   = 0\n",
    "            else:\n",
    "                cost = 0\n",
    "                tp   = 0\n",
    "            fp = 0\n",
    "            treat_flag = 0\n",
    "            ttime = None\n",
    "        else:\n",
    "            treat_flag = 1\n",
    "            if label == 1:\n",
    "                cost = D_COST * treat_time\n",
    "                tp   = 1\n",
    "                fp   = 0\n",
    "            else:\n",
    "                cost = FP_COST\n",
    "                tp   = 0\n",
    "                fp   = 1\n",
    "            ttime = treat_time\n",
    "        \n",
    "        results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': treat_flag,\n",
    "            'treat_time': ttime,\n",
    "            'cost': cost,\n",
    "            'tp': tp,\n",
    "            'fp': fp\n",
    "        })\n",
    "    \n",
    "    df_res     = pd.DataFrame(results)\n",
    "    total_cost = df_res['cost'].sum()\n",
    "    \n",
    "    treated_df = df_res[df_res['treated']==1]\n",
    "    tp_sum = treated_df['tp'].sum()\n",
    "    fp_sum = treated_df['fp'].sum()\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        precision = tp_sum / (tp_sum + fp_sum)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "    \n",
    "    sick_df = df_res[df_res['label']==1]\n",
    "    total_sick = len(sick_df)\n",
    "    if total_sick > 0:\n",
    "        recall = tp_sum / total_sick\n",
    "    else:\n",
    "        recall = 0.0\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        valid_tt = treated_df['treat_time'].dropna()\n",
    "        avg_tt   = valid_tt.mean() if len(valid_tt) > 0 else 0.0\n",
    "    else:\n",
    "        avg_tt = 0.0\n",
    "    \n",
    "    return {\n",
    "        'cost': total_cost,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'avg_treatment_time': avg_tt\n",
    "    }\n",
    "\n",
    "\n",
    "def simulate_policy_with_sick_capacity(df, policy_func, capacity_frac=0.5):\n",
    "    \"\"\"\n",
    "    Enforce that at most (capacity_frac) fraction of the *sick* patients\n",
    "    can be treated (as in Algorithm 0 for G4).\n",
    "    \n",
    "    Steps:\n",
    "      1. Identify which patients are \"recommended\" for treatment by the policy_func.\n",
    "      2. Separate them into recommended_sick vs. recommended_healthy.\n",
    "      3. Among recommended_sick, only treat the top floor(capacity_frac * total_sick) \n",
    "         by risk_score. The rest remain untreated.\n",
    "      4. All recommended_healthy are treated (no limit).\n",
    "      5. Everyone else is not treated, incurring FN cost if sick, 0 if healthy.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    recommended_sick = []     # (pid, label=1, time_treated, risk_score)\n",
    "    recommended_healthy = []  # (pid, label=0, time_treated, risk_score)\n",
    "    \n",
    "    # 1) Count total sick\n",
    "    all_sick_df = df[df['label']==1]\n",
    "    num_sick = all_sick_df['patient_id'].nunique()\n",
    "    capacity_num = int(np.floor(capacity_frac * num_sick)) if num_sick>0 else 0\n",
    "    \n",
    "    # Gather recommended patients\n",
    "    for pid, grp in df.groupby('patient_id'):\n",
    "        grp = grp.sort_values('time')\n",
    "        label = grp['label'].iloc[0]\n",
    "        \n",
    "        treat_time = policy_func(grp)\n",
    "        \n",
    "        if treat_time is None:\n",
    "            # not recommended -> fill cost later\n",
    "            results.append({\n",
    "                'patient_id': pid,\n",
    "                'label': label,\n",
    "                'treated': 0,\n",
    "                'treat_time': None,\n",
    "                'cost': None,\n",
    "                'tp': 0,\n",
    "                'fp': 0\n",
    "            })\n",
    "        else:\n",
    "            # recommended\n",
    "            row_t = grp[grp['time']==treat_time].iloc[0]\n",
    "            recommended_risk = row_t['risk_score']\n",
    "            if label == 1:\n",
    "                recommended_sick.append((pid, label, treat_time, recommended_risk))\n",
    "            else:\n",
    "                recommended_healthy.append((pid, label, treat_time, recommended_risk))\n",
    "    \n",
    "    # 2) Sort recommended sick by descending risk_score\n",
    "    recommended_sick.sort(key=lambda x: x[3], reverse=True)\n",
    "    \n",
    "    # 3) Actually treat only top capacity_num from recommended_sick\n",
    "    treat_sick_subset = recommended_sick[:capacity_num]\n",
    "    not_treat_sick_subset = recommended_sick[capacity_num:]\n",
    "    \n",
    "    # 4) Treat all recommended healthy\n",
    "    treat_healthy_subset = recommended_healthy\n",
    "    \n",
    "    # Build final records for the \"treated\" subsets\n",
    "    treat_results = []\n",
    "    \n",
    "    # SICK actually treated\n",
    "    for (pid, label, ttime, rsk) in treat_sick_subset:\n",
    "        cost_ = D_COST * ttime   # sick => cost is D * ttime\n",
    "        treat_results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': 1,\n",
    "            'treat_time': ttime,\n",
    "            'cost': cost_,\n",
    "            'tp': 1,\n",
    "            'fp': 0\n",
    "        })\n",
    "    \n",
    "    # HEALTHY actually treated\n",
    "    for (pid, label, ttime, rsk) in treat_healthy_subset:\n",
    "        cost_ = FP_COST  # healthy => false positive cost\n",
    "        treat_results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': 1,\n",
    "            'treat_time': ttime,\n",
    "            'cost': cost_,\n",
    "            'tp': 0,\n",
    "            'fp': 1\n",
    "        })\n",
    "    \n",
    "    # Build final records for \"not-treated\" subsets\n",
    "    not_treat_results = []\n",
    "    \n",
    "    # recommended sick but not in top capacity\n",
    "    for (pid, label, ttime, rsk) in not_treat_sick_subset:\n",
    "        cost_ = FN_COST  # sick but not treated\n",
    "        not_treat_results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': 0,\n",
    "            'treat_time': None,\n",
    "            'cost': cost_,\n",
    "            'tp': 0,\n",
    "            'fp': 0\n",
    "        })\n",
    "    \n",
    "    # never recommended (cost=None above)\n",
    "    for row in results:\n",
    "        if row['cost'] is None:\n",
    "            if row['label'] == 1:\n",
    "                row['cost'] = FN_COST\n",
    "            else:\n",
    "                row['cost'] = 0\n",
    "            not_treat_results.append(row)\n",
    "    \n",
    "    # Combine\n",
    "    df_res = pd.DataFrame(treat_results + not_treat_results)\n",
    "    \n",
    "    # Compute final stats\n",
    "    total_cost = df_res['cost'].sum()\n",
    "    \n",
    "    treated_df = df_res[df_res['treated']==1]\n",
    "    tp_sum = treated_df['tp'].sum()\n",
    "    fp_sum = treated_df['fp'].sum()\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        precision = tp_sum / (tp_sum + fp_sum)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "    \n",
    "    sick_df = df_res[df_res['label']==1]\n",
    "    total_sick = len(sick_df)\n",
    "    if total_sick > 0:\n",
    "        recall = tp_sum / total_sick\n",
    "    else:\n",
    "        recall = 0.0\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        valid_tt = treated_df['treat_time'].dropna()\n",
    "        avg_tt   = valid_tt.mean() if len(valid_tt) > 0 else 0.0\n",
    "    else:\n",
    "        avg_tt = 0.0\n",
    "    \n",
    "    return {\n",
    "        'cost': total_cost,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'avg_treatment_time': avg_tt\n",
    "    }\n",
    "\n",
    "###############################################################################\n",
    "# 4. BENCHMARK POLICIES (Threshold-based, DP, etc.)\n",
    "###############################################################################\n",
    "def constant_threshold_search(df, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0,1,21)\n",
    "    best_thr, best_cost, best_stats = None, float('inf'), None\n",
    "    for thr in thresholds:\n",
    "        def policy_func(patient_rows):\n",
    "            for _, row in patient_rows.iterrows():\n",
    "                if row['risk_score'] >= thr:\n",
    "                    return int(row['time'])\n",
    "            return None\n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_thr  = thr\n",
    "            best_stats= stats\n",
    "    return best_thr, best_stats\n",
    "\n",
    "def make_constant_threshold_policy(thr):\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            if row['risk_score'] >= thr:\n",
    "                return int(row['time'])\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def dynamic_threshold_random_search(df,\n",
    "                                    time_steps=20,\n",
    "                                    threshold_candidates=[0.0,0.2,0.4,0.6,0.8,1.0],\n",
    "                                    n_samples=200,\n",
    "                                    seed=0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    best_vec = None\n",
    "    best_cost= float('inf')\n",
    "    best_stats=None\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        thr_vec = rng.choice(threshold_candidates, size=time_steps)\n",
    "        \n",
    "        def policy_func(patient_rows):\n",
    "            for _, row in patient_rows.iterrows():\n",
    "                t = int(row['time'])\n",
    "                if t < time_steps and row['risk_score'] >= thr_vec[t]:\n",
    "                    return t\n",
    "            return None\n",
    "        \n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_vec  = thr_vec.copy()\n",
    "            best_stats= stats\n",
    "    return best_vec, best_stats\n",
    "\n",
    "def make_dynamic_threshold_policy(thr_vec):\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = int(row['time'])\n",
    "            if t < len(thr_vec):\n",
    "                if row['risk_score'] >= thr_vec[t]:\n",
    "                    return t\n",
    "            return None\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def linear_threshold_search(df,\n",
    "                            A_candidates=np.linspace(-0.05, 0.01, 7),\n",
    "                            B_candidates=np.linspace(0,0.8,7)):\n",
    "    best_A, best_B = None, None\n",
    "    best_cost, best_stats = float('inf'), None\n",
    "    \n",
    "    for A in A_candidates:\n",
    "        for B in B_candidates:\n",
    "            def policy_func(patient_rows):\n",
    "                for _, row in patient_rows.iterrows():\n",
    "                    t = row['time']\n",
    "                    thr = A*t + B\n",
    "                    thr = np.clip(thr,0,1)\n",
    "                    if row['risk_score'] >= thr:\n",
    "                        return int(t)\n",
    "                return None\n",
    "            stats = simulate_policy(df, policy_func)\n",
    "            if stats['cost'] < best_cost:\n",
    "                best_cost = stats['cost']\n",
    "                best_A    = A\n",
    "                best_B    = B\n",
    "                best_stats= stats\n",
    "    return (best_A,best_B), best_stats\n",
    "\n",
    "def make_linear_threshold_policy(A,B):\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = row['time']\n",
    "            thr = A*t + B\n",
    "            thr = np.clip(thr,0,1)\n",
    "            if row['risk_score'] >= thr:\n",
    "                return int(t)\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def wait_till_end_search(df, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0,1,21)\n",
    "    best_thr, best_cost, best_stats = None, float('inf'), None\n",
    "    \n",
    "    for thr in thresholds:\n",
    "        def policy_func(patient_rows):\n",
    "            final_t = patient_rows['time'].max()\n",
    "            final_row = patient_rows[patient_rows['time']==final_t].iloc[0]\n",
    "            if final_row['risk_score'] >= thr:\n",
    "                return int(final_t)\n",
    "            return None\n",
    "        \n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_thr  = thr\n",
    "            best_stats= stats\n",
    "    return best_thr, best_stats\n",
    "\n",
    "def make_wait_till_end_policy(thr):\n",
    "    def policy_func(patient_rows):\n",
    "        final_t = patient_rows['time'].max()\n",
    "        final_row = patient_rows[patient_rows['time']==final_t].iloc[0]\n",
    "        if final_row['risk_score'] >= thr:\n",
    "            return int(final_t)\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "###############################################################################\n",
    "# 5. DATA-DRIVEN DP (Unconstrained)\n",
    "###############################################################################\n",
    "def to_bucket(prob):\n",
    "    \"\"\"Map a probability into a bucket [0..4].\"\"\"\n",
    "    b = int(prob * 5)\n",
    "    return min(b, 4)\n",
    "\n",
    "def estimate_transition_and_sick_probs(df_train, T=20, n_buckets=5):\n",
    "    transition_counts = np.zeros((T-1, n_buckets, n_buckets), dtype=float)\n",
    "    bucket_counts     = np.zeros((T, n_buckets), dtype=float)\n",
    "    sick_counts       = np.zeros((T, n_buckets), dtype=float)\n",
    "    \n",
    "    df_sorted = df_train.sort_values(['patient_id','time'])\n",
    "    for pid, grp in df_sorted.groupby('patient_id'):\n",
    "        grp = grp.sort_values('time')\n",
    "        rows= grp.to_dict('records')\n",
    "        \n",
    "        for i, row in enumerate(rows):\n",
    "            t = int(row['time'])\n",
    "            b = int(row['risk_bucket'])\n",
    "            lbl = row['label']\n",
    "            \n",
    "            if t < T:\n",
    "                bucket_counts[t,b] += 1\n",
    "                sick_counts[t,b]   += lbl\n",
    "            \n",
    "            if i < len(rows)-1:\n",
    "                nxt = rows[i+1]\n",
    "                t_next = nxt['time']\n",
    "                b_next = nxt['risk_bucket']\n",
    "                if (t_next == t+1) and (t < T-1):\n",
    "                    transition_counts[t,b,b_next] += 1\n",
    "    \n",
    "    p_trans = np.zeros((T-1, n_buckets, n_buckets), dtype=float)\n",
    "    for t_ in range(T-1):\n",
    "        for b_ in range(n_buckets):\n",
    "            denom = transition_counts[t_,b_,:].sum()\n",
    "            if denom > 0:\n",
    "                p_trans[t_,b_,:] = transition_counts[t_,b_,:] / denom\n",
    "            else:\n",
    "                p_trans[t_,b_,b_] = 1.0\n",
    "    \n",
    "    p_sick = np.zeros((T, n_buckets), dtype=float)\n",
    "    for t_ in range(T):\n",
    "        for b_ in range(n_buckets):\n",
    "            denom = bucket_counts[t_,b_]\n",
    "            if denom>0:\n",
    "                p_sick[t_,b_] = sick_counts[t_,b_] / denom\n",
    "            else:\n",
    "                p_sick[t_,b_] = 0.0\n",
    "    return p_trans, p_sick\n",
    "\n",
    "def train_data_driven_dp_unconstrained(p_trans, p_sick,\n",
    "                                       FP=10, FN=50, D=1,\n",
    "                                       gamma=0.99, T=20):\n",
    "    \"\"\"\n",
    "    Standard DP for unconstrained scenario:\n",
    "      V[t,b] = min( cost_treat_now, cost_wait )\n",
    "    \"\"\"\n",
    "    n_buckets = p_sick.shape[1]\n",
    "    V = np.zeros((T+1, n_buckets))\n",
    "    pi_ = np.zeros((T, n_buckets), dtype=int)\n",
    "    \n",
    "    # boundary at t=T\n",
    "    for b in range(n_buckets):\n",
    "        cost_treat   = p_sick[T-1,b]*(D*(T-1)) + (1-p_sick[T-1,b])*FP\n",
    "        cost_notreat = p_sick[T-1,b]*FN\n",
    "        V[T,b] = min(cost_treat, cost_notreat)\n",
    "    \n",
    "    # fill from T-1 down to 0\n",
    "    for t in reversed(range(T)):\n",
    "        for b in range(n_buckets):\n",
    "            # treat now\n",
    "            cost_treat = p_sick[t,b]*(D*t) + (1-p_sick[t,b])*FP\n",
    "            \n",
    "            # wait\n",
    "            if t == T-1:\n",
    "                cost_wait = gamma * V[T,b]\n",
    "            else:\n",
    "                exp_future = 0.0\n",
    "                for b_next in range(n_buckets):\n",
    "                    exp_future += p_trans[t,b,b_next]*V[t+1,b_next]\n",
    "                cost_wait = gamma * exp_future\n",
    "            \n",
    "            if cost_treat <= cost_wait:\n",
    "                V[t,b]   = cost_treat\n",
    "                pi_[t,b] = 1\n",
    "            else:\n",
    "                V[t,b]   = cost_wait\n",
    "                pi_[t,b] = 0\n",
    "    return V, pi_\n",
    "\n",
    "def make_dp_policy(V, pi_, T=20):\n",
    "    \"\"\"Return a policy function that treats if pi[t,b]==1 at time t.\"\"\"\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = int(row['time'])\n",
    "            if t < T:\n",
    "                b = int(row['risk_bucket'])\n",
    "                if pi_[t,b] == 1:\n",
    "                    return t\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "###############################################################################\n",
    "# 6. SPSA ALGORITHM + COST FUNCTION\n",
    "###############################################################################\n",
    "def train_and_select_best_model(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    (Reference from Algorithm 0)\n",
    "    Trains multiple models (RF, GB, CatBoost) over small hyperparam grids,\n",
    "    picks best by AUC.\n",
    "    \"\"\"\n",
    "    best_auc = -1.0\n",
    "    best_model = None\n",
    "    best_name  = None\n",
    "    \n",
    "    RF_PARAM_GRID = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [3, 5]\n",
    "    }\n",
    "    GB_PARAM_GRID = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 5]\n",
    "    }\n",
    "    CATBOOST_PARAM_GRID = {\n",
    "        'iterations': [50, 100],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'depth': [3, 5]\n",
    "    }\n",
    "    \n",
    "    for params in ParameterGrid(RF_PARAM_GRID):\n",
    "        rf = RandomForestClassifier(random_state=0, **params)\n",
    "        rf.fit(X_train, y_train)\n",
    "        val_prob = rf.predict_proba(X_val)[:,1]\n",
    "        auc_val  = compute_auc_score(y_val, val_prob)\n",
    "        if auc_val > best_auc:\n",
    "            best_auc   = auc_val\n",
    "            best_model = rf\n",
    "            best_name  = f\"RandomForest_{params}\"\n",
    "    \n",
    "    for params in ParameterGrid(GB_PARAM_GRID):\n",
    "        gb = GradientBoostingClassifier(random_state=0, **params)\n",
    "        gb.fit(X_train, y_train)\n",
    "        val_prob = gb.predict_proba(X_val)[:,1]\n",
    "        auc_val  = compute_auc_score(y_val, val_prob)\n",
    "        if auc_val > best_auc:\n",
    "            best_auc   = auc_val\n",
    "            best_model = gb\n",
    "            best_name  = f\"GradientBoosting_{params}\"\n",
    "    \n",
    "    for params in ParameterGrid(CATBOOST_PARAM_GRID):\n",
    "        cb = CatBoostClassifier(verbose=0, random_state=0, **params)\n",
    "        cb.fit(X_train, y_train)\n",
    "        val_prob = cb.predict_proba(X_val)[:,1]\n",
    "        auc_val  = compute_auc_score(y_val, val_prob)\n",
    "        if auc_val > best_auc:\n",
    "            best_auc   = auc_val\n",
    "            best_model = cb\n",
    "            best_name  = f\"CatBoost_{params}\"\n",
    "    \n",
    "    return best_model, best_auc, best_name\n",
    "\n",
    "def spsa_optimize(cost_func, param_init, n_iter=20,\n",
    "                  alpha=0.602, gamma=0.101, a=0.1, c=0.1, seed=0):\n",
    "    \"\"\"\n",
    "    Generic SPSA optimizer to minimize a cost_func over a real vector space.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    p = param_init.copy()\n",
    "    best_p = p.copy()\n",
    "    best_cost = cost_func(p)\n",
    "    \n",
    "    for k in range(1, n_iter+1):\n",
    "        ak = a / (k**alpha)\n",
    "        ck = c / (k**gamma)\n",
    "        delta = rng.choice([-1,1], size=len(p))\n",
    "        \n",
    "        p_plus  = p + ck*delta\n",
    "        p_minus = p - ck*delta\n",
    "        \n",
    "        cost_plus  = cost_func(p_plus)\n",
    "        cost_minus = cost_func(p_minus)\n",
    "        \n",
    "        g_approx = (cost_plus - cost_minus)/(2.0*ck) * delta\n",
    "        \n",
    "        p = p - ak*g_approx\n",
    "        \n",
    "        current_cost = cost_func(p)\n",
    "        if current_cost < best_cost:\n",
    "            best_cost = current_cost\n",
    "            best_p = p.copy()\n",
    "    \n",
    "    return best_p, best_cost\n",
    "\n",
    "def parse_spsa_params(params):\n",
    "    \"\"\"\n",
    "    Map a real vector `params` into discrete hyperparams + DP gamma:\n",
    "      params[0]: model_type (0=RF,1=GB,2=CB)\n",
    "      params[1]: n_estimators [10..200]\n",
    "      params[2]: learning_rate [0.01..0.2]\n",
    "      params[3]: max_depth [2..10]\n",
    "      params[4]: gamma [0.90..0.999]\n",
    "    \"\"\"\n",
    "    p0 = int(round(np.clip(params[0], 0, 2)))       # model_type\n",
    "    p1 = int(round(np.clip(params[1], 10, 200)))    # n_estimators\n",
    "    p2 = float(np.clip(params[2], 0.01, 0.2))       # learning_rate\n",
    "    p3 = int(round(np.clip(params[3], 2, 10)))      # max_depth\n",
    "    p4 = float(np.clip(params[4], 0.90, 0.999))      # gamma\n",
    "    return (p0, p1, p2, p3, p4)\n",
    "\n",
    "def spsa_cost_function(param_vector, df_train, df_val):\n",
    "    \"\"\"\n",
    "    Decision-aware cost function used by SPSA:\n",
    "      1) Parse param_vector => (model_type, n_estimators, learning_rate, max_depth, gamma)\n",
    "      2) Train model on df_train\n",
    "      3) Predict risk on df_val\n",
    "      4) Build DP with gamma (from param_vector) using transitions from df_train\n",
    "      5) Evaluate cost on df_val (unconstrained).\n",
    "    \"\"\"\n",
    "    model_type, n_est, lr, m_depth, gamma_ = parse_spsa_params(param_vector)\n",
    "\n",
    "    X_tr = df_train[['EIT','NIRS','EIS']].values\n",
    "    y_tr = df_train['label'].values\n",
    "    \n",
    "    # Build the model\n",
    "    if model_type == 0:\n",
    "        clf = RandomForestClassifier(n_estimators=n_est, max_depth=m_depth, random_state=0)\n",
    "    elif model_type == 1:\n",
    "        clf = GradientBoostingClassifier(n_estimators=n_est, learning_rate=lr,\n",
    "                                         max_depth=m_depth, random_state=0)\n",
    "    else:\n",
    "        clf = CatBoostClassifier(iterations=n_est, learning_rate=lr, depth=m_depth,\n",
    "                                 verbose=0, random_state=0)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Evaluate on df_val with DP policy\n",
    "    X_val = df_val[['EIT','NIRS','EIS']].values\n",
    "    prob_val = clf.predict_proba(X_val)[:,1]\n",
    "    df_val_ = df_val.copy()\n",
    "    df_val_['risk_score'] = prob_val\n",
    "    \n",
    "    # DP transitions from df_train\n",
    "    df_tr_ = df_train.copy()\n",
    "    train_probs = clf.predict_proba(df_tr_[['EIT','NIRS','EIS']])[:,1]\n",
    "    df_tr_['risk_score'] = train_probs\n",
    "    df_tr_['risk_bucket'] = df_tr_['risk_score'].apply(to_bucket)\n",
    "    \n",
    "    p_trans, p_sick = estimate_transition_and_sick_probs(df_tr_, T=T_MAX, n_buckets=5)\n",
    "    V, pi_ = train_data_driven_dp_unconstrained(\n",
    "        p_trans, p_sick,\n",
    "        FP=FP_COST, FN=FN_COST, D=D_COST,\n",
    "        gamma=gamma_, T=T_MAX\n",
    "    )\n",
    "    \n",
    "    # Evaluate that DP policy on df_val\n",
    "    df_val_['risk_bucket'] = df_val_['risk_score'].apply(to_bucket)\n",
    "    dp_policy = make_dp_policy(V, pi_, T=T_MAX)\n",
    "    stats = simulate_policy(df_val_, dp_policy)  # unconstrained cost\n",
    "    return stats['cost']\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 7. ALGORITHM 5 (SPSA) WITH 50% CAP ON FINAL HOLDOUT\n",
    "###############################################################################\n",
    "def run_algorithm5_spsa_with_capacity(df_all, k=3, seed=0, n_spsa_iter=20, capacity_frac=0.5):\n",
    "    \"\"\"\n",
    "    SPSA Hyper-Parameter Tuning (Decision-Aware) + 50% cap on final holdout.\n",
    "    \n",
    "    1) Split data into k+1 groups: G1..Gk, G_{k+1}\n",
    "    2) For each fold i in [1..k]:\n",
    "         - define cost function that trains on G\\\\G_i, evaluates cost on G_i\n",
    "         - run SPSA to find best param_i\n",
    "    3) Among param_1..param_k, pick best overall param* with minimal sum-of-costs across folds\n",
    "    4) Evaluate param* on G_{k+1} (the holdout),\n",
    "       but we apply the 50%-cap to *sick* patients in the final holdout only.\n",
    "    5) Build final table with 5 methods:\n",
    "       - Constant Threshold\n",
    "       - Dynamic Threshold-R\n",
    "       - Linear Threshold\n",
    "       - Wait Till End\n",
    "       - DP-based (SPSA)\n",
    "      and each one is simulated with the 50%-cap on sick.\n",
    "    \"\"\"\n",
    "    # Split into k+1 groups\n",
    "    groups = k_plus_1_splits(df_all, k=k, seed=seed)\n",
    "    \n",
    "    # param_init is the starting guess for SPSA hyperparams\n",
    "    param_init = np.array([1.0, 50.0, 0.05, 3.0, 0.95], dtype=float)\n",
    "    \n",
    "    # 2) For each fold i in [1..k], run SPSA to get best param_i\n",
    "    spsa_solutions = []\n",
    "    for i in range(1, k+1):\n",
    "        df_val = groups[i-1]\n",
    "        df_train_list = [groups[j] for j in range(k) if j != (i-1)]\n",
    "        df_train_ = pd.concat(df_train_list, ignore_index=True)\n",
    "        \n",
    "        def fold_cost_func(p):\n",
    "            return spsa_cost_function(p, df_train_, df_val)\n",
    "        \n",
    "        best_p_fold, best_c_fold = spsa_optimize(\n",
    "            fold_cost_func,\n",
    "            param_init,\n",
    "            n_iter=n_spsa_iter,\n",
    "            alpha=0.602,\n",
    "            gamma=0.101,\n",
    "            a=0.1,\n",
    "            c=0.1,\n",
    "            seed=seed+i\n",
    "        )\n",
    "        spsa_solutions.append( (best_p_fold, best_c_fold) )\n",
    "    \n",
    "    # 3) Among these k solutions, pick best overall param*\n",
    "    #    with minimal sum-of-costs across all k folds\n",
    "    k_ = k\n",
    "    fold_cost_matrix = np.zeros((k_, k_), dtype=float)\n",
    "    for i in range(k_):\n",
    "        param_i = spsa_solutions[i][0]\n",
    "        for j in range(k_):\n",
    "            df_val_j = groups[j]\n",
    "            df_train_j_list = [groups[m] for m in range(k_) if m != j]\n",
    "            df_train_j = pd.concat(df_train_j_list, ignore_index=True)\n",
    "            c_ij = spsa_cost_function(param_i, df_train_j, df_val_j)\n",
    "            fold_cost_matrix[i,j] = c_ij\n",
    "    \n",
    "    total_cost_per_param = fold_cost_matrix.sum(axis=1)\n",
    "    best_index = np.argmin(total_cost_per_param)\n",
    "    best_param = spsa_solutions[best_index][0]\n",
    "    \n",
    "    # 4) Evaluate best_param on final holdout G_{k+1}, with 50%-cap\n",
    "    df_holdout = groups[k]\n",
    "    df_train_for_holdout = pd.concat(groups[:k], ignore_index=True)\n",
    "    \n",
    "    # Parse best_param -> final ML model + DP discount factor\n",
    "    model_type, n_est, lr, m_depth, gamma_ = parse_spsa_params(best_param)\n",
    "    \n",
    "    # Train final classifier on union of k folds\n",
    "    X_train2 = df_train_for_holdout[['EIT','NIRS','EIS']].values\n",
    "    y_train2 = df_train_for_holdout['label'].values\n",
    "    \n",
    "    if model_type == 0:\n",
    "        clf_final = RandomForestClassifier(n_estimators=n_est, max_depth=m_depth, random_state=0)\n",
    "    elif model_type == 1:\n",
    "        clf_final = GradientBoostingClassifier(n_estimators=n_est, learning_rate=lr,\n",
    "                                               max_depth=m_depth, random_state=0)\n",
    "    else:\n",
    "        clf_final = CatBoostClassifier(iterations=n_est, learning_rate=lr, depth=m_depth,\n",
    "                                       verbose=0, random_state=0)\n",
    "    clf_final.fit(X_train2, y_train2)\n",
    "    \n",
    "    # Build DP transitions from df_train_for_holdout\n",
    "    df_train2 = df_train_for_holdout.copy()\n",
    "    train_probs2 = clf_final.predict_proba(df_train2[['EIT','NIRS','EIS']])[:,1]\n",
    "    df_train2['risk_score'] = train_probs2\n",
    "    df_train2['risk_bucket'] = df_train2['risk_score'].apply(to_bucket)\n",
    "    p_trans2, p_sick2 = estimate_transition_and_sick_probs(df_train2, T=T_MAX, n_buckets=5)\n",
    "    \n",
    "    V_final, pi_final = train_data_driven_dp_unconstrained(\n",
    "        p_trans2, p_sick2,\n",
    "        FP=FP_COST, FN=FN_COST, D=D_COST,\n",
    "        gamma=gamma_, T=T_MAX\n",
    "    )\n",
    "    dp_policy_final = make_dp_policy(V_final, pi_final, T=T_MAX)\n",
    "    \n",
    "    # 5) Tune threshold-based policies on the same train set (df_train2)\n",
    "    thr_const, _ = constant_threshold_search(df_train2)\n",
    "    thr_vec, _ = dynamic_threshold_random_search(df_train2, time_steps=T_MAX)\n",
    "    (A_lin, B_lin), _ = linear_threshold_search(df_train2)\n",
    "    thr_wte, _ = wait_till_end_search(df_train2)\n",
    "    \n",
    "    # Evaluate final policies on holdout with capacity\n",
    "    df_holdout2 = df_holdout.copy()\n",
    "    holdout_probs = clf_final.predict_proba(df_holdout2[['EIT','NIRS','EIS']])[:,1]\n",
    "    df_holdout2['risk_score'] = holdout_probs\n",
    "    \n",
    "    # 1) Constant threshold\n",
    "    pol_const = make_constant_threshold_policy(thr_const)\n",
    "    stats_const = simulate_policy_with_sick_capacity(df_holdout2, pol_const, capacity_frac=capacity_frac)\n",
    "    \n",
    "    # 2) Dynamic threshold - random\n",
    "    pol_dyn = make_dynamic_threshold_policy(thr_vec)\n",
    "    stats_dyn = simulate_policy_with_sick_capacity(df_holdout2, pol_dyn, capacity_frac=capacity_frac)\n",
    "    \n",
    "    # 3) Linear threshold\n",
    "    pol_lin = make_linear_threshold_policy(A_lin, B_lin)\n",
    "    stats_lin = simulate_policy_with_sick_capacity(df_holdout2, pol_lin, capacity_frac=capacity_frac)\n",
    "    \n",
    "    # 4) Wait till end\n",
    "    pol_wte = make_wait_till_end_policy(thr_wte)\n",
    "    stats_wte = simulate_policy_with_sick_capacity(df_holdout2, pol_wte, capacity_frac=capacity_frac)\n",
    "    \n",
    "    # 5) DP-based policy from SPSA\n",
    "    df_holdout2_dp = df_holdout2.copy()\n",
    "    df_holdout2_dp['risk_bucket'] = df_holdout2_dp['risk_score'].apply(to_bucket)\n",
    "    stats_dp = simulate_policy_with_sick_capacity(df_holdout2_dp, dp_policy_final,\n",
    "                                                  capacity_frac=capacity_frac)\n",
    "    \n",
    "    # Build final table\n",
    "    table = pd.DataFrame({\n",
    "        'Method': [\n",
    "            'Constant Threshold',\n",
    "            'Dynamic Threshold-R',\n",
    "            'Linear Threshold',\n",
    "            'Wait Till End',\n",
    "            'DP-based (SPSA)'\n",
    "        ],\n",
    "        'Cost': [\n",
    "            stats_const['cost'],\n",
    "            stats_dyn['cost'],\n",
    "            stats_lin['cost'],\n",
    "            stats_wte['cost'],\n",
    "            stats_dp['cost']\n",
    "        ],\n",
    "        'Precision (%)': [\n",
    "            100*stats_const['precision'],\n",
    "            100*stats_dyn['precision'],\n",
    "            100*stats_lin['precision'],\n",
    "            100*stats_wte['precision'],\n",
    "            100*stats_dp['precision']\n",
    "        ],\n",
    "        'Recall (%)': [\n",
    "            100*stats_const['recall'],\n",
    "            100*stats_dyn['recall'],\n",
    "            100*stats_lin['recall'],\n",
    "            100*stats_wte['recall'],\n",
    "            100*stats_dp['recall']\n",
    "        ],\n",
    "        'Avg Treat Time': [\n",
    "            stats_const['avg_treatment_time'],\n",
    "            stats_dyn['avg_treatment_time'],\n",
    "            stats_lin['avg_treatment_time'],\n",
    "            stats_wte['avg_treatment_time'],\n",
    "            stats_dp['avg_treatment_time']\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    return table\n",
    "\n",
    "###############################################################################\n",
    "# 8. MAIN\n",
    "###############################################################################\n",
    "def main():\n",
    "    # Load synthetic data\n",
    "    df_all = pd.read_csv(\"synthetic_patients_with_features.csv\")\n",
    "    \n",
    "    # Filter to time < T_MAX if needed\n",
    "    df_all = df_all[df_all['time'] < T_MAX].copy()\n",
    "    \n",
    "    # Check required columns\n",
    "    required = {'patient_id','time','EIT','NIRS','EIS','label'}\n",
    "    if not required.issubset(df_all.columns):\n",
    "        raise ValueError(f\"CSV must have columns at least: {required}. Found: {df_all.columns}\")\n",
    "    \n",
    "    # Run ALGORITHM 5 (SPSA) with 50%-cap in final holdout\n",
    "    table_alg5 = run_algorithm5_spsa_with_capacity(\n",
    "        df_all,\n",
    "        k=3,\n",
    "        seed=42,\n",
    "        n_spsa_iter=20,\n",
    "        capacity_frac=0.5\n",
    "    )\n",
    "    print(\"\\n=== ALGORITHM 5 (SPSA) + 50% CAP ON SICK, FINAL HOLDOUT ===\")\n",
    "    print(table_alg5.to_string(index=False))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1948361-3685-4fa4-a4d9-7563aee2cdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running replicate 1/30 (seed=412) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1043      43.750000   48.275862        3.562500\n",
      "Dynamic Threshold-R  1450       0.000000    0.000000        0.000000\n",
      "   Linear Threshold  1137      30.434783   48.275862        1.500000\n",
      "      Wait Till End  1040      93.333333   48.275862       20.000000\n",
      "    DP-based (SPSA)   905      82.352941   48.275862        8.529412\n",
      "\n",
      "=== Running replicate 2/30 (seed=413) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1149      32.558140   48.275862        2.558140\n",
      "Dynamic Threshold-R  1450       0.000000    0.000000        0.000000\n",
      "   Linear Threshold  1195      26.923077   48.275862        1.288462\n",
      "      Wait Till End  1030     100.000000   48.275862       20.000000\n",
      "    DP-based (SPSA)   874     100.000000   48.275862        8.857143\n",
      "\n",
      "=== Running replicate 3/30 (seed=414) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1071      51.724138   48.387097        4.517241\n",
      "Dynamic Threshold-R  1550       0.000000    0.000000        0.000000\n",
      "   Linear Threshold  1121      37.500000   48.387097        1.800000\n",
      "      Wait Till End  1100     100.000000   48.387097       20.000000\n",
      "    DP-based (SPSA)   968      78.947368   48.387097        8.894737\n",
      "\n",
      "=== Running replicate 4/30 (seed=415) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1080      40.540541        50.0        3.000000\n",
      "Dynamic Threshold-R  1500       0.000000         0.0        0.000000\n",
      "   Linear Threshold  1144      31.250000        50.0        1.479167\n",
      "      Wait Till End  1050     100.000000        50.0       20.000000\n",
      "    DP-based (SPSA)   932      75.000000        50.0        8.800000\n",
      "\n",
      "=== Running replicate 5/30 (seed=416) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1081      40.000000   48.275862        3.457143\n",
      "Dynamic Threshold-R  1450       0.000000    0.000000        0.000000\n",
      "   Linear Threshold  1207      26.923077   48.275862        1.500000\n",
      "      Wait Till End  1030     100.000000   48.275862       20.000000\n",
      "    DP-based (SPSA)   875      93.333333   48.275862        7.866667\n",
      "\n",
      "=== Running replicate 6/30 (seed=417) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1244      34.782609   48.484848        2.108696\n",
      "Dynamic Threshold-R  1650       0.000000    0.000000        0.000000\n",
      "   Linear Threshold  1244      34.782609   48.484848        2.108696\n",
      "      Wait Till End  1190      88.888889   48.484848       20.000000\n",
      "    DP-based (SPSA)   995     100.000000   48.484848        9.062500\n",
      "\n",
      "=== Running replicate 7/30 (seed=418) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold   964      36.363636        48.0        3.212121\n",
      "Dynamic Threshold-R  1250       0.000000         0.0        0.000000\n",
      "   Linear Threshold  1106      23.529412        48.0        1.705882\n",
      "      Wait Till End   920      80.000000        48.0       20.000000\n",
      "    DP-based (SPSA)   861      54.545455        48.0        9.818182\n",
      "\n",
      "=== Running replicate 8/30 (seed=419) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1233      35.555556        50.0        3.200000\n",
      "Dynamic Threshold-R  1600       0.000000         0.0        0.000000\n",
      "   Linear Threshold  1257      28.571429        50.0        1.035714\n",
      "      Wait Till End  1130      94.117647        50.0       20.000000\n",
      "    DP-based (SPSA)   918      94.117647        50.0        6.941176\n",
      "\n",
      "=== Running replicate 9/30 (seed=420) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1018      32.432432        48.0        3.189189\n",
      "Dynamic Threshold-R  1250       0.000000         0.0        0.000000\n",
      "   Linear Threshold  1143      21.818182        48.0        1.163636\n",
      "      Wait Till End   900      92.307692        48.0       20.000000\n",
      "    DP-based (SPSA)   793      85.714286        48.0       10.214286\n",
      "\n",
      "=== Running replicate 10/30 (seed=421) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1141      32.558140   48.275862        2.348837\n",
      "Dynamic Threshold-R  1450       0.000000    0.000000        0.000000\n",
      "   Linear Threshold  1215      25.925926   48.275862        1.203704\n",
      "      Wait Till End  1060      82.352941   48.275862       20.000000\n",
      "    DP-based (SPSA)   894      87.500000   48.275862        9.625000\n",
      "\n",
      "=== Running replicate 11/30 (seed=422) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1085      33.333333        50.0        2.571429\n",
      "Dynamic Threshold-R  1400       0.000000         0.0        0.000000\n",
      "   Linear Threshold  1206      25.454545        50.0        1.800000\n",
      "      Wait Till End   980     100.000000        50.0       20.000000\n",
      "    DP-based (SPSA)   864      70.000000        50.0        8.500000\n",
      "\n",
      "=== Running replicate 12/30 (seed=423) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1285      36.956522   48.571429        2.217391\n",
      "Dynamic Threshold-R  1750       0.000000    0.000000        0.000000\n",
      "   Linear Threshold  1353      31.481481   48.571429        1.666667\n",
      "      Wait Till End  1260      89.473684   48.571429       20.000000\n",
      "    DP-based (SPSA)  1072      77.272727   48.571429        7.681818\n",
      "\n",
      "=== Running replicate 13/30 (seed=424) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1292      51.351351        50.0        4.378378\n",
      "Dynamic Threshold-R  1900       0.000000         0.0        0.000000\n",
      "   Linear Threshold  1400      36.538462        50.0        2.346154\n",
      "      Wait Till End  1330     100.000000        50.0       20.000000\n",
      "    DP-based (SPSA)  1107     100.000000        50.0        8.263158\n",
      "\n",
      "=== Running replicate 14/30 (seed=425) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold   907      31.428571   47.826087        1.942857\n",
      "Dynamic Threshold-R  1150       0.000000    0.000000        0.000000\n",
      "   Linear Threshold   954      24.444444   47.826087        0.466667\n",
      "      Wait Till End   820     100.000000   47.826087       20.000000\n",
      "    DP-based (SPSA)   711      73.333333   47.826087        7.466667\n",
      "\n",
      "=== Running replicate 15/30 (seed=426) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1071      41.176471   48.275862        3.558824\n",
      "Dynamic Threshold-R  1450       0.000000    0.000000        0.000000\n",
      "   Linear Threshold  1160      28.000000   48.275862        1.020000\n",
      "      Wait Till End  1030     100.000000   48.275862       20.000000\n",
      "    DP-based (SPSA)   878      82.352941   48.275862        6.823529\n",
      "\n",
      "=== Running replicate 16/30 (seed=427) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1107      36.842105   48.275862        3.131579\n",
      "Dynamic Threshold-R  1450       0.000000    0.000000        0.000000\n",
      "   Linear Threshold  1193      27.450980   48.275862        1.470588\n",
      "      Wait Till End  1040      93.333333   48.275862       20.000000\n",
      "    DP-based (SPSA)   908      82.352941   48.275862        9.529412\n",
      "\n",
      "=== Running replicate 17/30 (seed=428) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold   909      44.444444        48.0        4.074074\n",
      "Dynamic Threshold-R  1250       0.000000         0.0        0.000000\n",
      "   Linear Threshold   996      29.268293        48.0        1.512195\n",
      "      Wait Till End   890     100.000000        48.0       20.000000\n",
      "    DP-based (SPSA)   788      66.666667        48.0        5.000000\n",
      "\n",
      "=== Running replicate 18/30 (seed=429) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1192      41.025641   48.484848        2.871795\n",
      "Dynamic Threshold-R  1650       0.000000    0.000000        0.000000\n",
      "   Linear Threshold  1269      30.769231   48.484848        1.134615\n",
      "      Wait Till End  1170     100.000000   48.484848       20.000000\n",
      "    DP-based (SPSA)   997     100.000000   48.484848        9.187500\n",
      "\n",
      "=== Running replicate 19/30 (seed=430) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold   899      40.000000        48.0        2.300000\n",
      "Dynamic Threshold-R  1250       0.000000         0.0        0.000000\n",
      "   Linear Threshold  1035      26.086957        48.0        1.000000\n",
      "      Wait Till End   890     100.000000        48.0       20.000000\n",
      "    DP-based (SPSA)   766      85.714286        48.0        8.285714\n",
      "\n",
      "=== Running replicate 20/30 (seed=431) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1081      48.484848        50.0        3.363636\n",
      "Dynamic Threshold-R  1600       0.000000         0.0        0.000000\n",
      "   Linear Threshold  1212      33.333333        50.0        1.979167\n",
      "      Wait Till End  1120     100.000000        50.0       20.000000\n",
      "    DP-based (SPSA)   972      88.888889        50.0        8.666667\n",
      "\n",
      "=== Running replicate 21/30 (seed=432) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1249      36.170213        50.0        2.148936\n",
      "Dynamic Threshold-R  1700       0.000000         0.0        0.000000\n",
      "   Linear Threshold  1253      34.693878        50.0        2.510204\n",
      "      Wait Till End  1200      94.444444        50.0       20.000000\n",
      "    DP-based (SPSA)  1039      94.444444        50.0       10.500000\n",
      "\n",
      "=== Running replicate 22/30 (seed=433) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1283      48.648649   48.648649        3.891892\n",
      "Dynamic Threshold-R  1850       0.000000    0.000000        0.000000\n",
      "   Linear Threshold  1338      36.000000   48.648649        1.380000\n",
      "      Wait Till End  1310     100.000000   48.648649       20.000000\n",
      "    DP-based (SPSA)  1091      75.000000   48.648649        5.958333\n",
      "\n",
      "=== Running replicate 23/30 (seed=434) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1085      36.842105   48.275862        2.526316\n",
      "Dynamic Threshold-R  1450       0.000000    0.000000        0.000000\n",
      "   Linear Threshold  1250      25.000000   48.275862        1.517857\n",
      "      Wait Till End  1040      93.333333   48.275862       20.000000\n",
      "    DP-based (SPSA)   914      77.777778   48.275862        8.055556\n",
      "\n",
      "=== Running replicate 24/30 (seed=435) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1068      31.707317   48.148148        2.170732\n",
      "Dynamic Threshold-R  1350       0.000000    0.000000        0.000000\n",
      "   Linear Threshold  1128      26.000000   48.148148        1.200000\n",
      "      Wait Till End   970      92.857143   48.148148       20.000000\n",
      "    DP-based (SPSA)   835      86.666667   48.148148        7.933333\n",
      "\n",
      "=== Running replicate 25/30 (seed=436) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1279      37.777778        50.0        3.311111\n",
      "Dynamic Threshold-R  1700       0.000000         0.0        0.000000\n",
      "   Linear Threshold  1289      30.357143        50.0        0.875000\n",
      "      Wait Till End  1230      80.952381        50.0       20.000000\n",
      "    DP-based (SPSA)   991      89.473684        50.0        8.368421\n",
      "\n",
      "=== Running replicate 26/30 (seed=437) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1314      51.351351        50.0        4.972973\n",
      "Dynamic Threshold-R  1900       0.000000         0.0        0.000000\n",
      "   Linear Threshold  1355      36.538462        50.0        1.519231\n",
      "      Wait Till End  1330     100.000000        50.0       20.000000\n",
      "    DP-based (SPSA)  1147      90.476190        50.0        8.619048\n",
      "\n",
      "=== Running replicate 27/30 (seed=438) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1175      42.105263   48.484848        2.763158\n",
      "Dynamic Threshold-R  1650       0.000000    0.000000        0.000000\n",
      "   Linear Threshold  1353      26.666667   48.484848        1.116667\n",
      "      Wait Till End  1170     100.000000   48.484848       20.000000\n",
      "    DP-based (SPSA)  1015      84.210526   48.484848        8.789474\n",
      "\n",
      "=== Running replicate 28/30 (seed=439) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1124       32.55814        50.0        3.139535\n",
      "Dynamic Threshold-R  1400        0.00000         0.0        0.000000\n",
      "   Linear Threshold  1192       25.00000        50.0        1.339286\n",
      "      Wait Till End   980      100.00000        50.0       20.000000\n",
      "    DP-based (SPSA)   848       87.50000        50.0        9.250000\n",
      "\n",
      "=== Running replicate 29/30 (seed=440) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1144      47.058824        50.0        4.823529\n",
      "Dynamic Threshold-R  1600       0.000000         0.0        0.000000\n",
      "   Linear Threshold  1228      30.769231        50.0        1.346154\n",
      "      Wait Till End  1130      94.117647        50.0       20.000000\n",
      "    DP-based (SPSA)   962      94.117647        50.0        9.764706\n",
      "\n",
      "=== Running replicate 30/30 (seed=441) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1053      72.727273        50.0        8.772727\n",
      "Dynamic Threshold-R  1600       0.000000         0.0        0.000000\n",
      "   Linear Threshold  1280      29.090909        50.0        2.127273\n",
      "      Wait Till End  1130      94.117647        50.0       20.000000\n",
      "    DP-based (SPSA)   975      88.888889        50.0        8.888889\n",
      "\n",
      "=============================\n",
      "FINAL SUMMARY ACROSS REPLICATES\n",
      "=============================\n",
      "             Method   Cost_mean   Cost_std  Precision (%)_mean  Precision (%)_std  Recall (%)_mean  Recall (%)_std  Avg Treat Time_mean  Avg Treat Time_std\n",
      " Constant Threshold 1120.866667 117.414307           40.741846           8.722593          48.8989        0.869931             3.336158            1.313770\n",
      "    DP-based (SPSA)  929.833333 103.828467           84.888288          10.693100          48.8989        0.869931             8.471378            1.193462\n",
      "Dynamic Threshold-R 1521.666667 195.943048            0.000000           0.000000           0.0000        0.000000             0.000000            0.000000\n",
      "   Linear Threshold 1207.100000 105.192549           29.353417           4.269690          48.8989        0.869931             1.470433            0.446849\n",
      "      Wait Till End 1082.333333 134.975945           95.454337           6.065149          48.8989        0.869931            20.000000            0.000000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ALGORITHM 5 (SPSA) + BENCHMARK TABLE\n",
    "WITH 50% CAP ON SICK PATIENTS -- RUNNING MULTIPLE REPLICATES.\n",
    "\n",
    "Requirements:\n",
    "  pip install numpy pandas scikit-learn catboost\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Sklearn models, metrics, etc.\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "# CatBoost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "###############################################################################\n",
    "# 1. GLOBAL PARAMETERS\n",
    "###############################################################################\n",
    "FP_COST = 10\n",
    "FN_COST = 50\n",
    "D_COST  = 1\n",
    "T_MAX   = 21   # maximum discrete time steps (0..T_MAX-1)\n",
    "\n",
    "###############################################################################\n",
    "# 2. HELPER FUNCTIONS\n",
    "###############################################################################\n",
    "def split_into_four_groups(df, seed=0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    unique_pids = df['patient_id'].unique()\n",
    "    rng.shuffle(unique_pids)\n",
    "    \n",
    "    n = len(unique_pids)\n",
    "    i1 = int(0.25 * n)\n",
    "    i2 = int(0.50 * n)\n",
    "    i3 = int(0.75 * n)\n",
    "    \n",
    "    G1_pids = unique_pids[: i1]\n",
    "    G2_pids = unique_pids[i1 : i2]\n",
    "    G3_pids = unique_pids[i2 : i3]\n",
    "    G4_pids = unique_pids[i3 : ]\n",
    "    \n",
    "    G1 = df[df['patient_id'].isin(G1_pids)].copy()\n",
    "    G2 = df[df['patient_id'].isin(G2_pids)].copy()\n",
    "    G3 = df[df['patient_id'].isin(G3_pids)].copy()\n",
    "    G4 = df[df['patient_id'].isin(G4_pids)].copy()\n",
    "    return G1, G2, G3, G4\n",
    "\n",
    "def k_plus_1_splits(df, k=3, seed=0):\n",
    "    \"\"\"\n",
    "    For Algorithm 5 (SPSA), we often split the data into k+1 groups:\n",
    "      G1, G2, ..., Gk, G_{k+1}.\n",
    "    This is a k-fold style partition plus one final holdout.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    unique_pids = df['patient_id'].unique()\n",
    "    rng.shuffle(unique_pids)\n",
    "    \n",
    "    n = len(unique_pids)\n",
    "    fold_size = int(n/(k+1))\n",
    "    \n",
    "    groups = []\n",
    "    start = 0\n",
    "    for i in range(k):\n",
    "        pids_fold = unique_pids[start : start+fold_size]\n",
    "        start += fold_size\n",
    "        g = df[df['patient_id'].isin(pids_fold)].copy()\n",
    "        groups.append(g)\n",
    "    \n",
    "    # final group is everything leftover\n",
    "    pids_fold = unique_pids[start:]\n",
    "    g = df[df['patient_id'].isin(pids_fold)].copy()\n",
    "    groups.append(g)\n",
    "    return groups\n",
    "\n",
    "def compute_auc_score(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return 0.5\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "###############################################################################\n",
    "# 3. POLICY SIMULATION (WITH & WITHOUT CAPACITY)\n",
    "###############################################################################\n",
    "def simulate_policy(df, policy_func):\n",
    "    \"\"\"\n",
    "    Unconstrained simulation (no limit on how many sick get treated).\n",
    "    df must have columns: patient_id, time, risk_score, label.\n",
    "    policy_func(patient_rows) -> treat_time (int) or None\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for pid, grp in df.groupby('patient_id'):\n",
    "        grp = grp.sort_values('time')\n",
    "        label = grp['label'].iloc[0]\n",
    "        \n",
    "        treat_time = policy_func(grp)\n",
    "        \n",
    "        if treat_time is None:\n",
    "            # never treated\n",
    "            if label == 1:\n",
    "                cost = FN_COST\n",
    "                tp   = 0\n",
    "            else:\n",
    "                cost = 0\n",
    "                tp   = 0\n",
    "            fp = 0\n",
    "            treat_flag = 0\n",
    "            ttime = None\n",
    "        else:\n",
    "            treat_flag = 1\n",
    "            if label == 1:\n",
    "                cost = D_COST * treat_time\n",
    "                tp   = 1\n",
    "                fp   = 0\n",
    "            else:\n",
    "                cost = FP_COST\n",
    "                tp   = 0\n",
    "                fp   = 1\n",
    "            ttime = treat_time\n",
    "        \n",
    "        results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': treat_flag,\n",
    "            'treat_time': ttime,\n",
    "            'cost': cost,\n",
    "            'tp': tp,\n",
    "            'fp': fp\n",
    "        })\n",
    "    \n",
    "    df_res     = pd.DataFrame(results)\n",
    "    total_cost = df_res['cost'].sum()\n",
    "    \n",
    "    treated_df = df_res[df_res['treated']==1]\n",
    "    tp_sum = treated_df['tp'].sum()\n",
    "    fp_sum = treated_df['fp'].sum()\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        precision = tp_sum / (tp_sum + fp_sum)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "    \n",
    "    sick_df = df_res[df_res['label']==1]\n",
    "    total_sick = len(sick_df)\n",
    "    if total_sick > 0:\n",
    "        recall = tp_sum / total_sick\n",
    "    else:\n",
    "        recall = 0.0\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        valid_tt = treated_df['treat_time'].dropna()\n",
    "        avg_tt   = valid_tt.mean() if len(valid_tt) > 0 else 0.0\n",
    "    else:\n",
    "        avg_tt = 0.0\n",
    "    \n",
    "    return {\n",
    "        'cost': total_cost,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'avg_treatment_time': avg_tt\n",
    "    }\n",
    "\n",
    "\n",
    "def simulate_policy_with_sick_capacity(df, policy_func, capacity_frac=0.5):\n",
    "    \"\"\"\n",
    "    Enforce that at most (capacity_frac) fraction of the *sick* patients\n",
    "    can be treated (as in Algorithm 0 for G4).\n",
    "    \n",
    "    Steps:\n",
    "      1. Identify which patients are \"recommended\" for treatment by the policy_func.\n",
    "      2. Separate them into recommended_sick vs. recommended_healthy.\n",
    "      3. Among recommended_sick, only treat the top floor(capacity_frac * total_sick) \n",
    "         by risk_score. The rest remain untreated.\n",
    "      4. All recommended_healthy are treated (no limit).\n",
    "      5. Everyone else is not treated, incurring FN cost if sick, 0 if healthy.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    recommended_sick = []     # (pid, label=1, time_treated, risk_score)\n",
    "    recommended_healthy = []  # (pid, label=0, time_treated, risk_score)\n",
    "    \n",
    "    # 1) Count total sick\n",
    "    all_sick_df = df[df['label']==1]\n",
    "    num_sick = all_sick_df['patient_id'].nunique()\n",
    "    capacity_num = int(np.floor(capacity_frac * num_sick)) if num_sick>0 else 0\n",
    "    \n",
    "    # Gather recommended patients\n",
    "    for pid, grp in df.groupby('patient_id'):\n",
    "        grp = grp.sort_values('time')\n",
    "        label = grp['label'].iloc[0]\n",
    "        \n",
    "        treat_time = policy_func(grp)\n",
    "        \n",
    "        if treat_time is None:\n",
    "            # not recommended -> fill cost later\n",
    "            results.append({\n",
    "                'patient_id': pid,\n",
    "                'label': label,\n",
    "                'treated': 0,\n",
    "                'treat_time': None,\n",
    "                'cost': None,\n",
    "                'tp': 0,\n",
    "                'fp': 0\n",
    "            })\n",
    "        else:\n",
    "            # recommended\n",
    "            row_t = grp[grp['time']==treat_time].iloc[0]\n",
    "            recommended_risk = row_t['risk_score']\n",
    "            if label == 1:\n",
    "                recommended_sick.append((pid, label, treat_time, recommended_risk))\n",
    "            else:\n",
    "                recommended_healthy.append((pid, label, treat_time, recommended_risk))\n",
    "    \n",
    "    # 2) Sort recommended sick by descending risk_score\n",
    "    recommended_sick.sort(key=lambda x: x[3], reverse=True)\n",
    "    \n",
    "    # 3) Actually treat only top capacity_num from recommended_sick\n",
    "    treat_sick_subset = recommended_sick[:capacity_num]\n",
    "    not_treat_sick_subset = recommended_sick[capacity_num:]\n",
    "    \n",
    "    # 4) Treat all recommended healthy\n",
    "    treat_healthy_subset = recommended_healthy\n",
    "    \n",
    "    # Build final records for the \"treated\" subsets\n",
    "    treat_results = []\n",
    "    \n",
    "    # SICK actually treated\n",
    "    for (pid, label, ttime, rsk) in treat_sick_subset:\n",
    "        cost_ = D_COST * ttime   # sick => cost is D * ttime\n",
    "        treat_results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': 1,\n",
    "            'treat_time': ttime,\n",
    "            'cost': cost_,\n",
    "            'tp': 1,\n",
    "            'fp': 0\n",
    "        })\n",
    "    \n",
    "    # HEALTHY actually treated\n",
    "    for (pid, label, ttime, rsk) in treat_healthy_subset:\n",
    "        cost_ = FP_COST  # healthy => false positive cost\n",
    "        treat_results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': 1,\n",
    "            'treat_time': ttime,\n",
    "            'cost': cost_,\n",
    "            'tp': 0,\n",
    "            'fp': 1\n",
    "        })\n",
    "    \n",
    "    # Build final records for \"not-treated\" subsets\n",
    "    not_treat_results = []\n",
    "    \n",
    "    # recommended sick but not in top capacity\n",
    "    for (pid, label, ttime, rsk) in not_treat_sick_subset:\n",
    "        cost_ = FN_COST  # sick but not treated\n",
    "        not_treat_results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': 0,\n",
    "            'treat_time': None,\n",
    "            'cost': cost_,\n",
    "            'tp': 0,\n",
    "            'fp': 0\n",
    "        })\n",
    "    \n",
    "    # never recommended (cost=None above)\n",
    "    for row in results:\n",
    "        if row['cost'] is None:\n",
    "            if row['label'] == 1:\n",
    "                row['cost'] = FN_COST\n",
    "            else:\n",
    "                row['cost'] = 0\n",
    "            not_treat_results.append(row)\n",
    "    \n",
    "    # Combine\n",
    "    df_res = pd.DataFrame(treat_results + not_treat_results)\n",
    "    \n",
    "    # Compute final stats\n",
    "    total_cost = df_res['cost'].sum()\n",
    "    \n",
    "    treated_df = df_res[df_res['treated']==1]\n",
    "    tp_sum = treated_df['tp'].sum()\n",
    "    fp_sum = treated_df['fp'].sum()\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        precision = tp_sum / (tp_sum + fp_sum)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "    \n",
    "    sick_df = df_res[df_res['label']==1]\n",
    "    total_sick = len(sick_df)\n",
    "    if total_sick > 0:\n",
    "        recall = tp_sum / total_sick\n",
    "    else:\n",
    "        recall = 0.0\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        valid_tt = treated_df['treat_time'].dropna()\n",
    "        avg_tt   = valid_tt.mean() if len(valid_tt) > 0 else 0.0\n",
    "    else:\n",
    "        avg_tt = 0.0\n",
    "    \n",
    "    return {\n",
    "        'cost': total_cost,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'avg_treatment_time': avg_tt\n",
    "    }\n",
    "\n",
    "###############################################################################\n",
    "# 4. BENCHMARK POLICIES (Threshold-based, DP, etc.)\n",
    "###############################################################################\n",
    "def constant_threshold_search(df, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0,1,21)\n",
    "    best_thr, best_cost, best_stats = None, float('inf'), None\n",
    "    for thr in thresholds:\n",
    "        def policy_func(patient_rows):\n",
    "            for _, row in patient_rows.iterrows():\n",
    "                if row['risk_score'] >= thr:\n",
    "                    return int(row['time'])\n",
    "            return None\n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_thr  = thr\n",
    "            best_stats= stats\n",
    "    return best_thr, best_stats\n",
    "\n",
    "def make_constant_threshold_policy(thr):\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            if row['risk_score'] >= thr:\n",
    "                return int(row['time'])\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def dynamic_threshold_random_search(df,\n",
    "                                    time_steps=20,\n",
    "                                    threshold_candidates=[0.0,0.2,0.4,0.6,0.8,1.0],\n",
    "                                    n_samples=200,\n",
    "                                    seed=0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    best_vec = None\n",
    "    best_cost= float('inf')\n",
    "    best_stats=None\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        thr_vec = rng.choice(threshold_candidates, size=time_steps)\n",
    "        \n",
    "        def policy_func(patient_rows):\n",
    "            for _, row in patient_rows.iterrows():\n",
    "                t = int(row['time'])\n",
    "                if t < time_steps and row['risk_score'] >= thr_vec[t]:\n",
    "                    return t\n",
    "            return None\n",
    "        \n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_vec  = thr_vec.copy()\n",
    "            best_stats= stats\n",
    "    return best_vec, best_stats\n",
    "\n",
    "def make_dynamic_threshold_policy(thr_vec):\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = int(row['time'])\n",
    "            if t < len(thr_vec):\n",
    "                if row['risk_score'] >= thr_vec[t]:\n",
    "                    return t\n",
    "            return None\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def linear_threshold_search(df,\n",
    "                            A_candidates=np.linspace(-0.05, 0.01, 7),\n",
    "                            B_candidates=np.linspace(0,0.8,7)):\n",
    "    best_A, best_B = None, None\n",
    "    best_cost, best_stats = float('inf'), None\n",
    "    \n",
    "    for A in A_candidates:\n",
    "        for B in B_candidates:\n",
    "            def policy_func(patient_rows):\n",
    "                for _, row in patient_rows.iterrows():\n",
    "                    t = row['time']\n",
    "                    thr = A*t + B\n",
    "                    thr = np.clip(thr,0,1)\n",
    "                    if row['risk_score'] >= thr:\n",
    "                        return int(t)\n",
    "                return None\n",
    "            stats = simulate_policy(df, policy_func)\n",
    "            if stats['cost'] < best_cost:\n",
    "                best_cost = stats['cost']\n",
    "                best_A    = A\n",
    "                best_B    = B\n",
    "                best_stats= stats\n",
    "    return (best_A,best_B), best_stats\n",
    "\n",
    "def make_linear_threshold_policy(A,B):\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = row['time']\n",
    "            thr = A*t + B\n",
    "            thr = np.clip(thr,0,1)\n",
    "            if row['risk_score'] >= thr:\n",
    "                return int(t)\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def wait_till_end_search(df, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0,1,21)\n",
    "    best_thr, best_cost, best_stats = None, float('inf'), None\n",
    "    \n",
    "    for thr in thresholds:\n",
    "        def policy_func(patient_rows):\n",
    "            final_t = patient_rows['time'].max()\n",
    "            final_row = patient_rows[patient_rows['time']==final_t].iloc[0]\n",
    "            if final_row['risk_score'] >= thr:\n",
    "                return int(final_t)\n",
    "            return None\n",
    "        \n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_thr  = thr\n",
    "            best_stats= stats\n",
    "    return best_thr, best_stats\n",
    "\n",
    "def make_wait_till_end_policy(thr):\n",
    "    def policy_func(patient_rows):\n",
    "        final_t = patient_rows['time'].max()\n",
    "        final_row = patient_rows[patient_rows['time']==final_t].iloc[0]\n",
    "        if final_row['risk_score'] >= thr:\n",
    "            return int(final_t)\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "###############################################################################\n",
    "# 5. DATA-DRIVEN DP (Unconstrained)\n",
    "###############################################################################\n",
    "def to_bucket(prob):\n",
    "    \"\"\"Map a probability into a bucket [0..4].\"\"\"\n",
    "    b = int(prob * 5)\n",
    "    return min(b, 4)\n",
    "\n",
    "def estimate_transition_and_sick_probs(df_train, T=20, n_buckets=5):\n",
    "    transition_counts = np.zeros((T-1, n_buckets, n_buckets), dtype=float)\n",
    "    bucket_counts     = np.zeros((T, n_buckets), dtype=float)\n",
    "    sick_counts       = np.zeros((T, n_buckets), dtype=float)\n",
    "    \n",
    "    df_sorted = df_train.sort_values(['patient_id','time'])\n",
    "    for pid, grp in df_sorted.groupby('patient_id'):\n",
    "        grp = grp.sort_values('time')\n",
    "        rows= grp.to_dict('records')\n",
    "        \n",
    "        for i, row in enumerate(rows):\n",
    "            t = int(row['time'])\n",
    "            b = int(row['risk_bucket'])\n",
    "            lbl = row['label']\n",
    "            \n",
    "            if t < T:\n",
    "                bucket_counts[t,b] += 1\n",
    "                sick_counts[t,b]   += lbl\n",
    "            \n",
    "            if i < len(rows)-1:\n",
    "                nxt = rows[i+1]\n",
    "                t_next = nxt['time']\n",
    "                b_next = nxt['risk_bucket']\n",
    "                if (t_next == t+1) and (t < T-1):\n",
    "                    transition_counts[t,b,b_next] += 1\n",
    "    \n",
    "    p_trans = np.zeros((T-1, n_buckets, n_buckets), dtype=float)\n",
    "    for t_ in range(T-1):\n",
    "        for b_ in range(n_buckets):\n",
    "            denom = transition_counts[t_,b_,:].sum()\n",
    "            if denom > 0:\n",
    "                p_trans[t_,b_,:] = transition_counts[t_,b_,:] / denom\n",
    "            else:\n",
    "                p_trans[t_,b_,b_] = 1.0\n",
    "    \n",
    "    p_sick = np.zeros((T, n_buckets), dtype=float)\n",
    "    for t_ in range(T):\n",
    "        for b_ in range(n_buckets):\n",
    "            denom = bucket_counts[t_,b_]\n",
    "            if denom>0:\n",
    "                p_sick[t_,b_] = sick_counts[t_,b_] / denom\n",
    "            else:\n",
    "                p_sick[t_,b_] = 0.0\n",
    "    return p_trans, p_sick\n",
    "\n",
    "def train_data_driven_dp_unconstrained(p_trans, p_sick,\n",
    "                                       FP=10, FN=50, D=1,\n",
    "                                       gamma=0.99, T=20):\n",
    "    \"\"\"\n",
    "    Standard DP for unconstrained scenario:\n",
    "      V[t,b] = min( cost_treat_now, cost_wait )\n",
    "    \"\"\"\n",
    "    n_buckets = p_sick.shape[1]\n",
    "    V = np.zeros((T+1, n_buckets))\n",
    "    pi_ = np.zeros((T, n_buckets), dtype=int)\n",
    "    \n",
    "    # boundary at t=T\n",
    "    for b in range(n_buckets):\n",
    "        cost_treat   = p_sick[T-1,b]*(D*(T-1)) + (1-p_sick[T-1,b])*FP\n",
    "        cost_notreat = p_sick[T-1,b]*FN\n",
    "        V[T,b] = min(cost_treat, cost_notreat)\n",
    "    \n",
    "    # fill from T-1 down to 0\n",
    "    for t in reversed(range(T)):\n",
    "        for b in range(n_buckets):\n",
    "            # treat now\n",
    "            cost_treat = p_sick[t,b]*(D*t) + (1-p_sick[t,b])*FP\n",
    "            \n",
    "            # wait\n",
    "            if t == T-1:\n",
    "                cost_wait = gamma * V[T,b]\n",
    "            else:\n",
    "                exp_future = 0.0\n",
    "                for b_next in range(n_buckets):\n",
    "                    exp_future += p_trans[t,b,b_next]*V[t+1,b_next]\n",
    "                cost_wait = gamma * exp_future\n",
    "            \n",
    "            if cost_treat <= cost_wait:\n",
    "                V[t,b]   = cost_treat\n",
    "                pi_[t,b] = 1\n",
    "            else:\n",
    "                V[t,b]   = cost_wait\n",
    "                pi_[t,b] = 0\n",
    "    return V, pi_\n",
    "\n",
    "def make_dp_policy(V, pi_, T=20):\n",
    "    \"\"\"Return a policy function that treats if pi[t,b]==1 at time t.\"\"\"\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = int(row['time'])\n",
    "            if t < T:\n",
    "                b = int(row['risk_bucket'])\n",
    "                if pi_[t,b] == 1:\n",
    "                    return t\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "###############################################################################\n",
    "# 6. SPSA ALGORITHM + COST FUNCTION\n",
    "###############################################################################\n",
    "def train_and_select_best_model(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    (Reference from Algorithm 0)\n",
    "    Trains multiple models (RF, GB, CatBoost) over small hyperparam grids,\n",
    "    picks best by AUC.\n",
    "    \"\"\"\n",
    "    best_auc = -1.0\n",
    "    best_model = None\n",
    "    best_name  = None\n",
    "    \n",
    "    RF_PARAM_GRID = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [3, 5]\n",
    "    }\n",
    "    GB_PARAM_GRID = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 5]\n",
    "    }\n",
    "    CATBOOST_PARAM_GRID = {\n",
    "        'iterations': [50, 100],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'depth': [3, 5]\n",
    "    }\n",
    "    \n",
    "    for params in ParameterGrid(RF_PARAM_GRID):\n",
    "        rf = RandomForestClassifier(random_state=0, **params)\n",
    "        rf.fit(X_train, y_train)\n",
    "        val_prob = rf.predict_proba(X_val)[:,1]\n",
    "        auc_val  = compute_auc_score(y_val, val_prob)\n",
    "        if auc_val > best_auc:\n",
    "            best_auc   = auc_val\n",
    "            best_model = rf\n",
    "            best_name  = f\"RandomForest_{params}\"\n",
    "    \n",
    "    for params in ParameterGrid(GB_PARAM_GRID):\n",
    "        gb = GradientBoostingClassifier(random_state=0, **params)\n",
    "        gb.fit(X_train, y_train)\n",
    "        val_prob = gb.predict_proba(X_val)[:,1]\n",
    "        auc_val  = compute_auc_score(y_val, val_prob)\n",
    "        if auc_val > best_auc:\n",
    "            best_auc   = auc_val\n",
    "            best_model = gb\n",
    "            best_name  = f\"GradientBoosting_{params}\"\n",
    "    \n",
    "    for params in ParameterGrid(CATBOOST_PARAM_GRID):\n",
    "        cb = CatBoostClassifier(verbose=0, random_state=0, **params)\n",
    "        cb.fit(X_train, y_train)\n",
    "        val_prob = cb.predict_proba(X_val)[:,1]\n",
    "        auc_val  = compute_auc_score(y_val, val_prob)\n",
    "        if auc_val > best_auc:\n",
    "            best_auc   = auc_val\n",
    "            best_model = cb\n",
    "            best_name  = f\"CatBoost_{params}\"\n",
    "    \n",
    "    return best_model, best_auc, best_name\n",
    "\n",
    "def spsa_optimize(cost_func, param_init, n_iter=20,\n",
    "                  alpha=0.602, gamma=0.101, a=0.1, c=0.1, seed=0):\n",
    "    \"\"\"\n",
    "    Generic SPSA optimizer to minimize a cost_func over a real vector space.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    p = param_init.copy()\n",
    "    best_p = p.copy()\n",
    "    best_cost = cost_func(p)\n",
    "    \n",
    "    for k in range(1, n_iter+1):\n",
    "        ak = a / (k**alpha)\n",
    "        ck = c / (k**gamma)\n",
    "        delta = rng.choice([-1,1], size=len(p))\n",
    "        \n",
    "        p_plus  = p + ck*delta\n",
    "        p_minus = p - ck*delta\n",
    "        \n",
    "        cost_plus  = cost_func(p_plus)\n",
    "        cost_minus = cost_func(p_minus)\n",
    "        \n",
    "        g_approx = (cost_plus - cost_minus)/(2.0*ck) * delta\n",
    "        \n",
    "        p = p - ak*g_approx\n",
    "        \n",
    "        current_cost = cost_func(p)\n",
    "        if current_cost < best_cost:\n",
    "            best_cost = current_cost\n",
    "            best_p = p.copy()\n",
    "    \n",
    "    return best_p, best_cost\n",
    "\n",
    "def parse_spsa_params(params):\n",
    "    \"\"\"\n",
    "    Map a real vector `params` into discrete hyperparams + DP gamma:\n",
    "      params[0]: model_type (0=RF,1=GB,2=CB)\n",
    "      params[1]: n_estimators [10..200]\n",
    "      params[2]: learning_rate [0.01..0.2]\n",
    "      params[3]: max_depth [2..10]\n",
    "      params[4]: gamma [0.90..0.999]\n",
    "    \"\"\"\n",
    "    p0 = int(round(np.clip(params[0], 0, 2)))       # model_type\n",
    "    p1 = int(round(np.clip(params[1], 10, 200)))    # n_estimators\n",
    "    p2 = float(np.clip(params[2], 0.01, 0.2))       # learning_rate\n",
    "    p3 = int(round(np.clip(params[3], 2, 10)))      # max_depth\n",
    "    p4 = float(np.clip(params[4], 0.90, 0.999))      # gamma\n",
    "    return (p0, p1, p2, p3, p4)\n",
    "\n",
    "def spsa_cost_function(param_vector, df_train, df_val):\n",
    "    \"\"\"\n",
    "    Decision-aware cost function used by SPSA:\n",
    "      1) Parse param_vector => (model_type, n_estimators, learning_rate, max_depth, gamma)\n",
    "      2) Train model on df_train\n",
    "      3) Predict risk on df_val\n",
    "      4) Build DP with gamma (from param_vector) using transitions from df_train\n",
    "      5) Evaluate cost on df_val (unconstrained).\n",
    "    \"\"\"\n",
    "    model_type, n_est, lr, m_depth, gamma_ = parse_spsa_params(param_vector)\n",
    "\n",
    "    X_tr = df_train[['EIT','NIRS','EIS']].values\n",
    "    y_tr = df_train['label'].values\n",
    "    \n",
    "    # Build the model\n",
    "    if model_type == 0:\n",
    "        clf = RandomForestClassifier(n_estimators=n_est, max_depth=m_depth, random_state=0)\n",
    "    elif model_type == 1:\n",
    "        clf = GradientBoostingClassifier(n_estimators=n_est, learning_rate=lr,\n",
    "                                         max_depth=m_depth, random_state=0)\n",
    "    else:\n",
    "        clf = CatBoostClassifier(iterations=n_est, learning_rate=lr, depth=m_depth,\n",
    "                                 verbose=0, random_state=0)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Evaluate on df_val with DP policy\n",
    "    X_val = df_val[['EIT','NIRS','EIS']].values\n",
    "    prob_val = clf.predict_proba(X_val)[:,1]\n",
    "    df_val_ = df_val.copy()\n",
    "    df_val_['risk_score'] = prob_val\n",
    "    \n",
    "    # DP transitions from df_train\n",
    "    df_tr_ = df_train.copy()\n",
    "    train_probs = clf.predict_proba(df_tr_[['EIT','NIRS','EIS']])[:,1]\n",
    "    df_tr_['risk_score'] = train_probs\n",
    "    df_tr_['risk_bucket'] = df_tr_['risk_score'].apply(to_bucket)\n",
    "    \n",
    "    p_trans, p_sick = estimate_transition_and_sick_probs(df_tr_, T=T_MAX, n_buckets=5)\n",
    "    V, pi_ = train_data_driven_dp_unconstrained(\n",
    "        p_trans, p_sick,\n",
    "        FP=FP_COST, FN=FN_COST, D=D_COST,\n",
    "        gamma=gamma_, T=T_MAX\n",
    "    )\n",
    "    \n",
    "    # Evaluate that DP policy on df_val\n",
    "    df_val_['risk_bucket'] = df_val_['risk_score'].apply(to_bucket)\n",
    "    dp_policy = make_dp_policy(V, pi_, T=T_MAX)\n",
    "    stats = simulate_policy(df_val_, dp_policy)  # unconstrained cost\n",
    "    return stats['cost']\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 7. ALGORITHM 5 (SPSA) WITH 50% CAP ON FINAL HOLDOUT\n",
    "###############################################################################\n",
    "def run_algorithm5_spsa_with_capacity(df_all, k=3, seed=0, n_spsa_iter=20, capacity_frac=0.5):\n",
    "    \"\"\"\n",
    "    SPSA Hyper-Parameter Tuning (Decision-Aware) + 50% cap on final holdout.\n",
    "    \n",
    "    1) Split data into k+1 groups: G1..Gk, G_{k+1}\n",
    "    2) For each fold i in [1..k]:\n",
    "         - define cost function that trains on G\\\\G_i, evaluates cost on G_i\n",
    "         - run SPSA to find best param_i\n",
    "    3) Among param_1..param_k, pick best overall param* with minimal sum-of-costs across folds\n",
    "    4) Evaluate param* on G_{k+1} (the holdout),\n",
    "       but we apply the 50%-cap to *sick* patients in the final holdout only.\n",
    "    5) Build final table with 5 methods:\n",
    "       - Constant Threshold\n",
    "       - Dynamic Threshold-R\n",
    "       - Linear Threshold\n",
    "       - Wait Till End\n",
    "       - DP-based (SPSA)\n",
    "      and each one is simulated with the 50%-cap on sick.\n",
    "    \"\"\"\n",
    "    # Split into k+1 groups\n",
    "    groups = k_plus_1_splits(df_all, k=k, seed=seed)\n",
    "    \n",
    "    # param_init is the starting guess for SPSA hyperparams\n",
    "    param_init = np.array([1.0, 50.0, 0.05, 3.0, 0.95], dtype=float)\n",
    "    \n",
    "    # 2) For each fold i in [1..k], run SPSA to get best param_i\n",
    "    spsa_solutions = []\n",
    "    for i in range(1, k+1):\n",
    "        df_val = groups[i-1]\n",
    "        df_train_list = [groups[j] for j in range(k) if j != (i-1)]\n",
    "        df_train_ = pd.concat(df_train_list, ignore_index=True)\n",
    "        \n",
    "        def fold_cost_func(p):\n",
    "            return spsa_cost_function(p, df_train_, df_val)\n",
    "        \n",
    "        best_p_fold, best_c_fold = spsa_optimize(\n",
    "            fold_cost_func,\n",
    "            param_init,\n",
    "            n_iter=n_spsa_iter,\n",
    "            alpha=0.602,\n",
    "            gamma=0.101,\n",
    "            a=0.1,\n",
    "            c=0.1,\n",
    "            seed=seed+i\n",
    "        )\n",
    "        spsa_solutions.append( (best_p_fold, best_c_fold) )\n",
    "    \n",
    "    # 3) Among these k solutions, pick best overall param*\n",
    "    #    with minimal sum-of-costs across all k folds\n",
    "    k_ = k\n",
    "    fold_cost_matrix = np.zeros((k_, k_), dtype=float)\n",
    "    for i in range(k_):\n",
    "        param_i = spsa_solutions[i][0]\n",
    "        for j in range(k_):\n",
    "            df_val_j = groups[j]\n",
    "            df_train_j_list = [groups[m] for m in range(k_) if m != j]\n",
    "            df_train_j = pd.concat(df_train_j_list, ignore_index=True)\n",
    "            c_ij = spsa_cost_function(param_i, df_train_j, df_val_j)\n",
    "            fold_cost_matrix[i,j] = c_ij\n",
    "    \n",
    "    total_cost_per_param = fold_cost_matrix.sum(axis=1)\n",
    "    best_index = np.argmin(total_cost_per_param)\n",
    "    best_param = spsa_solutions[best_index][0]\n",
    "    \n",
    "    # 4) Evaluate best_param on final holdout G_{k+1}, with 50%-cap\n",
    "    df_holdout = groups[k]\n",
    "    df_train_for_holdout = pd.concat(groups[:k], ignore_index=True)\n",
    "    \n",
    "    # Parse best_param -> final ML model + DP discount factor\n",
    "    model_type, n_est, lr, m_depth, gamma_ = parse_spsa_params(best_param)\n",
    "    \n",
    "    # Train final classifier on union of k folds\n",
    "    X_train2 = df_train_for_holdout[['EIT','NIRS','EIS']].values\n",
    "    y_train2 = df_train_for_holdout['label'].values\n",
    "    \n",
    "    if model_type == 0:\n",
    "        clf_final = RandomForestClassifier(n_estimators=n_est, max_depth=m_depth, random_state=0)\n",
    "    elif model_type == 1:\n",
    "        clf_final = GradientBoostingClassifier(n_estimators=n_est, learning_rate=lr,\n",
    "                                               max_depth=m_depth, random_state=0)\n",
    "    else:\n",
    "        clf_final = CatBoostClassifier(iterations=n_est, learning_rate=lr, depth=m_depth,\n",
    "                                       verbose=0, random_state=0)\n",
    "    clf_final.fit(X_train2, y_train2)\n",
    "    \n",
    "    # Build DP transitions from df_train_for_holdout\n",
    "    df_train2 = df_train_for_holdout.copy()\n",
    "    train_probs2 = clf_final.predict_proba(df_train2[['EIT','NIRS','EIS']])[:,1]\n",
    "    df_train2['risk_score'] = train_probs2\n",
    "    df_train2['risk_bucket'] = df_train2['risk_score'].apply(to_bucket)\n",
    "    p_trans2, p_sick2 = estimate_transition_and_sick_probs(df_train2, T=T_MAX, n_buckets=5)\n",
    "    \n",
    "    V_final, pi_final = train_data_driven_dp_unconstrained(\n",
    "        p_trans2, p_sick2,\n",
    "        FP=FP_COST, FN=FN_COST, D=D_COST,\n",
    "        gamma=gamma_, T=T_MAX\n",
    "    )\n",
    "    dp_policy_final = make_dp_policy(V_final, pi_final, T=T_MAX)\n",
    "    \n",
    "    # 5) Tune threshold-based policies on the same train set (df_train2)\n",
    "    thr_const, _ = constant_threshold_search(df_train2)\n",
    "    thr_vec, _ = dynamic_threshold_random_search(df_train2, time_steps=T_MAX)\n",
    "    (A_lin, B_lin), _ = linear_threshold_search(df_train2)\n",
    "    thr_wte, _ = wait_till_end_search(df_train2)\n",
    "    \n",
    "    # Evaluate final policies on holdout with capacity\n",
    "    df_holdout2 = df_holdout.copy()\n",
    "    holdout_probs = clf_final.predict_proba(df_holdout2[['EIT','NIRS','EIS']])[:,1]\n",
    "    df_holdout2['risk_score'] = holdout_probs\n",
    "    \n",
    "    # 1) Constant threshold\n",
    "    pol_const = make_constant_threshold_policy(thr_const)\n",
    "    stats_const = simulate_policy_with_sick_capacity(df_holdout2, pol_const, capacity_frac=capacity_frac)\n",
    "    \n",
    "    # 2) Dynamic threshold - random\n",
    "    pol_dyn = make_dynamic_threshold_policy(thr_vec)\n",
    "    stats_dyn = simulate_policy_with_sick_capacity(df_holdout2, pol_dyn, capacity_frac=capacity_frac)\n",
    "    \n",
    "    # 3) Linear threshold\n",
    "    pol_lin = make_linear_threshold_policy(A_lin, B_lin)\n",
    "    stats_lin = simulate_policy_with_sick_capacity(df_holdout2, pol_lin, capacity_frac=capacity_frac)\n",
    "    \n",
    "    # 4) Wait till end\n",
    "    pol_wte = make_wait_till_end_policy(thr_wte)\n",
    "    stats_wte = simulate_policy_with_sick_capacity(df_holdout2, pol_wte, capacity_frac=capacity_frac)\n",
    "    \n",
    "    # 5) DP-based policy from SPSA\n",
    "    df_holdout2_dp = df_holdout2.copy()\n",
    "    df_holdout2_dp['risk_bucket'] = df_holdout2_dp['risk_score'].apply(to_bucket)\n",
    "    stats_dp = simulate_policy_with_sick_capacity(df_holdout2_dp, dp_policy_final,\n",
    "                                                  capacity_frac=capacity_frac)\n",
    "    \n",
    "    # Build final table\n",
    "    table = pd.DataFrame({\n",
    "        'Method': [\n",
    "            'Constant Threshold',\n",
    "            'Dynamic Threshold-R',\n",
    "            'Linear Threshold',\n",
    "            'Wait Till End',\n",
    "            'DP-based (SPSA)'\n",
    "        ],\n",
    "        'Cost': [\n",
    "            stats_const['cost'],\n",
    "            stats_dyn['cost'],\n",
    "            stats_lin['cost'],\n",
    "            stats_wte['cost'],\n",
    "            stats_dp['cost']\n",
    "        ],\n",
    "        'Precision (%)': [\n",
    "            100*stats_const['precision'],\n",
    "            100*stats_dyn['precision'],\n",
    "            100*stats_lin['precision'],\n",
    "            100*stats_wte['precision'],\n",
    "            100*stats_dp['precision']\n",
    "        ],\n",
    "        'Recall (%)': [\n",
    "            100*stats_const['recall'],\n",
    "            100*stats_dyn['recall'],\n",
    "            100*stats_lin['recall'],\n",
    "            100*stats_wte['recall'],\n",
    "            100*stats_dp['recall']\n",
    "        ],\n",
    "        'Avg Treat Time': [\n",
    "            stats_const['avg_treatment_time'],\n",
    "            stats_dyn['avg_treatment_time'],\n",
    "            stats_lin['avg_treatment_time'],\n",
    "            stats_wte['avg_treatment_time'],\n",
    "            stats_dp['avg_treatment_time']\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    return table\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 8. MAIN - RUN MULTIPLE REPLICATES\n",
    "###############################################################################\n",
    "def main():\n",
    "    # Load synthetic data\n",
    "    df_all = pd.read_csv(\"synthetic_patients_with_features.csv\")\n",
    "    \n",
    "    # Filter to time < T_MAX if needed\n",
    "    df_all = df_all[df_all['time'] < T_MAX].copy()\n",
    "    \n",
    "    # Check required columns\n",
    "    required = {'patient_id','time','EIT','NIRS','EIS','label'}\n",
    "    if not required.issubset(df_all.columns):\n",
    "        raise ValueError(f\"CSV must have columns at least: {required}. Found: {df_all.columns}\")\n",
    "    \n",
    "    # Number of replicates to run\n",
    "    NUM_REPLICATES = 30\n",
    "    \n",
    "    # Store each replicate's table in a list\n",
    "    replicate_tables = []\n",
    "    \n",
    "    for rep in range(NUM_REPLICATES):\n",
    "        # Use different seed each time to randomize grouping\n",
    "        seed = 412 + rep\n",
    "        print(f\"\\n=== Running replicate {rep+1}/{NUM_REPLICATES} (seed={seed}) ===\")\n",
    "        \n",
    "        # Run ALGORITHM 5 (SPSA) with 50%-cap on final holdout\n",
    "        table_alg5 = run_algorithm5_spsa_with_capacity(\n",
    "            df_all,\n",
    "            k=3,\n",
    "            seed=seed,\n",
    "            n_spsa_iter=20,\n",
    "            capacity_frac=0.5\n",
    "        )\n",
    "        \n",
    "        print(table_alg5.to_string(index=False))\n",
    "        replicate_tables.append(table_alg5)\n",
    "    \n",
    "    # After running all replicates, concatenate them for summary stats\n",
    "    all_results = pd.concat(replicate_tables, ignore_index=True)\n",
    "    \n",
    "    # Group by 'Method' and compute mean/std of each numeric column\n",
    "    summary = all_results.groupby('Method').agg({\n",
    "        'Cost': ['mean','std'],\n",
    "        'Precision (%)': ['mean','std'],\n",
    "        'Recall (%)': ['mean','std'],\n",
    "        'Avg Treat Time': ['mean','std']\n",
    "    })\n",
    "    \n",
    "    # Flatten the multi-level column index\n",
    "    summary.columns = ['_'.join(col).strip() for col in summary.columns.values]\n",
    "    summary.reset_index(inplace=True)\n",
    "\n",
    "    print(\"\\n=============================\")\n",
    "    print(\"FINAL SUMMARY ACROSS REPLICATES\")\n",
    "    print(\"=============================\")\n",
    "    print(summary.to_string(index=False))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb1f221-45b7-48f8-b793-e5719e7eb6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
