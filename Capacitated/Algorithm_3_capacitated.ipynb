{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34694252-0ddc-444c-b97f-a9cc21df0b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ALGORITHM 3 (SEQUENTIAL OPTIMIZATION) WITH 50% CAP ON FINAL FOLD SICK PATIENTS ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      " Constant Threshold  1004      37.142857   48.148148        2.400000\n",
      "Dynamic Threshold-R  1179      23.214286   48.148148        2.857143\n",
      "   Linear Threshold  1099      27.083333   48.148148        1.020833\n",
      "      Wait Till End   960     100.000000   48.148148       20.000000\n",
      "    DP-based Policy   831     100.000000   48.148148       10.076923\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SEQUENTIAL OPTIMIZATION (ALGORITHM 3) FOR HEMORRHAGE DIAGNOSIS & TREATMENT\n",
    "WITH A 50% CAP ON SICK PATIENTS.\n",
    "\n",
    "Requirements:\n",
    "  pip install numpy pandas scikit-learn catboost\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Sklearn models, metrics, etc.\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "# CatBoost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "###############################################################################\n",
    "# 1. GLOBAL PARAMETERS\n",
    "###############################################################################\n",
    "FP_COST = 10\n",
    "FN_COST = 50\n",
    "D_COST  = 1\n",
    "T_MAX   = 21   # maximum discrete time steps (0..T_MAX-1)\n",
    "GAMMA_CANDIDATES = [0.95, 0.99]  # Example DP discount factors to try\n",
    "\n",
    "# Hyperparameter grids for ML models\n",
    "RF_PARAM_GRID = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "GB_PARAM_GRID = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "CATBOOST_PARAM_GRID = {\n",
    "    'iterations': [50, 100],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'depth': [3, 5]\n",
    "}\n",
    "\n",
    "###############################################################################\n",
    "# 2. HELPER FUNCTIONS (DATA SPLITS, MODEL TRAINING, ETC.)\n",
    "###############################################################################\n",
    "def split_into_nplus1_groups(df, n=4, seed=0):\n",
    "    \"\"\"\n",
    "    Shuffle patient IDs and split ~evenly into (n+1) groups: G1, G2, ..., G_{n+1}.\n",
    "    Example usage: n=4 => 5 groups total.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    unique_pids = df['patient_id'].unique()\n",
    "    rng.shuffle(unique_pids)\n",
    "    \n",
    "    # We'll cut into (n+1) roughly-equal slices\n",
    "    # For n=4 => 5 slices\n",
    "    N = len(unique_pids)\n",
    "    group_size = int(np.ceil(N/(n+1)))\n",
    "    \n",
    "    groups = []\n",
    "    start_idx = 0\n",
    "    for i in range(n+1):\n",
    "        end_idx = min(start_idx+group_size, N)\n",
    "        group_pids = unique_pids[start_idx:end_idx]\n",
    "        group_df   = df[df['patient_id'].isin(group_pids)].copy()\n",
    "        groups.append(group_df)\n",
    "        start_idx = end_idx\n",
    "    return groups  # list of dataframes: G[0], G[1], ..., G[n]\n",
    "\n",
    "def compute_auc_score(y_true, y_prob):\n",
    "    \"\"\"Compute AUC safely. If only one class, return 0.5.\"\"\"\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return 0.5\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def train_and_select_best_model(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Trains multiple models (RandomForest, GB, CatBoost)\n",
    "    over small hyperparam grids, picks best by AUC.\n",
    "    \n",
    "    Returns: (best_model, best_auc, best_model_name)\n",
    "    \"\"\"\n",
    "    best_auc = -1.0\n",
    "    best_model = None\n",
    "    best_name  = None\n",
    "    \n",
    "    # 1) RandomForest\n",
    "    for params in ParameterGrid(RF_PARAM_GRID):\n",
    "        rf = RandomForestClassifier(random_state=0, **params)\n",
    "        rf.fit(X_train, y_train)\n",
    "        val_prob = rf.predict_proba(X_val)[:,1]\n",
    "        auc_val  = compute_auc_score(y_val, val_prob)\n",
    "        if auc_val > best_auc:\n",
    "            best_auc   = auc_val\n",
    "            best_model = rf\n",
    "            best_name  = f\"RandomForest_{params}\"\n",
    "    \n",
    "    # 2) GradientBoosting\n",
    "    for params in ParameterGrid(GB_PARAM_GRID):\n",
    "        gb = GradientBoostingClassifier(random_state=0, **params)\n",
    "        gb.fit(X_train, y_train)\n",
    "        val_prob = gb.predict_proba(X_val)[:,1]\n",
    "        auc_val  = compute_auc_score(y_val, val_prob)\n",
    "        if auc_val > best_auc:\n",
    "            best_auc   = auc_val\n",
    "            best_model = gb\n",
    "            best_name  = f\"GradientBoosting_{params}\"\n",
    "    \n",
    "    # 3) CatBoost\n",
    "    for params in ParameterGrid(CATBOOST_PARAM_GRID):\n",
    "        cb = CatBoostClassifier(verbose=0, random_state=0, **params)\n",
    "        cb.fit(X_train, y_train)\n",
    "        val_prob = cb.predict_proba(X_val)[:,1]\n",
    "        auc_val  = compute_auc_score(y_val, val_prob)\n",
    "        if auc_val > best_auc:\n",
    "            best_auc   = auc_val\n",
    "            best_model = cb\n",
    "            best_name  = f\"CatBoost_{params}\"\n",
    "    \n",
    "    return best_model, best_auc, best_name\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 3. POLICY SIMULATION FUNCTIONS\n",
    "###############################################################################\n",
    "def simulate_policy(df, policy_func):\n",
    "    \"\"\"\n",
    "    df must contain:\n",
    "      - patient_id\n",
    "      - time\n",
    "      - risk_score\n",
    "      - label (0 or 1)\n",
    "    \n",
    "    policy_func(patient_rows) -> treat_time (int) or None\n",
    "    \n",
    "    Returns a dictionary of relevant metrics: total cost, precision, recall, etc.\n",
    "    (Unconstrained treatment for all recommended patients.)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for pid, grp in df.groupby('patient_id'):\n",
    "        grp = grp.sort_values('time')\n",
    "        label = grp['label'].iloc[0]\n",
    "        \n",
    "        treat_time = policy_func(grp)\n",
    "        \n",
    "        if treat_time is None:\n",
    "            # never treated\n",
    "            if label == 1:\n",
    "                cost = FN_COST\n",
    "                tp   = 0\n",
    "            else:\n",
    "                cost = 0\n",
    "                tp   = 0\n",
    "            fp = 0\n",
    "            treat_flag = 0\n",
    "            ttime = None\n",
    "        else:\n",
    "            treat_flag = 1\n",
    "            if label == 1:\n",
    "                cost = D_COST * treat_time\n",
    "                tp   = 1\n",
    "                fp   = 0\n",
    "            else:\n",
    "                cost = FP_COST\n",
    "                tp   = 0\n",
    "                fp   = 1\n",
    "            ttime = treat_time\n",
    "        \n",
    "        results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': treat_flag,\n",
    "            'treat_time': ttime,\n",
    "            'cost': cost,\n",
    "            'tp': tp,\n",
    "            'fp': fp\n",
    "        })\n",
    "    \n",
    "    df_res     = pd.DataFrame(results)\n",
    "    total_cost = df_res['cost'].sum()\n",
    "    \n",
    "    treated_df = df_res[df_res['treated']==1]\n",
    "    tp_sum = treated_df['tp'].sum()\n",
    "    fp_sum = treated_df['fp'].sum()\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        precision = tp_sum / (tp_sum + fp_sum)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "    \n",
    "    sick_df = df_res[df_res['label']==1]\n",
    "    total_sick = len(sick_df)\n",
    "    if total_sick > 0:\n",
    "        recall = tp_sum / total_sick\n",
    "    else:\n",
    "        recall = 0.0\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        valid_tt = treated_df['treat_time'].dropna()\n",
    "        avg_tt   = valid_tt.mean() if len(valid_tt) > 0 else 0.0\n",
    "    else:\n",
    "        avg_tt = 0.0\n",
    "    \n",
    "    return {\n",
    "        'cost': total_cost,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'avg_treatment_time': avg_tt\n",
    "    }\n",
    "\n",
    "def simulate_policy_with_sick_capacity(df, policy_func, capacity_frac=0.5):\n",
    "    \"\"\"\n",
    "    We enforce that at most (capacity_frac) fraction of the *sick* patients\n",
    "    in this fold can be treated.\n",
    "\n",
    "    Steps:\n",
    "      1. Identify which patients are \"recommended\" for treatment by the policy_func.\n",
    "      2. Separate recommended patients into \"sick recommended\" vs. \"healthy recommended\".\n",
    "      3. Among the recommended *sick* patients, we can only treat up to\n",
    "         floor(capacity_frac * total_sick_in_this_fold). We'll choose the top (by risk_score).\n",
    "      4. We treat all recommended *healthy* patients with no limit.\n",
    "      5. Everyone else is not treated (FN cost if sick, 0 cost if healthy).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    recommended_sick = []     # (pid, label=1, time_treated, risk_score)\n",
    "    recommended_healthy = []  # (pid, label=0, time_treated, risk_score)\n",
    "    \n",
    "    # Count total sick in this fold\n",
    "    all_sick_df = df[df['label']==1]\n",
    "    num_sick = all_sick_df['patient_id'].nunique()\n",
    "    # capacity = max number of sick we can treat\n",
    "    capacity_num = int(np.floor(capacity_frac * num_sick)) if num_sick>0 else 0\n",
    "    \n",
    "    # 1) Check policy recommendation\n",
    "    for pid, grp in df.groupby('patient_id'):\n",
    "        grp = grp.sort_values('time')\n",
    "        label = grp['label'].iloc[0]\n",
    "        \n",
    "        treat_time = policy_func(grp)\n",
    "        \n",
    "        if treat_time is None:\n",
    "            # not recommended => cost is assigned later\n",
    "            results.append({\n",
    "                'patient_id': pid,\n",
    "                'label': label,\n",
    "                'treated': 0,\n",
    "                'treat_time': None,\n",
    "                'cost': None,\n",
    "                'tp': 0,\n",
    "                'fp': 0\n",
    "            })\n",
    "        else:\n",
    "            # recommended => store in recommended_sick or recommended_healthy\n",
    "            row_t = grp[grp['time']==treat_time].iloc[0]\n",
    "            recommended_risk = row_t['risk_score']\n",
    "            if label == 1:\n",
    "                recommended_sick.append((pid, label, treat_time, recommended_risk))\n",
    "            else:\n",
    "                recommended_healthy.append((pid, label, treat_time, recommended_risk))\n",
    "    \n",
    "    # 2) Sort recommended sick by descending risk_score\n",
    "    recommended_sick.sort(key=lambda x: x[3], reverse=True)\n",
    "    # 3) Actually treat only top capacity_num from recommended sick\n",
    "    treat_sick_subset = recommended_sick[:capacity_num]\n",
    "    not_treat_sick_subset = recommended_sick[capacity_num:]\n",
    "    \n",
    "    # 4) We treat ALL recommended healthy, no limit\n",
    "    treat_healthy_subset = recommended_healthy\n",
    "    \n",
    "    # Build final result records for the treated subsets\n",
    "    treat_results = []\n",
    "    \n",
    "    # 4a) SICK actually treated\n",
    "    for (pid, label, ttime, rsk) in treat_sick_subset:\n",
    "        cost_ = D_COST * ttime  # treat_time * D\n",
    "        treat_results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': 1,\n",
    "            'treat_time': ttime,\n",
    "            'cost': cost_,\n",
    "            'tp': 1,\n",
    "            'fp': 0\n",
    "        })\n",
    "    \n",
    "    # 4b) HEALTHY actually treated\n",
    "    for (pid, label, ttime, rsk) in treat_healthy_subset:\n",
    "        cost_ = FP_COST  # healthy => false positive cost\n",
    "        treat_results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': 1,\n",
    "            'treat_time': ttime,\n",
    "            'cost': cost_,\n",
    "            'tp': 0,\n",
    "            'fp': 1\n",
    "        })\n",
    "    \n",
    "    # 5) Build final result records for not-treated subsets\n",
    "    not_treat_results = []\n",
    "    \n",
    "    # (a) SICK recommended but not treated (exceeds capacity)\n",
    "    for (pid, label, ttime, rsk) in not_treat_sick_subset:\n",
    "        # label==1 => sick\n",
    "        cost_ = FN_COST\n",
    "        not_treat_results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': 0,\n",
    "            'treat_time': None,\n",
    "            'cost': cost_,\n",
    "            'tp': 0,\n",
    "            'fp': 0\n",
    "        })\n",
    "    \n",
    "    # (b) Those who were never recommended\n",
    "    for row in results:\n",
    "        if row['cost'] is None:\n",
    "            # not recommended\n",
    "            if row['label'] == 1:\n",
    "                row['cost'] = FN_COST\n",
    "            else:\n",
    "                row['cost'] = 0\n",
    "            not_treat_results.append(row)\n",
    "    \n",
    "    df_res = pd.DataFrame(treat_results + not_treat_results)\n",
    "    \n",
    "    # Compute final stats\n",
    "    total_cost = df_res['cost'].sum()\n",
    "    treated_df = df_res[df_res['treated']==1]\n",
    "    \n",
    "    tp_sum = treated_df['tp'].sum()\n",
    "    fp_sum = treated_df['fp'].sum()\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        precision = tp_sum / (tp_sum + fp_sum)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "    \n",
    "    sick_df = df_res[df_res['label']==1]\n",
    "    total_sick = len(sick_df)\n",
    "    if total_sick > 0:\n",
    "        recall = tp_sum / total_sick\n",
    "    else:\n",
    "        recall = 0.0\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        valid_tt = treated_df['treat_time'].dropna()\n",
    "        avg_tt   = valid_tt.mean() if len(valid_tt) > 0 else 0.0\n",
    "    else:\n",
    "        avg_tt = 0.0\n",
    "    \n",
    "    return {\n",
    "        'cost': total_cost,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'avg_treatment_time': avg_tt\n",
    "    }\n",
    "\n",
    "###############################################################################\n",
    "# 4. BENCHMARK THRESHOLD-BASED POLICIES\n",
    "###############################################################################\n",
    "def constant_threshold_search(df, thresholds=None):\n",
    "    \"\"\"\n",
    "    Search over possible constant thresholds in [0, 1].\n",
    "    Returns best_thr, best_stats.\n",
    "    \"\"\"\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0,1,21)\n",
    "    best_thr, best_cost, best_stats = None, float('inf'), None\n",
    "    \n",
    "    for thr in thresholds:\n",
    "        def policy_func(patient_rows):\n",
    "            for _, row in patient_rows.iterrows():\n",
    "                if row['risk_score'] >= thr:\n",
    "                    return int(row['time'])\n",
    "            return None\n",
    "        \n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_thr  = thr\n",
    "            best_stats= stats\n",
    "    return best_thr, best_stats\n",
    "\n",
    "def make_constant_threshold_policy(thr):\n",
    "    \"\"\"Returns a policy function that treats as soon as risk_score >= thr.\"\"\"\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            if row['risk_score'] >= thr:\n",
    "                return int(row['time'])\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def dynamic_threshold_random_search(df,\n",
    "                                    time_steps=20,\n",
    "                                    threshold_candidates=[0.0,0.2,0.4,0.6,0.8,1.0],\n",
    "                                    n_samples=200,\n",
    "                                    seed=0):\n",
    "    \"\"\"\n",
    "    We sample random threshold vectors across time_steps\n",
    "    and pick the one with minimal cost on 'df'.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    best_vec = None\n",
    "    best_cost= float('inf')\n",
    "    best_stats=None\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        thr_vec = rng.choice(threshold_candidates, size=time_steps)\n",
    "        \n",
    "        def policy_func(patient_rows):\n",
    "            for _, row in patient_rows.iterrows():\n",
    "                t = int(row['time'])\n",
    "                if t < time_steps and row['risk_score'] >= thr_vec[t]:\n",
    "                    return t\n",
    "            return None\n",
    "        \n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_vec  = thr_vec.copy()\n",
    "            best_stats= stats\n",
    "    return best_vec, best_stats\n",
    "\n",
    "def make_dynamic_threshold_policy(thr_vec):\n",
    "    \"\"\"Returns a policy function using a time-dependent threshold vector thr_vec.\"\"\"\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = int(row['time'])\n",
    "            if t < len(thr_vec):\n",
    "                if row['risk_score'] >= thr_vec[t]:\n",
    "                    return t\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def linear_threshold_search(df,\n",
    "                            A_candidates=np.linspace(-0.05, 0.01, 7),\n",
    "                            B_candidates=np.linspace(0,0.6,2)):\n",
    "    \"\"\"\n",
    "    Search policies of the form threshold(t) = clip(A*t + B, 0, 1).\n",
    "    \"\"\"\n",
    "    best_A, best_B = None, None\n",
    "    best_cost, best_stats = float('inf'), None\n",
    "    \n",
    "    for A in A_candidates:\n",
    "        for B in B_candidates:\n",
    "            def policy_func(patient_rows):\n",
    "                for _, row in patient_rows.iterrows():\n",
    "                    t = row['time']\n",
    "                    thr = A*t + B\n",
    "                    thr = np.clip(thr,0,1)\n",
    "                    if row['risk_score'] >= thr:\n",
    "                        return int(t)\n",
    "                return None\n",
    "            \n",
    "            stats = simulate_policy(df, policy_func)\n",
    "            if stats['cost'] < best_cost:\n",
    "                best_cost = stats['cost']\n",
    "                best_A    = A\n",
    "                best_B    = B\n",
    "                best_stats= stats\n",
    "    return (best_A,best_B), best_stats\n",
    "\n",
    "def make_linear_threshold_policy(A,B):\n",
    "    \"\"\"Returns a policy function threshold(t) = clip(A*t + B, 0, 1).\"\"\"\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = int(row['time'])\n",
    "            thr = A*t + B\n",
    "            thr = np.clip(thr,0,1)\n",
    "            if row['risk_score'] >= thr:\n",
    "                return t\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def wait_till_end_search(df, thresholds=None):\n",
    "    \"\"\"\n",
    "    Policy: wait until the final time for each patient, treat if final risk >= thr.\n",
    "    \"\"\"\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0,1,21)\n",
    "    best_thr, best_cost, best_stats = None, float('inf'), None\n",
    "    \n",
    "    for thr in thresholds:\n",
    "        def policy_func(patient_rows):\n",
    "            final_t = patient_rows['time'].max()\n",
    "            final_row = patient_rows[patient_rows['time']==final_t].iloc[0]\n",
    "            if final_row['risk_score'] >= thr:\n",
    "                return int(final_t)\n",
    "            return None\n",
    "        \n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_thr  = thr\n",
    "            best_stats= stats\n",
    "    return best_thr, best_stats\n",
    "\n",
    "def make_wait_till_end_policy(thr):\n",
    "    \"\"\"Returns a policy function that treats only at final time if risk_score >= thr.\"\"\"\n",
    "    def policy_func(patient_rows):\n",
    "        final_t = patient_rows['time'].max()\n",
    "        final_row = patient_rows[patient_rows['time']==final_t].iloc[0]\n",
    "        if final_row['risk_score'] >= thr:\n",
    "            return int(final_t)\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 5. DATA-DRIVEN DP (UNCONSTRAINED)\n",
    "###############################################################################\n",
    "def to_bucket(prob):\n",
    "    \"\"\"Simple function to map prob into a 5-bucket scale [0..4].\"\"\"\n",
    "    b = int(prob * 5)\n",
    "    return min(b, 4)\n",
    "\n",
    "def estimate_transition_and_sick_probs(df_train, T=20, n_buckets=5):\n",
    "    \"\"\"\n",
    "    p_trans[t,b,b_next], p_sick[t,b]\n",
    "    df_train has columns: patient_id, time, risk_bucket, label\n",
    "    \"\"\"\n",
    "    transition_counts = np.zeros((T-1, n_buckets, n_buckets), dtype=float)\n",
    "    bucket_counts     = np.zeros((T, n_buckets), dtype=float)\n",
    "    sick_counts       = np.zeros((T, n_buckets), dtype=float)\n",
    "    \n",
    "    df_sorted = df_train.sort_values(['patient_id','time'])\n",
    "    for pid, grp in df_sorted.groupby('patient_id'):\n",
    "        grp = grp.sort_values('time')\n",
    "        rows= grp.to_dict('records')\n",
    "        \n",
    "        for i, row in enumerate(rows):\n",
    "            t = int(row['time'])\n",
    "            b = int(row['risk_bucket'])\n",
    "            lbl = row['label']\n",
    "            \n",
    "            if t < T:\n",
    "                bucket_counts[t,b] += 1\n",
    "                sick_counts[t,b]   += lbl\n",
    "            \n",
    "            if i < len(rows)-1:\n",
    "                nxt = rows[i+1]\n",
    "                t_next = nxt['time']\n",
    "                b_next = nxt['risk_bucket']\n",
    "                if (t_next == t+1) and (t < T-1):\n",
    "                    transition_counts[t,b,b_next] += 1\n",
    "    \n",
    "    p_trans = np.zeros((T-1, n_buckets, n_buckets), dtype=float)\n",
    "    for t_ in range(T-1):\n",
    "        for b_ in range(n_buckets):\n",
    "            denom = transition_counts[t_,b_,:].sum()\n",
    "            if denom>0:\n",
    "                p_trans[t_,b_,:] = transition_counts[t_,b_,:] / denom\n",
    "            else:\n",
    "                # if no data, assume self-transition\n",
    "                p_trans[t_,b_,b_] = 1.0\n",
    "    \n",
    "    p_sick = np.zeros((T, n_buckets), dtype=float)\n",
    "    for t_ in range(T):\n",
    "        for b_ in range(n_buckets):\n",
    "            denom = bucket_counts[t_,b_]\n",
    "            if denom>0:\n",
    "                p_sick[t_,b_] = sick_counts[t_,b_] / denom\n",
    "            else:\n",
    "                p_sick[t_,b_] = 0.0\n",
    "    return p_trans, p_sick\n",
    "\n",
    "def train_data_driven_dp_unconstrained(p_trans, p_sick, \n",
    "                                       FP=10, FN=50, D=1, gamma=0.99, T=20):\n",
    "    \"\"\"\n",
    "    Standard DP for unconstrained scenario:\n",
    "      V[t,b] = min( cost_treat_now, gamma * expected_future_if_wait )\n",
    "    \"\"\"\n",
    "    n_buckets = p_sick.shape[1]\n",
    "    V = np.zeros((T+1, n_buckets))\n",
    "    pi_ = np.zeros((T, n_buckets), dtype=int)\n",
    "    \n",
    "    # boundary at t=T\n",
    "    # we only have valid decisions up to t = T-1\n",
    "    for b in range(n_buckets):\n",
    "        # cost if treat exactly at T-1:\n",
    "        cost_treat   = p_sick[T-1,b]*(D*(T-1)) + (1-p_sick[T-1,b])*FP\n",
    "        # cost if never treated:\n",
    "        cost_notreat = p_sick[T-1,b]*FN\n",
    "        V[T,b] = min(cost_treat, cost_notreat)\n",
    "    \n",
    "    # fill from T-1 down to 0\n",
    "    for t in reversed(range(T)):\n",
    "        for b in range(n_buckets):\n",
    "            # treat now\n",
    "            cost_treat = p_sick[t,b]*(D*t) + (1-p_sick[t,b])*FP\n",
    "            \n",
    "            # wait\n",
    "            if t == T-1:\n",
    "                cost_wait = gamma * V[T,b]\n",
    "            else:\n",
    "                exp_future = 0.0\n",
    "                for b_next in range(n_buckets):\n",
    "                    exp_future += p_trans[t,b,b_next]*V[t+1,b_next]\n",
    "                cost_wait = gamma * exp_future\n",
    "            \n",
    "            if cost_treat <= cost_wait:\n",
    "                V[t,b]   = cost_treat\n",
    "                pi_[t,b] = 1\n",
    "            else:\n",
    "                V[t,b]   = cost_wait\n",
    "                pi_[t,b] = 0\n",
    "    \n",
    "    return V, pi_\n",
    "\n",
    "def make_dp_policy(V, pi_, T=20):\n",
    "    \"\"\"\n",
    "    Return a policy function that treats if pi[t,b]==1 at time t\n",
    "    for the bucket b of the risk score.\n",
    "    \"\"\"\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = int(row['time'])\n",
    "            if t < T:\n",
    "                b = int(row['risk_bucket'])\n",
    "                if pi_[t,b] == 1:\n",
    "                    return t\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "###############################################################################\n",
    "# 6. ALGORITHM 3 (SEQUENTIAL OPTIMIZATION) - BUT FINAL FOLD HAS 50% CAP\n",
    "###############################################################################\n",
    "def run_algorithm3_sequential_optimization_with_cap(df_all, n=4, seed=0, capacity_frac=0.5):\n",
    "    \"\"\"\n",
    "    Implements Algorithm 3 (Sequential Optimization) for hemorrhage diagnosis,\n",
    "    unconstrained on G1..G_n, BUT with a capacity_frac limit on how many sick \n",
    "    can be treated in the final holdout fold (G_{n+1}).\n",
    "\n",
    "    1) We split the data into (n+1) groups: G1,...,G_{n+1}.\n",
    "         Let G_{n+1} be the final holdout/test set.\n",
    "         G_cv = [G1..G_n] is used for cross-validation.\n",
    "    2) Stage 1: Choose best ML hyperparams by CV (maximize AUC).\n",
    "    3) Retrain final ML model on G1..G_n with best hyperparams.\n",
    "    4) Stage 2: With ML model fixed, choose best policy hyperparams by CV (min cost).\n",
    "    5) Evaluate final chosen methods on G_{n+1} with capacity_frac *SICK* limit.\n",
    "    \"\"\"\n",
    "    # 0) Filter df_all if needed\n",
    "    df_all = df_all[df_all['time'] < T_MAX].copy()\n",
    "    \n",
    "    # 1) Split\n",
    "    groups = split_into_nplus1_groups(df_all, n=n, seed=seed)\n",
    "    G_test = groups[-1]\n",
    "    G_cv   = groups[:-1]\n",
    "    \n",
    "    # Combine G1..G_n for final retraining\n",
    "    G_cv_concat = pd.concat(G_cv, ignore_index=True)\n",
    "    \n",
    "    ###########################################################################\n",
    "    # STAGE 1: ML hyperparam selection by CV (maximize AUC)\n",
    "    ###########################################################################\n",
    "    def cv_auc_for_ml(params, model_type):\n",
    "        total_auc = 0.0\n",
    "        for i_cv in range(n):\n",
    "            # training = G_cv except G_cv[i_cv]\n",
    "            train_df_list = [G_cv[j] for j in range(n) if j != i_cv]\n",
    "            train_df = pd.concat(train_df_list, ignore_index=True)\n",
    "            val_df   = G_cv[i_cv]\n",
    "            \n",
    "            X_train = train_df[['EIT','NIRS','EIS']].values\n",
    "            y_train = train_df['label'].values\n",
    "            \n",
    "            X_val   = val_df[['EIT','NIRS','EIS']].values\n",
    "            y_val   = val_df['label'].values\n",
    "            \n",
    "            if model_type == 'rf':\n",
    "                mdl = RandomForestClassifier(random_state=0, **params)\n",
    "            elif model_type == 'gb':\n",
    "                mdl = GradientBoostingClassifier(random_state=0, **params)\n",
    "            else:\n",
    "                mdl = CatBoostClassifier(verbose=0, random_state=0, **params)\n",
    "            \n",
    "            mdl.fit(X_train, y_train)\n",
    "            val_prob = mdl.predict_proba(X_val)[:,1]\n",
    "            auc_val  = compute_auc_score(y_val, val_prob)\n",
    "            total_auc += auc_val\n",
    "        return total_auc\n",
    "    \n",
    "    best_overall_auc = -1.0\n",
    "    best_overall_params = None\n",
    "    best_model_type = None\n",
    "    \n",
    "    # 1) RF\n",
    "    for params in ParameterGrid(RF_PARAM_GRID):\n",
    "        sum_auc = cv_auc_for_ml(params, 'rf')\n",
    "        if sum_auc > best_overall_auc:\n",
    "            best_overall_auc = sum_auc\n",
    "            best_overall_params = params\n",
    "            best_model_type = 'rf'\n",
    "    \n",
    "    # 2) GB\n",
    "    for params in ParameterGrid(GB_PARAM_GRID):\n",
    "        sum_auc = cv_auc_for_ml(params, 'gb')\n",
    "        if sum_auc > best_overall_auc:\n",
    "            best_overall_auc = sum_auc\n",
    "            best_overall_params = params\n",
    "            best_model_type = 'gb'\n",
    "    \n",
    "    # 3) CatBoost\n",
    "    for params in ParameterGrid(CATBOOST_PARAM_GRID):\n",
    "        sum_auc = cv_auc_for_ml(params, 'cat')\n",
    "        if sum_auc > best_overall_auc:\n",
    "            best_overall_auc = sum_auc\n",
    "            best_overall_params = params\n",
    "            best_model_type = 'cat'\n",
    "    \n",
    "    # Retrain final ML on entire G_cv\n",
    "    if best_model_type == 'rf':\n",
    "        best_model = RandomForestClassifier(random_state=0, **best_overall_params)\n",
    "    elif best_model_type == 'gb':\n",
    "        best_model = GradientBoostingClassifier(random_state=0, **best_overall_params)\n",
    "    else:\n",
    "        best_model = CatBoostClassifier(verbose=0, random_state=0, **best_overall_params)\n",
    "    \n",
    "    X_cv_final = G_cv_concat[['EIT','NIRS','EIS']].values\n",
    "    y_cv_final = G_cv_concat['label'].values\n",
    "    best_model.fit(X_cv_final, y_cv_final)\n",
    "    \n",
    "    ###########################################################################\n",
    "    # STAGE 2: With ML model fixed, pick best policy hyperparams by CV (min cost)\n",
    "    ###########################################################################\n",
    "    def evaluate_policy_cost_cv(policy_maker_func, param):\n",
    "        \"\"\"\n",
    "        policy_maker_func is a callable that, given 'param', returns policy_func.\n",
    "        We sum the cost across G1..G_n, each with risk scores from best_model.\n",
    "        \"\"\"\n",
    "        total_cost = 0.0\n",
    "        for i_cv in range(n):\n",
    "            G_i = G_cv[i_cv].copy()\n",
    "            X_i = G_i[['EIT','NIRS','EIS']].values\n",
    "            prob_i = best_model.predict_proba(X_i)[:,1]\n",
    "            G_i['risk_score'] = prob_i\n",
    "            \n",
    "            policy_func = policy_maker_func(param)\n",
    "            stats_i = simulate_policy(G_i, policy_func)  # unconstrained in CV\n",
    "            total_cost += stats_i['cost']\n",
    "        return total_cost\n",
    "    \n",
    "    # (A) Constant threshold\n",
    "    possible_thresholds = np.linspace(0,1,21)\n",
    "    best_thr_const = None\n",
    "    best_const_cost = float('inf')\n",
    "    for thr_candidate in possible_thresholds:\n",
    "        cost_cv = evaluate_policy_cost_cv(make_constant_threshold_policy, thr_candidate)\n",
    "        if cost_cv < best_const_cost:\n",
    "            best_const_cost = cost_cv\n",
    "            best_thr_const  = thr_candidate\n",
    "    \n",
    "    # (B) Dynamic threshold (random search)\n",
    "    rng = np.random.RandomState(42)\n",
    "    threshold_candidates = [0.0,0.2,0.4,0.6,0.8,1.0]\n",
    "    dynamic_param_candidates = []\n",
    "    N_SAMPLES = 30\n",
    "    for _ in range(N_SAMPLES):\n",
    "        thr_vec = rng.choice(threshold_candidates, size=T_MAX-1)\n",
    "        dynamic_param_candidates.append(tuple(thr_vec))\n",
    "    \n",
    "    best_thr_vec = None\n",
    "    best_dyn_cost = float('inf')\n",
    "    for candidate_vec in dynamic_param_candidates:\n",
    "        cost_cv = evaluate_policy_cost_cv(make_dynamic_threshold_policy, candidate_vec)\n",
    "        if cost_cv < best_dyn_cost:\n",
    "            best_dyn_cost = cost_cv\n",
    "            best_thr_vec  = candidate_vec\n",
    "    \n",
    "    # (C) Linear threshold\n",
    "    A_candidates = np.linspace(-0.05, 0.01, 7)\n",
    "    B_candidates = np.linspace(0,0.6,2)\n",
    "    best_lin = None\n",
    "    best_lin_cost = float('inf')\n",
    "    for A_ in A_candidates:\n",
    "        for B_ in B_candidates:\n",
    "            cost_cv = 0.0\n",
    "            for i_cv in range(n):\n",
    "                G_i = G_cv[i_cv].copy()\n",
    "                X_i = G_i[['EIT','NIRS','EIS']].values\n",
    "                prob_i = best_model.predict_proba(X_i)[:,1]\n",
    "                G_i['risk_score'] = prob_i\n",
    "                \n",
    "                policy_lin = make_linear_threshold_policy(A_, B_)\n",
    "                stats_i = simulate_policy(G_i, policy_lin)\n",
    "                cost_cv += stats_i['cost']\n",
    "            if cost_cv < best_lin_cost:\n",
    "                best_lin_cost = cost_cv\n",
    "                best_lin = (A_, B_)\n",
    "    A_lin, B_lin = best_lin\n",
    "    \n",
    "    # (D) Wait-till-end threshold\n",
    "    best_thr_wte = None\n",
    "    best_wte_cost= float('inf')\n",
    "    for thr_candidate in possible_thresholds:\n",
    "        cost_cv = evaluate_policy_cost_cv(make_wait_till_end_policy, thr_candidate)\n",
    "        if cost_cv < best_wte_cost:\n",
    "            best_wte_cost   = cost_cv\n",
    "            best_thr_wte    = thr_candidate\n",
    "    \n",
    "    # (E) Data-driven DP: pick best gamma by cross-validation\n",
    "    def evaluate_dp_gamma_cv(gamma_val):\n",
    "        total_cost = 0.0\n",
    "        for i_cv in range(n):\n",
    "            # train transition model on all folds except i_cv\n",
    "            train_df_list = [G_cv[j] for j in range(n) if j != i_cv]\n",
    "            train_df = pd.concat(train_df_list, ignore_index=True)\n",
    "            \n",
    "            X_train = train_df[['EIT','NIRS','EIS']].values\n",
    "            prob_train = best_model.predict_proba(X_train)[:,1]\n",
    "            train_df['risk_score'] = prob_train\n",
    "            train_df['risk_bucket'] = train_df['risk_score'].apply(to_bucket)\n",
    "            \n",
    "            p_trans, p_sick = estimate_transition_and_sick_probs(train_df, T=T_MAX, n_buckets=5)\n",
    "            V_temp, pi_temp = train_data_driven_dp_unconstrained(\n",
    "                p_trans, p_sick,\n",
    "                FP=FP_COST, FN=FN_COST, D=D_COST,\n",
    "                gamma=gamma_val, T=T_MAX\n",
    "            )\n",
    "            dp_policy_temp = make_dp_policy(V_temp, pi_temp, T=T_MAX)\n",
    "            \n",
    "            # Evaluate on G_cv[i_cv]\n",
    "            G_i = G_cv[i_cv].copy()\n",
    "            X_i = G_i[['EIT','NIRS','EIS']].values\n",
    "            prob_i = best_model.predict_proba(X_i)[:,1]\n",
    "            G_i['risk_score'] = prob_i\n",
    "            G_i['risk_bucket'] = G_i['risk_score'].apply(to_bucket)\n",
    "            \n",
    "            stats_i = simulate_policy(G_i, dp_policy_temp)  # unconstrained in CV\n",
    "            total_cost += stats_i['cost']\n",
    "        return total_cost\n",
    "    \n",
    "    best_gamma = None\n",
    "    best_dp_cost= float('inf')\n",
    "    for gamma_ in GAMMA_CANDIDATES:\n",
    "        cost_cv_gamma = evaluate_dp_gamma_cv(gamma_)\n",
    "        if cost_cv_gamma < best_dp_cost:\n",
    "            best_dp_cost = cost_cv_gamma\n",
    "            best_gamma   = gamma_\n",
    "    \n",
    "    # Train final DP on G_cv_concat with best_gamma\n",
    "    G_cv_concat_dp = G_cv_concat.copy()\n",
    "    X_dp = G_cv_concat_dp[['EIT','NIRS','EIS']].values\n",
    "    prob_dp = best_model.predict_proba(X_dp)[:,1]\n",
    "    G_cv_concat_dp['risk_score'] = prob_dp\n",
    "    G_cv_concat_dp['risk_bucket'] = G_cv_concat_dp['risk_score'].apply(to_bucket)\n",
    "    \n",
    "    p_trans_final, p_sick_final = estimate_transition_and_sick_probs(\n",
    "        G_cv_concat_dp, T=T_MAX, n_buckets=5\n",
    "    )\n",
    "    V_final, pi_final = train_data_driven_dp_unconstrained(\n",
    "        p_trans_final, p_sick_final,\n",
    "        FP=FP_COST, FN=FN_COST, D=D_COST,\n",
    "        gamma=best_gamma, T=T_MAX\n",
    "    )\n",
    "    dp_policy_final = make_dp_policy(V_final, pi_final, T=T_MAX)\n",
    "    \n",
    "    ###########################################################################\n",
    "    # 7) Evaluate all final chosen methods on G_{n+1} with 50% capacity\n",
    "    ###########################################################################\n",
    "    G_test_eval = G_test.copy()\n",
    "    X_test = G_test_eval[['EIT','NIRS','EIS']].values\n",
    "    prob_test = best_model.predict_proba(X_test)[:,1]\n",
    "    G_test_eval['risk_score'] = prob_test\n",
    "    \n",
    "    # We now simulate with the capacity constraint\n",
    "    policy_const = make_constant_threshold_policy(best_thr_const)\n",
    "    stats_const  = simulate_policy_with_sick_capacity(G_test_eval, policy_const, capacity_frac=capacity_frac)\n",
    "    \n",
    "    policy_dyn = make_dynamic_threshold_policy(best_thr_vec)\n",
    "    stats_dyn  = simulate_policy_with_sick_capacity(G_test_eval, policy_dyn, capacity_frac=capacity_frac)\n",
    "    \n",
    "    policy_lin = make_linear_threshold_policy(A_lin, B_lin)\n",
    "    stats_lin  = simulate_policy_with_sick_capacity(G_test_eval, policy_lin, capacity_frac=capacity_frac)\n",
    "    \n",
    "    policy_wte = make_wait_till_end_policy(best_thr_wte)\n",
    "    stats_wte  = simulate_policy_with_sick_capacity(G_test_eval, policy_wte, capacity_frac=capacity_frac)\n",
    "    \n",
    "    # For DP, need bucket info\n",
    "    G_test_eval_dp = G_test_eval.copy()\n",
    "    G_test_eval_dp['risk_bucket'] = G_test_eval_dp['risk_score'].apply(to_bucket)\n",
    "    stats_dp = simulate_policy_with_sick_capacity(G_test_eval_dp, dp_policy_final, capacity_frac=capacity_frac)\n",
    "    \n",
    "    # Build final table\n",
    "    table = pd.DataFrame({\n",
    "        'Method': [\n",
    "            'Constant Threshold',\n",
    "            'Dynamic Threshold-R',\n",
    "            'Linear Threshold',\n",
    "            'Wait Till End',\n",
    "            'DP-based Policy'\n",
    "        ],\n",
    "        'Cost': [\n",
    "            stats_const['cost'],\n",
    "            stats_dyn['cost'],\n",
    "            stats_lin['cost'],\n",
    "            stats_wte['cost'],\n",
    "            stats_dp['cost']\n",
    "        ],\n",
    "        'Precision (%)': [\n",
    "            100*stats_const['precision'],\n",
    "            100*stats_dyn['precision'],\n",
    "            100*stats_lin['precision'],\n",
    "            100*stats_wte['precision'],\n",
    "            100*stats_dp['precision']\n",
    "        ],\n",
    "        'Recall (%)': [\n",
    "            100*stats_const['recall'],\n",
    "            100*stats_dyn['recall'],\n",
    "            100*stats_lin['recall'],\n",
    "            100*stats_wte['recall'],\n",
    "            100*stats_dp['recall']\n",
    "        ],\n",
    "        'Avg Treat Time': [\n",
    "            stats_const['avg_treatment_time'],\n",
    "            stats_dyn['avg_treatment_time'],\n",
    "            stats_lin['avg_treatment_time'],\n",
    "            stats_wte['avg_treatment_time'],\n",
    "            stats_dp['avg_treatment_time']\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    return table\n",
    "\n",
    "###############################################################################\n",
    "# 7. MAIN\n",
    "###############################################################################\n",
    "def main():\n",
    "    df_all = pd.read_csv(\"synthetic_patients_with_features.csv\")\n",
    "    \n",
    "    final_table = run_algorithm3_sequential_optimization_with_cap(\n",
    "        df_all, \n",
    "        n=4,            \n",
    "        seed=4,\n",
    "        capacity_frac=0.5  \n",
    "    )\n",
    "    \n",
    "    print(\"\\n=== ALGORITHM 3 (SEQUENTIAL OPTIMIZATION) WITH 50% CAP ON FINAL FOLD SICK PATIENTS ===\")\n",
    "    print(final_table.to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b288fa-6078-4c41-9717-d2a402fdf00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running replicate 1/30 (seed=412) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   692      34.615385        50.0        2.769231          0\n",
      "Dynamic Threshold-R   955      16.363636        50.0        3.363636          0\n",
      "   Linear Threshold   850      20.454545        50.0        1.181818          0\n",
      "      Wait Till End   660      75.000000        50.0       20.000000          0\n",
      "    DP-based Policy   534     100.000000        50.0        9.333333          0\n",
      "\n",
      "=== Running replicate 2/30 (seed=413) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   849      33.333333        50.0        2.393939          1\n",
      "Dynamic Threshold-R  1042      19.642857        50.0        2.910714          1\n",
      "   Linear Threshold   974      22.916667        50.0        1.125000          1\n",
      "      Wait Till End   770     100.000000        50.0       20.000000          1\n",
      "    DP-based Policy   651      91.666667        50.0        8.750000          1\n",
      "\n",
      "=== Running replicate 3/30 (seed=414) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   909      44.444444        48.0        4.111111          2\n",
      "Dynamic Threshold-R  1014      26.666667        48.0        3.022222          2\n",
      "   Linear Threshold   935      32.432432        48.0        0.945946          2\n",
      "      Wait Till End   910      85.714286        48.0       20.000000          2\n",
      "    DP-based Policy   806      66.666667        48.0        9.277778          2\n",
      "\n",
      "=== Running replicate 4/30 (seed=415) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   877      42.857143        48.0        2.464286          3\n",
      "Dynamic Threshold-R  1101      23.529412        48.0        2.960784          3\n",
      "   Linear Threshold  1037      26.666667        48.0        1.466667          3\n",
      "      Wait Till End   890     100.000000        48.0       20.000000          3\n",
      "    DP-based Policy   779      85.714286        48.0        8.357143          3\n",
      "\n",
      "=== Running replicate 5/30 (seed=416) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   834      40.740741   47.826087        2.740741          4\n",
      "Dynamic Threshold-R   997      23.913043   47.826087        2.152174          4\n",
      "   Linear Threshold   965      26.190476   47.826087        1.309524          4\n",
      "      Wait Till End   830      91.666667   47.826087       20.000000          4\n",
      "    DP-based Policy   722      91.666667   47.826087        9.500000          4\n",
      "\n",
      "=== Running replicate 6/30 (seed=417) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   903      54.166667   48.148148        3.875000          5\n",
      "Dynamic Threshold-R  1111      26.530612   48.148148        2.326531          5\n",
      "   Linear Threshold  1064      29.545455   48.148148        1.272727          5\n",
      "      Wait Till End   970      92.857143   48.148148       20.000000          5\n",
      "    DP-based Policy   858      81.250000   48.148148       10.062500          5\n",
      "\n",
      "=== Running replicate 7/30 (seed=418) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   789      28.125000   47.368421        1.906250          6\n",
      "Dynamic Threshold-R   935      18.367347   47.368421        2.020408          6\n",
      "   Linear Threshold   885      20.454545   47.368421        0.840909          6\n",
      "      Wait Till End   700      81.818182   47.368421       20.000000          6\n",
      "    DP-based Policy   591      81.818182   47.368421        8.090909          6\n",
      "\n",
      "=== Running replicate 8/30 (seed=419) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   986      37.142857        50.0        3.342857          7\n",
      "Dynamic Threshold-R  1133      23.636364        50.0        2.581818          7\n",
      "   Linear Threshold  1081      26.000000        50.0        1.300000          7\n",
      "      Wait Till End   910     100.000000        50.0       20.000000          7\n",
      "    DP-based Policy   778      86.666667        50.0        7.466667          7\n",
      "\n",
      "=== Running replicate 9/30 (seed=420) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   847      33.333333   47.619048        3.266667          8\n",
      "Dynamic Threshold-R  1057      18.867925   47.619048        3.018868          8\n",
      "   Linear Threshold   977      22.222222   47.619048        1.711111          8\n",
      "      Wait Till End   750     100.000000   47.619048       20.000000          8\n",
      "    DP-based Policy   669      90.909091   47.619048       10.090909          8\n",
      "\n",
      "=== Running replicate 10/30 (seed=421) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   895      27.777778   47.619048        2.361111          9\n",
      "Dynamic Threshold-R  1015      19.607843   47.619048        2.607843          9\n",
      "   Linear Threshold   954      22.222222   47.619048        1.200000          9\n",
      "      Wait Till End   770      83.333333   47.619048       20.000000          9\n",
      "    DP-based Policy   679      71.428571   47.619048        6.928571          9\n",
      "\n",
      "=== Running replicate 11/30 (seed=422) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   864      37.931034   47.826087        2.965517         10\n",
      "Dynamic Threshold-R  1055      22.000000   47.826087        3.180000         10\n",
      "   Linear Threshold   987      25.581395   47.826087        1.558140         10\n",
      "      Wait Till End   830      91.666667   47.826087       20.000000         10\n",
      "    DP-based Policy   724      73.333333   47.826087        8.133333         10\n",
      "\n",
      "=== Running replicate 12/30 (seed=423) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold  1059      35.897436        50.0        2.794872         11\n",
      "Dynamic Threshold-R  1201      24.561404        50.0        1.912281         11\n",
      "   Linear Threshold  1161      26.415094        50.0        1.377358         11\n",
      "      Wait Till End   990      93.333333        50.0       20.000000         11\n",
      "    DP-based Policy   879      77.777778        50.0       10.000000         11\n",
      "\n",
      "=== Running replicate 13/30 (seed=424) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   912      56.000000        50.0        4.080000         12\n",
      "Dynamic Threshold-R  1117      28.000000        50.0        2.760000         12\n",
      "   Linear Threshold  1044      32.558140        50.0        1.255814         12\n",
      "      Wait Till End   980     100.000000        50.0       20.000000         12\n",
      "    DP-based Policy   828      93.333333        50.0        8.733333         12\n",
      "\n",
      "=== Running replicate 14/30 (seed=425) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   588      25.000000        50.0        1.000000         13\n",
      "Dynamic Threshold-R   840      12.500000        50.0        3.714286         13\n",
      "   Linear Threshold   690      17.073171        50.0        0.073171         13\n",
      "      Wait Till End   500      87.500000        50.0       20.000000         13\n",
      "    DP-based Policy   418      70.000000        50.0        4.500000         13\n",
      "\n",
      "=== Running replicate 15/30 (seed=426) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   775      37.931034        50.0        1.551724         14\n",
      "Dynamic Threshold-R  1037      19.298246        50.0        2.175439         14\n",
      "   Linear Threshold   985      21.568627        50.0        0.764706         14\n",
      "      Wait Till End   800      78.571429        50.0       20.000000         14\n",
      "    DP-based Policy   664      84.615385        50.0        7.538462         14\n",
      "\n",
      "=== Running replicate 16/30 (seed=427) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   869      28.571429   47.619048        2.028571         15\n",
      "Dynamic Threshold-R  1029      18.518519   47.619048        3.037037         15\n",
      "   Linear Threshold   939      22.222222   47.619048        0.866667         15\n",
      "      Wait Till End   760      90.909091   47.619048       20.000000         15\n",
      "    DP-based Policy   686      71.428571   47.619048       10.428571         15\n",
      "\n",
      "=== Running replicate 17/30 (seed=428) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   725      34.615385   47.368421        2.115385         16\n",
      "Dynamic Threshold-R   971      16.363636   47.368421        2.800000         16\n",
      "   Linear Threshold   881      19.565217   47.368421        0.326087         16\n",
      "      Wait Till End   680     100.000000   47.368421       20.000000         16\n",
      "    DP-based Policy   603      81.818182   47.368421        9.272727         16\n",
      "\n",
      "=== Running replicate 18/30 (seed=429) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   983      42.424242        50.0        2.818182         17\n",
      "Dynamic Threshold-R  1179      24.561404        50.0        3.561404         17\n",
      "   Linear Threshold  1091      29.787234        50.0        1.297872         17\n",
      "      Wait Till End   980     100.000000        50.0       20.000000         17\n",
      "    DP-based Policy   859      87.500000        50.0       11.062500         17\n",
      "\n",
      "=== Running replicate 19/30 (seed=430) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   798      35.714286   47.619048        2.428571         18\n",
      "Dynamic Threshold-R  1035      17.857143   47.619048        2.785714         18\n",
      "   Linear Threshold   935      21.739130   47.619048        0.543478         18\n",
      "      Wait Till End   770      83.333333   47.619048       20.000000         18\n",
      "    DP-based Policy   649      90.909091   47.619048        8.727273         18\n",
      "\n",
      "=== Running replicate 20/30 (seed=431) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   943      48.148148   48.148148        3.814815         19\n",
      "Dynamic Threshold-R  1165      25.000000   48.148148        2.750000         19\n",
      "   Linear Threshold  1105      28.260870   48.148148        1.673913         19\n",
      "      Wait Till End   960     100.000000   48.148148       20.000000         19\n",
      "    DP-based Policy   844      81.250000   48.148148        8.750000         19\n",
      "\n",
      "=== Running replicate 21/30 (seed=432) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   965      45.161290        50.0        3.096774         20\n",
      "Dynamic Threshold-R  1119      28.000000        50.0        1.960000         20\n",
      "   Linear Threshold  1089      29.787234        50.0        1.297872         20\n",
      "      Wait Till End   980     100.000000        50.0       20.000000         20\n",
      "    DP-based Policy   835      93.333333        50.0        8.466667         20\n",
      "\n",
      "=== Running replicate 22/30 (seed=433) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold  1031      57.692308   48.387097        4.653846         21\n",
      "Dynamic Threshold-R  1242      27.777778   48.387097        2.685185         21\n",
      "   Linear Threshold  1182      31.250000   48.387097        1.083333         21\n",
      "      Wait Till End  1100     100.000000   48.387097       20.000000         21\n",
      "    DP-based Policy   929     100.000000   48.387097        8.600000         21\n",
      "\n",
      "=== Running replicate 23/30 (seed=434) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   926      37.500000        48.0        2.406250         22\n",
      "Dynamic Threshold-R  1183      20.000000        48.0        2.433333         22\n",
      "   Linear Threshold  1120      22.641509        48.0        1.207547         22\n",
      "      Wait Till End   900      92.307692        48.0       20.000000         22\n",
      "    DP-based Policy   790      75.000000        48.0        7.500000         22\n",
      "\n",
      "=== Running replicate 24/30 (seed=435) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   887      34.375000   47.826087        2.406250         23\n",
      "Dynamic Threshold-R  1041      22.000000   47.826087        2.620000         23\n",
      "   Linear Threshold   983      25.000000   47.826087        1.250000         23\n",
      "      Wait Till End   830      91.666667   47.826087       20.000000         23\n",
      "    DP-based Policy   696     100.000000   47.826087        8.727273         23\n",
      "\n",
      "=== Running replicate 25/30 (seed=436) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold  1019      38.888889        50.0        2.750000         24\n",
      "Dynamic Threshold-R  1155      25.000000        50.0        1.750000         24\n",
      "   Linear Threshold  1113      27.450980        50.0        0.882353         24\n",
      "      Wait Till End   980     100.000000        50.0       20.000000         24\n",
      "    DP-based Policy   862      87.500000        50.0       11.250000         24\n",
      "\n",
      "=== Running replicate 26/30 (seed=437) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold  1025      46.666667   48.275862        3.933333         25\n",
      "Dynamic Threshold-R  1167      28.571429   48.275862        3.061224         25\n",
      "   Linear Threshold  1118      32.558140   48.275862        1.813953         25\n",
      "      Wait Till End  1030     100.000000   48.275862       20.000000         25\n",
      "    DP-based Policy   900      87.500000   48.275862        8.375000         25\n",
      "\n",
      "=== Running replicate 27/30 (seed=438) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold  1022      28.571429        48.0        1.714286         26\n",
      "Dynamic Threshold-R  1117      21.428571        48.0        2.000000         26\n",
      "   Linear Threshold  1078      23.529412        48.0        0.803922         26\n",
      "      Wait Till End   890     100.000000        48.0       20.000000         26\n",
      "    DP-based Policy   808      80.000000        48.0       11.666667         26\n",
      "\n",
      "=== Running replicate 28/30 (seed=439) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   917      27.500000        50.0        1.925000         27\n",
      "Dynamic Threshold-R  1108      18.032787        50.0        2.131148         27\n",
      "   Linear Threshold  1058      19.642857        50.0        1.035714         27\n",
      "      Wait Till End   770     100.000000        50.0       20.000000         27\n",
      "    DP-based Policy   662      84.615385        50.0        8.769231         27\n",
      "\n",
      "=== Running replicate 29/30 (seed=440) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   944      41.935484        50.0        3.677419         28\n",
      "Dynamic Threshold-R  1090      26.000000        50.0        2.500000         28\n",
      "   Linear Threshold  1066      28.260870        50.0        1.869565         28\n",
      "      Wait Till End   910     100.000000        50.0       20.000000         28\n",
      "    DP-based Policy   759      92.857143        50.0        7.214286         28\n",
      "\n",
      "=== Running replicate 30/30 (seed=441) ===\n",
      "             Method  Cost  Precision (%)  Recall (%)  Avg Treat Time  Replicate\n",
      " Constant Threshold   887      28.571429   47.619048        2.514286         29\n",
      "Dynamic Threshold-R  1089      16.949153   47.619048        2.237288         29\n",
      "   Linear Threshold  1037      18.518519   47.619048        1.370370         29\n",
      "      Wait Till End   760      90.909091   47.619048       20.000000         29\n",
      "    DP-based Policy   668      76.923077   47.619048        7.692308         29\n",
      "\n",
      "=== SUMMARY ACROSS ALL REPLICATES ===\n",
      "             Method   mean_cost   std_cost  mean_precision  std_precision  mean_recall  std_recall  mean_ttime  std_ttime\n",
      " Constant Threshold  890.666667 106.753126       38.187739       8.606648    48.708987     1.09551    2.796876   0.856496\n",
      "    DP-based Policy  737.666667 117.498154       84.582714       9.111979    48.708987     1.09551    8.775515   1.440654\n",
      "Dynamic Threshold-R 1076.666667  87.692776       21.984859       4.221838    48.708987     1.09551    2.633978   0.502112\n",
      "   Linear Threshold 1012.800000 104.216419       25.083862       4.439916    48.708987     1.09551    1.156851   0.408112\n",
      "      Wait Till End  852.000000 130.050388       93.686230       7.572632    48.708987     1.09551   20.000000   0.000000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SEQUENTIAL OPTIMIZATION (ALGORITHM 3) FOR HEMORRHAGE DIAGNOSIS & TREATMENT\n",
    "WITH A 50% CAP ON SICK PATIENTS, RUN MULTIPLE REPLICATES AND REPORT MEAN/STD.\n",
    "\n",
    "Requirements:\n",
    "  pip install numpy pandas scikit-learn catboost\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Sklearn models, metrics, etc.\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "# CatBoost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 1. GLOBAL PARAMETERS\n",
    "###############################################################################\n",
    "FP_COST = 10\n",
    "FN_COST = 50\n",
    "D_COST  = 1\n",
    "T_MAX   = 21   # maximum discrete time steps (0..T_MAX-1)\n",
    "GAMMA_CANDIDATES = [0.95, 0.99]  # Example DP discount factors to try\n",
    "\n",
    "# Hyperparameter grids for ML models\n",
    "RF_PARAM_GRID = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "GB_PARAM_GRID = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "CATBOOST_PARAM_GRID = {\n",
    "    'iterations': [50, 100],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'depth': [3, 5]\n",
    "}\n",
    "\n",
    "###############################################################################\n",
    "# 2. HELPER FUNCTIONS (DATA SPLITS, MODEL TRAINING, ETC.)\n",
    "###############################################################################\n",
    "def split_into_nplus1_groups(df, n=4, seed=0):\n",
    "    \"\"\"\n",
    "    Shuffle patient IDs and split ~evenly into (n+1) groups: G1, G2, ..., G_{n+1}.\n",
    "    Example usage: n=4 => 5 groups total.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    unique_pids = df['patient_id'].unique()\n",
    "    rng.shuffle(unique_pids)\n",
    "    \n",
    "    N = len(unique_pids)\n",
    "    num_groups = n + 1\n",
    "    group_size = int(np.ceil(N / num_groups))\n",
    "    \n",
    "    groups = []\n",
    "    start_idx = 0\n",
    "    for i in range(num_groups):\n",
    "        end_idx = min(start_idx + group_size, N)\n",
    "        group_pids = unique_pids[start_idx:end_idx]\n",
    "        group_df   = df[df['patient_id'].isin(group_pids)].copy()\n",
    "        groups.append(group_df)\n",
    "        start_idx = end_idx\n",
    "    return groups\n",
    "\n",
    "def compute_auc_score(y_true, y_prob):\n",
    "    \"\"\"Compute AUC safely. If only one class, return 0.5.\"\"\"\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return 0.5\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def train_and_select_best_model(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Trains multiple models (RandomForest, GB, CatBoost)\n",
    "    over small hyperparam grids, picks best by AUC.\n",
    "    \n",
    "    Returns: (best_model, best_auc, best_model_name)\n",
    "    \"\"\"\n",
    "    best_auc = -1.0\n",
    "    best_model = None\n",
    "    best_name  = None\n",
    "    \n",
    "    # 1) RandomForest\n",
    "    for params in ParameterGrid(RF_PARAM_GRID):\n",
    "        rf = RandomForestClassifier(random_state=0, **params)\n",
    "        rf.fit(X_train, y_train)\n",
    "        val_prob = rf.predict_proba(X_val)[:,1]\n",
    "        auc_val  = compute_auc_score(y_val, val_prob)\n",
    "        if auc_val > best_auc:\n",
    "            best_auc   = auc_val\n",
    "            best_model = rf\n",
    "            best_name  = f\"RandomForest_{params}\"\n",
    "    \n",
    "    # 2) GradientBoosting\n",
    "    for params in ParameterGrid(GB_PARAM_GRID):\n",
    "        gb = GradientBoostingClassifier(random_state=0, **params)\n",
    "        gb.fit(X_train, y_train)\n",
    "        val_prob = gb.predict_proba(X_val)[:,1]\n",
    "        auc_val  = compute_auc_score(y_val, val_prob)\n",
    "        if auc_val > best_auc:\n",
    "            best_auc   = auc_val\n",
    "            best_model = gb\n",
    "            best_name  = f\"GradientBoosting_{params}\"\n",
    "    \n",
    "    # 3) CatBoost\n",
    "    for params in ParameterGrid(CATBOOST_PARAM_GRID):\n",
    "        cb = CatBoostClassifier(verbose=0, random_state=0, **params)\n",
    "        cb.fit(X_train, y_train)\n",
    "        val_prob = cb.predict_proba(X_val)[:,1]\n",
    "        auc_val  = compute_auc_score(y_val, val_prob)\n",
    "        if auc_val > best_auc:\n",
    "            best_auc   = auc_val\n",
    "            best_model = cb\n",
    "            best_name  = f\"CatBoost_{params}\"\n",
    "    \n",
    "    return best_model, best_auc, best_name\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 3. POLICY SIMULATION FUNCTIONS\n",
    "###############################################################################\n",
    "def simulate_policy(df, policy_func):\n",
    "    \"\"\"\n",
    "    df must contain:\n",
    "      - patient_id\n",
    "      - time\n",
    "      - risk_score\n",
    "      - label (0 or 1)\n",
    "    \n",
    "    policy_func(patient_rows) -> treat_time (int) or None\n",
    "    \n",
    "    Returns a dictionary of relevant metrics: total cost, precision, recall, etc.\n",
    "    (Unconstrained treatment for all recommended patients.)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for pid, grp in df.groupby('patient_id'):\n",
    "        grp = grp.sort_values('time')\n",
    "        label = grp['label'].iloc[0]\n",
    "        \n",
    "        treat_time = policy_func(grp)\n",
    "        \n",
    "        if treat_time is None:\n",
    "            # never treated\n",
    "            if label == 1:\n",
    "                cost = FN_COST\n",
    "                tp   = 0\n",
    "            else:\n",
    "                cost = 0\n",
    "                tp   = 0\n",
    "            fp = 0\n",
    "            treat_flag = 0\n",
    "            ttime = None\n",
    "        else:\n",
    "            treat_flag = 1\n",
    "            if label == 1:\n",
    "                cost = D_COST * treat_time\n",
    "                tp   = 1\n",
    "                fp   = 0\n",
    "            else:\n",
    "                cost = FP_COST\n",
    "                tp   = 0\n",
    "                fp   = 1\n",
    "            ttime = treat_time\n",
    "        \n",
    "        results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': treat_flag,\n",
    "            'treat_time': ttime,\n",
    "            'cost': cost,\n",
    "            'tp': tp,\n",
    "            'fp': fp\n",
    "        })\n",
    "    \n",
    "    df_res     = pd.DataFrame(results)\n",
    "    total_cost = df_res['cost'].sum()\n",
    "    \n",
    "    treated_df = df_res[df_res['treated']==1]\n",
    "    tp_sum = treated_df['tp'].sum()\n",
    "    fp_sum = treated_df['fp'].sum()\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        precision = tp_sum / (tp_sum + fp_sum)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "    \n",
    "    sick_df = df_res[df_res['label']==1]\n",
    "    total_sick = len(sick_df)\n",
    "    if total_sick > 0:\n",
    "        recall = tp_sum / total_sick\n",
    "    else:\n",
    "        recall = 0.0\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        valid_tt = treated_df['treat_time'].dropna()\n",
    "        avg_tt   = valid_tt.mean() if len(valid_tt) > 0 else 0.0\n",
    "    else:\n",
    "        avg_tt = 0.0\n",
    "    \n",
    "    return {\n",
    "        'cost': total_cost,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'avg_treatment_time': avg_tt\n",
    "    }\n",
    "\n",
    "def simulate_policy_with_sick_capacity(df, policy_func, capacity_frac=0.5):\n",
    "    \"\"\"\n",
    "    We enforce that at most (capacity_frac) fraction of the *sick* patients\n",
    "    in this fold can be treated.\n",
    "\n",
    "    Steps:\n",
    "      1. Identify which patients are \"recommended\" for treatment by the policy_func.\n",
    "      2. Separate recommended patients into \"sick recommended\" vs. \"healthy recommended\".\n",
    "      3. Among the recommended *sick* patients, we can only treat up to\n",
    "         floor(capacity_frac * total_sick_in_this_fold). We'll choose the top (by risk_score).\n",
    "      4. We treat all recommended *healthy* patients with no limit.\n",
    "      5. Everyone else is not treated (FN cost if sick, 0 cost if healthy).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    recommended_sick = []     # (pid, label=1, time_treated, risk_score)\n",
    "    recommended_healthy = []  # (pid, label=0, time_treated, risk_score)\n",
    "    \n",
    "    # Count total sick in this fold\n",
    "    all_sick_df = df[df['label']==1]\n",
    "    num_sick = all_sick_df['patient_id'].nunique()\n",
    "    capacity_num = int(np.floor(capacity_frac * num_sick)) if num_sick > 0 else 0\n",
    "    \n",
    "    # Step 1) Check policy recommendation\n",
    "    for pid, grp in df.groupby('patient_id'):\n",
    "        grp = grp.sort_values('time')\n",
    "        label = grp['label'].iloc[0]\n",
    "        \n",
    "        treat_time = policy_func(grp)\n",
    "        \n",
    "        if treat_time is None:\n",
    "            # not recommended => cost is assigned later\n",
    "            results.append({\n",
    "                'patient_id': pid,\n",
    "                'label': label,\n",
    "                'treated': 0,\n",
    "                'treat_time': None,\n",
    "                'cost': None,\n",
    "                'tp': 0,\n",
    "                'fp': 0\n",
    "            })\n",
    "        else:\n",
    "            # recommended => store in recommended_sick or recommended_healthy\n",
    "            row_t = grp[grp['time']==treat_time].iloc[0]\n",
    "            recommended_risk = row_t['risk_score']\n",
    "            if label == 1:\n",
    "                recommended_sick.append((pid, label, treat_time, recommended_risk))\n",
    "            else:\n",
    "                recommended_healthy.append((pid, label, treat_time, recommended_risk))\n",
    "    \n",
    "    # Step 2) Sort recommended sick by descending risk_score\n",
    "    recommended_sick.sort(key=lambda x: x[3], reverse=True)\n",
    "    # Step 3) Actually treat only top capacity_num from recommended sick\n",
    "    treat_sick_subset = recommended_sick[:capacity_num]\n",
    "    not_treat_sick_subset = recommended_sick[capacity_num:]\n",
    "    \n",
    "    # Step 4) We treat ALL recommended healthy, no limit\n",
    "    treat_healthy_subset = recommended_healthy\n",
    "    \n",
    "    # Build final result records for the treated subsets\n",
    "    treat_results = []\n",
    "    # 4a) SICK actually treated\n",
    "    for (pid, label, ttime, rsk) in treat_sick_subset:\n",
    "        cost_ = D_COST * ttime  # treat_time * D\n",
    "        treat_results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': 1,\n",
    "            'treat_time': ttime,\n",
    "            'cost': cost_,\n",
    "            'tp': 1,\n",
    "            'fp': 0\n",
    "        })\n",
    "    # 4b) HEALTHY actually treated\n",
    "    for (pid, label, ttime, rsk) in treat_healthy_subset:\n",
    "        cost_ = FP_COST  # healthy => false positive cost\n",
    "        treat_results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': 1,\n",
    "            'treat_time': ttime,\n",
    "            'cost': cost_,\n",
    "            'tp': 0,\n",
    "            'fp': 1\n",
    "        })\n",
    "    \n",
    "    # Step 5) Build final result records for not-treated subsets\n",
    "    not_treat_results = []\n",
    "    # (a) SICK recommended but not treated (exceeds capacity)\n",
    "    for (pid, label, ttime, rsk) in not_treat_sick_subset:\n",
    "        cost_ = FN_COST  # label==1 => sick\n",
    "        not_treat_results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': 0,\n",
    "            'treat_time': None,\n",
    "            'cost': cost_,\n",
    "            'tp': 0,\n",
    "            'fp': 0\n",
    "        })\n",
    "    # (b) Those who were never recommended\n",
    "    for row in results:\n",
    "        if row['cost'] is None:\n",
    "            # not recommended\n",
    "            if row['label'] == 1:\n",
    "                row['cost'] = FN_COST\n",
    "            else:\n",
    "                row['cost'] = 0\n",
    "            not_treat_results.append(row)\n",
    "    \n",
    "    df_res = pd.DataFrame(treat_results + not_treat_results)\n",
    "    \n",
    "    # Compute final stats\n",
    "    total_cost = df_res['cost'].sum()\n",
    "    treated_df = df_res[df_res['treated']==1]\n",
    "    \n",
    "    tp_sum = treated_df['tp'].sum()\n",
    "    fp_sum = treated_df['fp'].sum()\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        precision = tp_sum / (tp_sum + fp_sum)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "    \n",
    "    sick_df = df_res[df_res['label']==1]\n",
    "    total_sick = len(sick_df)\n",
    "    if total_sick > 0:\n",
    "        recall = tp_sum / total_sick\n",
    "    else:\n",
    "        recall = 0.0\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        valid_tt = treated_df['treat_time'].dropna()\n",
    "        avg_tt   = valid_tt.mean() if len(valid_tt) > 0 else 0.0\n",
    "    else:\n",
    "        avg_tt = 0.0\n",
    "    \n",
    "    return {\n",
    "        'cost': total_cost,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'avg_treatment_time': avg_tt\n",
    "    }\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 4. BENCHMARK THRESHOLD-BASED POLICIES\n",
    "###############################################################################\n",
    "def make_constant_threshold_policy(thr):\n",
    "    \"\"\"Returns a policy function that treats as soon as risk_score >= thr.\"\"\"\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            if row['risk_score'] >= thr:\n",
    "                return int(row['time'])\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def make_dynamic_threshold_policy(thr_vec):\n",
    "    \"\"\"Returns a policy function using a time-dependent threshold vector thr_vec.\"\"\"\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = int(row['time'])\n",
    "            if t < len(thr_vec):\n",
    "                if row['risk_score'] >= thr_vec[t]:\n",
    "                    return t\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def make_linear_threshold_policy(A,B):\n",
    "    \"\"\"Returns a policy function threshold(t) = clip(A*t + B, 0, 1).\"\"\"\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = int(row['time'])\n",
    "            thr = A*t + B\n",
    "            thr = np.clip(thr,0,1)\n",
    "            if row['risk_score'] >= thr:\n",
    "                return t\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "def make_wait_till_end_policy(thr):\n",
    "    \"\"\"Returns a policy function that treats only at final time if risk_score >= thr.\"\"\"\n",
    "    def policy_func(patient_rows):\n",
    "        final_t = patient_rows['time'].max()\n",
    "        final_row = patient_rows[patient_rows['time']==final_t].iloc[0]\n",
    "        if final_row['risk_score'] >= thr:\n",
    "            return int(final_t)\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 5. DATA-DRIVEN DP (UNCONSTRAINED)\n",
    "###############################################################################\n",
    "def to_bucket(prob):\n",
    "    \"\"\"Simple function to map prob into a 5-bucket scale [0..4].\"\"\"\n",
    "    b = int(prob * 5)\n",
    "    return min(b, 4)\n",
    "\n",
    "def estimate_transition_and_sick_probs(df_train, T=20, n_buckets=5):\n",
    "    \"\"\"\n",
    "    p_trans[t,b,b_next], p_sick[t,b]\n",
    "    df_train has columns: patient_id, time, risk_bucket, label\n",
    "    \"\"\"\n",
    "    transition_counts = np.zeros((T-1, n_buckets, n_buckets), dtype=float)\n",
    "    bucket_counts     = np.zeros((T, n_buckets), dtype=float)\n",
    "    sick_counts       = np.zeros((T, n_buckets), dtype=float)\n",
    "    \n",
    "    df_sorted = df_train.sort_values(['patient_id','time'])\n",
    "    for pid, grp in df_sorted.groupby('patient_id'):\n",
    "        grp = grp.sort_values('time')\n",
    "        rows = grp.to_dict('records')\n",
    "        \n",
    "        for i, row in enumerate(rows):\n",
    "            t = int(row['time'])\n",
    "            b = int(row['risk_bucket'])\n",
    "            lbl = row['label']\n",
    "            \n",
    "            if t < T:\n",
    "                bucket_counts[t,b] += 1\n",
    "                sick_counts[t,b]   += lbl\n",
    "            \n",
    "            if i < len(rows)-1:\n",
    "                nxt = rows[i+1]\n",
    "                t_next = nxt['time']\n",
    "                b_next = nxt['risk_bucket']\n",
    "                # Count transitions only if t_next = t+1 (consecutive time)\n",
    "                if (t_next == t+1) and (t < T-1):\n",
    "                    transition_counts[t,b,b_next] += 1\n",
    "    \n",
    "    p_trans = np.zeros((T-1, n_buckets, n_buckets), dtype=float)\n",
    "    for t_ in range(T-1):\n",
    "        for b_ in range(n_buckets):\n",
    "            denom = transition_counts[t_,b_,:].sum()\n",
    "            if denom>0:\n",
    "                p_trans[t_,b_,:] = transition_counts[t_,b_,:] / denom\n",
    "            else:\n",
    "                # if no data, assume \"self-transition\"\n",
    "                p_trans[t_,b_,b_] = 1.0\n",
    "    \n",
    "    p_sick = np.zeros((T, n_buckets), dtype=float)\n",
    "    for t_ in range(T):\n",
    "        for b_ in range(n_buckets):\n",
    "            denom = bucket_counts[t_,b_]\n",
    "            if denom>0:\n",
    "                p_sick[t_,b_] = sick_counts[t_,b_] / denom\n",
    "            else:\n",
    "                p_sick[t_,b_] = 0.0\n",
    "    return p_trans, p_sick\n",
    "\n",
    "def train_data_driven_dp_unconstrained(p_trans, p_sick, \n",
    "                                       FP=10, FN=50, D=1, gamma=0.99, T=20):\n",
    "    \"\"\"\n",
    "    Standard DP for unconstrained scenario:\n",
    "      V[t,b] = min( cost_treat_now, gamma * expected_future_if_wait )\n",
    "    \"\"\"\n",
    "    n_buckets = p_sick.shape[1]\n",
    "    V = np.zeros((T+1, n_buckets))\n",
    "    pi_ = np.zeros((T, n_buckets), dtype=int)\n",
    "    \n",
    "    # boundary at t=T => no more decisions\n",
    "    for b in range(n_buckets):\n",
    "        # If we ended up treating exactly at T-1, cost could be:\n",
    "        #    cost if sick: D*(T-1)\n",
    "        #    cost if healthy: FP\n",
    "        # If not treated at all: cost if sick: FN; else 0\n",
    "        cost_treat   = p_sick[T-1,b]*(D*(T-1)) + (1-p_sick[T-1,b])*FP\n",
    "        cost_notreat = p_sick[T-1,b]*FN\n",
    "        V[T,b] = min(cost_treat, cost_notreat)\n",
    "    \n",
    "    for t in reversed(range(T)):\n",
    "        for b in range(n_buckets):\n",
    "            # treat now\n",
    "            cost_treat = p_sick[t,b]*(D*t) + (1-p_sick[t,b])*FP\n",
    "            \n",
    "            # wait\n",
    "            if t == T-1:\n",
    "                cost_wait = gamma * V[T,b]\n",
    "            else:\n",
    "                exp_future = 0.0\n",
    "                for b_next in range(n_buckets):\n",
    "                    exp_future += p_trans[t,b,b_next]*V[t+1,b_next]\n",
    "                cost_wait = gamma * exp_future\n",
    "            \n",
    "            if cost_treat <= cost_wait:\n",
    "                V[t,b]   = cost_treat\n",
    "                pi_[t,b] = 1\n",
    "            else:\n",
    "                V[t,b]   = cost_wait\n",
    "                pi_[t,b] = 0\n",
    "    \n",
    "    return V, pi_\n",
    "\n",
    "def make_dp_policy(V, pi_, T=20):\n",
    "    \"\"\"\n",
    "    Return a policy function that treats if pi[t,b]==1 at time t\n",
    "    for the bucket b of the risk score.\n",
    "    \"\"\"\n",
    "    def policy_func(patient_rows):\n",
    "        for _, row in patient_rows.iterrows():\n",
    "            t = int(row['time'])\n",
    "            if t < T:\n",
    "                b = int(row['risk_bucket'])\n",
    "                if pi_[t,b] == 1:\n",
    "                    return t\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "###############################################################################\n",
    "# 6. ALGORITHM 3 (SEQUENTIAL OPTIMIZATION) - BUT FINAL FOLD HAS 50% CAP\n",
    "###############################################################################\n",
    "def run_algorithm3_sequential_optimization_with_cap(df_all, n=4, seed=0, capacity_frac=0.5):\n",
    "    \"\"\"\n",
    "    Implements Algorithm 3 (Sequential Optimization) for hemorrhage diagnosis,\n",
    "    unconstrained on G1..G_n, BUT with a capacity_frac limit on how many sick \n",
    "    can be treated in the final holdout fold (G_{n+1}).\n",
    "\n",
    "    1) We split the data into (n+1) groups: G1,...,G_{n+1}.\n",
    "         Let G_{n+1} be the final holdout/test set.\n",
    "         G_cv = [G1..G_n] is used for cross-validation.\n",
    "    2) Stage 1: Choose best ML hyperparams by CV (maximize AUC).\n",
    "    3) Retrain final ML model on G1..G_n with best hyperparams.\n",
    "    4) Stage 2: With ML model fixed, choose best policy hyperparams by CV (min cost).\n",
    "    5) Evaluate final chosen methods on G_{n+1} with capacity_frac *SICK* limit.\n",
    "    \"\"\"\n",
    "    # Only consider time < T_MAX\n",
    "    df_all = df_all[df_all['time'] < T_MAX].copy()\n",
    "    \n",
    "    # 1) Split into n+1 groups\n",
    "    groups = split_into_nplus1_groups(df_all, n=n, seed=seed)\n",
    "    G_test = groups[-1]\n",
    "    G_cv   = groups[:-1]\n",
    "    \n",
    "    # Combine G1..G_n for final retraining\n",
    "    G_cv_concat = pd.concat(G_cv, ignore_index=True)\n",
    "    \n",
    "    ###########################################################################\n",
    "    # STAGE 1: ML hyperparam selection by CV (maximize AUC)\n",
    "    ###########################################################################\n",
    "    def cv_auc_for_ml(params, model_type):\n",
    "        total_auc = 0.0\n",
    "        for i_cv in range(n):\n",
    "            train_df_list = [G_cv[j] for j in range(n) if j != i_cv]\n",
    "            train_df = pd.concat(train_df_list, ignore_index=True)\n",
    "            val_df   = G_cv[i_cv]\n",
    "            \n",
    "            X_train = train_df[['EIT','NIRS','EIS']].values\n",
    "            y_train = train_df['label'].values\n",
    "            \n",
    "            X_val   = val_df[['EIT','NIRS','EIS']].values\n",
    "            y_val   = val_df['label'].values\n",
    "            \n",
    "            if model_type == 'rf':\n",
    "                mdl = RandomForestClassifier(random_state=0, **params)\n",
    "            elif model_type == 'gb':\n",
    "                mdl = GradientBoostingClassifier(random_state=0, **params)\n",
    "            else:\n",
    "                mdl = CatBoostClassifier(verbose=0, random_state=0, **params)\n",
    "            \n",
    "            mdl.fit(X_train, y_train)\n",
    "            val_prob = mdl.predict_proba(X_val)[:,1]\n",
    "            auc_val  = compute_auc_score(y_val, val_prob)\n",
    "            total_auc += auc_val\n",
    "        return total_auc\n",
    "    \n",
    "    best_overall_auc = -1.0\n",
    "    best_overall_params = None\n",
    "    best_model_type = None\n",
    "    \n",
    "    # 1) RandomForest\n",
    "    for params in ParameterGrid(RF_PARAM_GRID):\n",
    "        sum_auc = cv_auc_for_ml(params, 'rf')\n",
    "        if sum_auc > best_overall_auc:\n",
    "            best_overall_auc = sum_auc\n",
    "            best_overall_params = params\n",
    "            best_model_type = 'rf'\n",
    "    # 2) GradientBoosting\n",
    "    for params in ParameterGrid(GB_PARAM_GRID):\n",
    "        sum_auc = cv_auc_for_ml(params, 'gb')\n",
    "        if sum_auc > best_overall_auc:\n",
    "            best_overall_auc = sum_auc\n",
    "            best_overall_params = params\n",
    "            best_model_type = 'gb'\n",
    "    # 3) CatBoost\n",
    "    for params in ParameterGrid(CATBOOST_PARAM_GRID):\n",
    "        sum_auc = cv_auc_for_ml(params, 'cat')\n",
    "        if sum_auc > best_overall_auc:\n",
    "            best_overall_auc = sum_auc\n",
    "            best_overall_params = params\n",
    "            best_model_type = 'cat'\n",
    "    \n",
    "    # Retrain final ML on entire G_cv\n",
    "    if best_model_type == 'rf':\n",
    "        best_model = RandomForestClassifier(random_state=0, **best_overall_params)\n",
    "    elif best_model_type == 'gb':\n",
    "        best_model = GradientBoostingClassifier(random_state=0, **best_overall_params)\n",
    "    else:\n",
    "        best_model = CatBoostClassifier(verbose=0, random_state=0, **best_overall_params)\n",
    "    \n",
    "    X_cv_final = G_cv_concat[['EIT','NIRS','EIS']].values\n",
    "    y_cv_final = G_cv_concat['label'].values\n",
    "    best_model.fit(X_cv_final, y_cv_final)\n",
    "    \n",
    "    ###########################################################################\n",
    "    # STAGE 2: With ML model fixed, pick best policy hyperparams by CV (min cost)\n",
    "    ###########################################################################\n",
    "    def evaluate_policy_cost_cv(policy_maker_func, param):\n",
    "        total_cost = 0.0\n",
    "        for i_cv in range(n):\n",
    "            G_i = G_cv[i_cv].copy()\n",
    "            X_i = G_i[['EIT','NIRS','EIS']].values\n",
    "            prob_i = best_model.predict_proba(X_i)[:,1]\n",
    "            G_i['risk_score'] = prob_i\n",
    "            \n",
    "            policy_func = policy_maker_func(param)\n",
    "            stats_i = simulate_policy(G_i, policy_func)  # unconstrained in CV\n",
    "            total_cost += stats_i['cost']\n",
    "        return total_cost\n",
    "    \n",
    "    # (A) Constant threshold\n",
    "    possible_thresholds = np.linspace(0,1,21)\n",
    "    best_thr_const = None\n",
    "    best_const_cost = float('inf')\n",
    "    for thr_candidate in possible_thresholds:\n",
    "        cost_cv = evaluate_policy_cost_cv(make_constant_threshold_policy, thr_candidate)\n",
    "        if cost_cv < best_const_cost:\n",
    "            best_const_cost = cost_cv\n",
    "            best_thr_const  = thr_candidate\n",
    "    \n",
    "    # (B) Dynamic threshold (random search)\n",
    "    rng = np.random.RandomState(42)\n",
    "    threshold_candidates = [0.0,0.2,0.4,0.6,0.8,1.0]\n",
    "    dynamic_param_candidates = []\n",
    "    N_SAMPLES = 30\n",
    "    for _ in range(N_SAMPLES):\n",
    "        thr_vec = rng.choice(threshold_candidates, size=T_MAX-1)\n",
    "        dynamic_param_candidates.append(tuple(thr_vec))\n",
    "    \n",
    "    best_thr_vec = None\n",
    "    best_dyn_cost = float('inf')\n",
    "    for candidate_vec in dynamic_param_candidates:\n",
    "        cost_cv = evaluate_policy_cost_cv(make_dynamic_threshold_policy, candidate_vec)\n",
    "        if cost_cv < best_dyn_cost:\n",
    "            best_dyn_cost = cost_cv\n",
    "            best_thr_vec  = candidate_vec\n",
    "    \n",
    "    # (C) Linear threshold\n",
    "    A_candidates = np.linspace(-0.05, 0.01, 7)\n",
    "    B_candidates = np.linspace(0,0.6,2)\n",
    "    best_lin = None\n",
    "    best_lin_cost = float('inf')\n",
    "    for A_ in A_candidates:\n",
    "        for B_ in B_candidates:\n",
    "            cost_cv_fold = 0.0\n",
    "            for i_cv in range(n):\n",
    "                G_i = G_cv[i_cv].copy()\n",
    "                X_i = G_i[['EIT','NIRS','EIS']].values\n",
    "                prob_i = best_model.predict_proba(X_i)[:,1]\n",
    "                G_i['risk_score'] = prob_i\n",
    "                \n",
    "                policy_lin = make_linear_threshold_policy(A_, B_)\n",
    "                stats_i = simulate_policy(G_i, policy_lin)\n",
    "                cost_cv_fold += stats_i['cost']\n",
    "            if cost_cv_fold < best_lin_cost:\n",
    "                best_lin_cost = cost_cv_fold\n",
    "                best_lin = (A_, B_)\n",
    "    A_lin, B_lin = best_lin\n",
    "    \n",
    "    # (D) Wait-till-end threshold\n",
    "    best_thr_wte = None\n",
    "    best_wte_cost= float('inf')\n",
    "    for thr_candidate in possible_thresholds:\n",
    "        cost_cv = evaluate_policy_cost_cv(make_wait_till_end_policy, thr_candidate)\n",
    "        if cost_cv < best_wte_cost:\n",
    "            best_wte_cost   = cost_cv\n",
    "            best_thr_wte    = thr_candidate\n",
    "    \n",
    "    # (E) Data-driven DP: pick best gamma by cross-validation\n",
    "    def evaluate_dp_gamma_cv(gamma_val):\n",
    "        total_cost = 0.0\n",
    "        for i_cv in range(n):\n",
    "            # train transition model on all folds except i_cv\n",
    "            train_df_list = [G_cv[j] for j in range(n) if j != i_cv]\n",
    "            train_df = pd.concat(train_df_list, ignore_index=True)\n",
    "            \n",
    "            X_train = train_df[['EIT','NIRS','EIS']].values\n",
    "            prob_train = best_model.predict_proba(X_train)[:,1]\n",
    "            train_df['risk_score'] = prob_train\n",
    "            train_df['risk_bucket'] = train_df['risk_score'].apply(to_bucket)\n",
    "            \n",
    "            p_trans, p_sick = estimate_transition_and_sick_probs(train_df, T=T_MAX, n_buckets=5)\n",
    "            V_temp, pi_temp = train_data_driven_dp_unconstrained(\n",
    "                p_trans, p_sick,\n",
    "                FP=FP_COST, FN=FN_COST, D=D_COST,\n",
    "                gamma=gamma_val, T=T_MAX\n",
    "            )\n",
    "            dp_policy_temp = make_dp_policy(V_temp, pi_temp, T=T_MAX)\n",
    "            \n",
    "            # Evaluate on hold-out fold i_cv\n",
    "            G_i = G_cv[i_cv].copy()\n",
    "            X_i = G_i[['EIT','NIRS','EIS']].values\n",
    "            prob_i = best_model.predict_proba(X_i)[:,1]\n",
    "            G_i['risk_score'] = prob_i\n",
    "            G_i['risk_bucket'] = G_i['risk_score'].apply(to_bucket)\n",
    "            \n",
    "            stats_i = simulate_policy(G_i, dp_policy_temp)\n",
    "            total_cost += stats_i['cost']\n",
    "        return total_cost\n",
    "    \n",
    "    best_gamma = None\n",
    "    best_dp_cost= float('inf')\n",
    "    for gamma_ in GAMMA_CANDIDATES:\n",
    "        cost_cv_gamma = evaluate_dp_gamma_cv(gamma_)\n",
    "        if cost_cv_gamma < best_dp_cost:\n",
    "            best_dp_cost = cost_cv_gamma\n",
    "            best_gamma   = gamma_\n",
    "    \n",
    "    # Train final DP on G_cv_concat with best_gamma\n",
    "    G_cv_concat_dp = G_cv_concat.copy()\n",
    "    X_dp = G_cv_concat_dp[['EIT','NIRS','EIS']].values\n",
    "    prob_dp = best_model.predict_proba(X_dp)[:,1]\n",
    "    G_cv_concat_dp['risk_score'] = prob_dp\n",
    "    G_cv_concat_dp['risk_bucket'] = G_cv_concat_dp['risk_score'].apply(to_bucket)\n",
    "    \n",
    "    p_trans_final, p_sick_final = estimate_transition_and_sick_probs(\n",
    "        G_cv_concat_dp, T=T_MAX, n_buckets=5\n",
    "    )\n",
    "    V_final, pi_final = train_data_driven_dp_unconstrained(\n",
    "        p_trans_final, p_sick_final,\n",
    "        FP=FP_COST, FN=FN_COST, D=D_COST,\n",
    "        gamma=best_gamma, T=T_MAX\n",
    "    )\n",
    "    dp_policy_final = make_dp_policy(V_final, pi_final, T=T_MAX)\n",
    "    \n",
    "    ###########################################################################\n",
    "    # 7) Evaluate all final chosen methods on G_{n+1} with capacity constraint\n",
    "    ###########################################################################\n",
    "    G_test_eval = G_test.copy()\n",
    "    X_test = G_test_eval[['EIT','NIRS','EIS']].values\n",
    "    prob_test = best_model.predict_proba(X_test)[:,1]\n",
    "    G_test_eval['risk_score'] = prob_test\n",
    "    \n",
    "    # Simulate with capacity constraint\n",
    "    policy_const = make_constant_threshold_policy(best_thr_const)\n",
    "    stats_const  = simulate_policy_with_sick_capacity(G_test_eval, policy_const, capacity_frac=capacity_frac)\n",
    "    \n",
    "    policy_dyn = make_dynamic_threshold_policy(best_thr_vec)\n",
    "    stats_dyn  = simulate_policy_with_sick_capacity(G_test_eval, policy_dyn, capacity_frac=capacity_frac)\n",
    "    \n",
    "    policy_lin = make_linear_threshold_policy(A_lin, B_lin)\n",
    "    stats_lin  = simulate_policy_with_sick_capacity(G_test_eval, policy_lin, capacity_frac=capacity_frac)\n",
    "    \n",
    "    policy_wte = make_wait_till_end_policy(best_thr_wte)\n",
    "    stats_wte  = simulate_policy_with_sick_capacity(G_test_eval, policy_wte, capacity_frac=capacity_frac)\n",
    "    \n",
    "    # DP policy\n",
    "    G_test_eval_dp = G_test_eval.copy()\n",
    "    G_test_eval_dp['risk_bucket'] = G_test_eval_dp['risk_score'].apply(to_bucket)\n",
    "    stats_dp = simulate_policy_with_sick_capacity(G_test_eval_dp, dp_policy_final, capacity_frac=capacity_frac)\n",
    "    \n",
    "    # Build final table\n",
    "    table = pd.DataFrame({\n",
    "        'Method': [\n",
    "            'Constant Threshold',\n",
    "            'Dynamic Threshold-R',\n",
    "            'Linear Threshold',\n",
    "            'Wait Till End',\n",
    "            'DP-based Policy'\n",
    "        ],\n",
    "        'Cost': [\n",
    "            stats_const['cost'],\n",
    "            stats_dyn['cost'],\n",
    "            stats_lin['cost'],\n",
    "            stats_wte['cost'],\n",
    "            stats_dp['cost']\n",
    "        ],\n",
    "        'Precision (%)': [\n",
    "            100*stats_const['precision'],\n",
    "            100*stats_dyn['precision'],\n",
    "            100*stats_lin['precision'],\n",
    "            100*stats_wte['precision'],\n",
    "            100*stats_dp['precision']\n",
    "        ],\n",
    "        'Recall (%)': [\n",
    "            100*stats_const['recall'],\n",
    "            100*stats_dyn['recall'],\n",
    "            100*stats_lin['recall'],\n",
    "            100*stats_wte['recall'],\n",
    "            100*stats_dp['recall']\n",
    "        ],\n",
    "        'Avg Treat Time': [\n",
    "            stats_const['avg_treatment_time'],\n",
    "            stats_dyn['avg_treatment_time'],\n",
    "            stats_lin['avg_treatment_time'],\n",
    "            stats_wte['avg_treatment_time'],\n",
    "            stats_dp['avg_treatment_time']\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    return table\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 7. MAIN - RUN REPLICATES AND REPORT MEAN/STD\n",
    "###############################################################################\n",
    "def main():\n",
    "    df_all = pd.read_csv(\"synthetic_patients_with_features.csv\")\n",
    "    \n",
    "    NUM_REPLICATES = 30\n",
    "    all_results = []  # will store results (as DataFrames) for each replicate\n",
    "    \n",
    "    for rep in range(NUM_REPLICATES):\n",
    "        seed = 412 + rep\n",
    "        print(f\"\\n=== Running replicate {rep+1}/{NUM_REPLICATES} (seed={seed}) ===\")\n",
    "        \n",
    "        final_table = run_algorithm3_sequential_optimization_with_cap(\n",
    "            df_all,\n",
    "            n=4,  # number of CV folds\n",
    "            seed=seed,\n",
    "            capacity_frac=0.5\n",
    "        )\n",
    "        # Add replicate info (so we can track across runs)\n",
    "        final_table['Replicate'] = rep\n",
    "        all_results.append(final_table)\n",
    "        \n",
    "        # Optional: Print or inspect final_table for each run\n",
    "        print(final_table.to_string(index=False))\n",
    "    \n",
    "    # Combine all replicate results\n",
    "    combined_df = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # Now compute mean & std across replicates, grouped by method\n",
    "    summary = combined_df.groupby('Method').agg(\n",
    "        mean_cost=('Cost','mean'),\n",
    "        std_cost=('Cost','std'),\n",
    "        mean_precision=('Precision (%)','mean'),\n",
    "        std_precision=('Precision (%)','std'),\n",
    "        mean_recall=('Recall (%)','mean'),\n",
    "        std_recall=('Recall (%)','std'),\n",
    "        mean_ttime=('Avg Treat Time','mean'),\n",
    "        std_ttime=('Avg Treat Time','std')\n",
    "    ).reset_index()\n",
    "    \n",
    "    print(\"\\n=== SUMMARY ACROSS ALL REPLICATES ===\")\n",
    "    print(summary.to_string(index=False))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf8417f-a5d0-420c-8ec2-4de14be301d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
