{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6ff71c-3135-4cff-bac3-35bc54695c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ALGORITHM 0 RESULTS (CAPACITATED - 50% capacity) ===\n",
      "Training ADP model with max capacity (distinct patients): 28\n",
      "Episode 0/1000\n",
      "Episode 100/1000\n",
      "Episode 200/1000\n",
      "Episode 300/1000\n",
      "Episode 400/1000\n",
      "Episode 500/1000\n",
      "Episode 600/1000\n",
      "Episode 700/1000\n",
      "Episode 800/1000\n",
      "Episode 900/1000\n",
      "                        Method  Cost  Precision (%)  Recall (%)  Avg Treat Time\n",
      "Capacitated Constant Threshold  1800       0.000000    0.000000             0.0\n",
      "  Capacitated Linear Threshold  1680      27.777778   13.888889             0.0\n",
      "     Capacitated Wait Till End  1260     100.000000   50.000000            20.0\n",
      "               Capacitated ADP  1800       0.000000    0.000000             0.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CAPACITATED VALIDATION (ALGORITHM 0) FOR HEMORRHAGE DIAGNOSIS & TREATMENT\n",
    "with an ADP approach that does epsilon-greedy exploration.\n",
    "\n",
    "Requirements:\n",
    "  pip install numpy pandas scikit-learn catboost\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Sklearn models, metrics, etc.\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "# CatBoost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "###############################################################################\n",
    "# 1. GLOBAL PARAMETERS\n",
    "###############################################################################\n",
    "FP_COST = 10\n",
    "FN_COST = 50\n",
    "D_COST  = 1\n",
    "T_MAX   = 21   # maximum discrete time steps (0..T_MAX-1)\n",
    "CAPACITY_FACTOR = 0.5  # treat at most 50% of sick patients\n",
    "\n",
    "# Example small hyperparam grid:\n",
    "RF_PARAM_GRID = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "GB_PARAM_GRID = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "CATBOOST_PARAM_GRID = {\n",
    "    'iterations': [50, 100],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'depth': [3, 5]\n",
    "}\n",
    "\n",
    "###############################################################################\n",
    "# 2. HELPER FUNCTIONS\n",
    "###############################################################################\n",
    "def split_into_four_groups(df, seed=0):\n",
    "    \"\"\"\n",
    "    Shuffle patient IDs and split ~evenly into four groups: G1, G2, G3, G4.\n",
    "    Used for Algorithm 0 validation.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    unique_pids = df['patient_id'].unique()\n",
    "    rng.shuffle(unique_pids)\n",
    "    \n",
    "    n = len(unique_pids)\n",
    "    i1 = int(0.25 * n)\n",
    "    i2 = int(0.50 * n)\n",
    "    i3 = int(0.75 * n)\n",
    "    \n",
    "    G1_pids = unique_pids[:i1]\n",
    "    G2_pids = unique_pids[i1:i2]\n",
    "    G3_pids = unique_pids[i2:i3]\n",
    "    G4_pids = unique_pids[i3:]\n",
    "    \n",
    "    G1 = df[df['patient_id'].isin(G1_pids)].copy()\n",
    "    G2 = df[df['patient_id'].isin(G2_pids)].copy()\n",
    "    G3 = df[df['patient_id'].isin(G3_pids)].copy()\n",
    "    G4 = df[df['patient_id'].isin(G4_pids)].copy()\n",
    "    return G1, G2, G3, G4\n",
    "\n",
    "def compute_auc_score(y_true, y_prob):\n",
    "    \"\"\"Compute AUC safely. If only one class present, return 0.5.\"\"\"\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return 0.5\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def train_and_select_best_model(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Trains multiple models (RandomForest, GB, CatBoost)\n",
    "    over small hyperparam grids, picks best by AUC.\n",
    "    Returns: (best_model, best_auc, best_model_name)\n",
    "    \"\"\"\n",
    "    best_auc = -1.0\n",
    "    best_model = None\n",
    "    best_name  = None\n",
    "    \n",
    "    # 1) RandomForest\n",
    "    for params in ParameterGrid(RF_PARAM_GRID):\n",
    "        rf = RandomForestClassifier(random_state=0, **params)\n",
    "        rf.fit(X_train, y_train)\n",
    "        val_prob = rf.predict_proba(X_val)[:,1]\n",
    "        auc_val  = compute_auc_score(y_val, val_prob)\n",
    "        if auc_val > best_auc:\n",
    "            best_auc = auc_val\n",
    "            best_model = rf\n",
    "            best_name = f\"RandomForest_{params}\"\n",
    "    \n",
    "    # 2) GradientBoosting\n",
    "    for params in ParameterGrid(GB_PARAM_GRID):\n",
    "        gb = GradientBoostingClassifier(random_state=0, **params)\n",
    "        gb.fit(X_train, y_train)\n",
    "        val_prob = gb.predict_proba(X_val)[:,1]\n",
    "        auc_val  = compute_auc_score(y_val, val_prob)\n",
    "        if auc_val > best_auc:\n",
    "            best_auc   = auc_val\n",
    "            best_model = gb\n",
    "            best_name  = f\"GradientBoosting_{params}\"\n",
    "    \n",
    "    # 3) CatBoost\n",
    "    for params in ParameterGrid(CATBOOST_PARAM_GRID):\n",
    "        cb = CatBoostClassifier(verbose=0, random_state=0, **params)\n",
    "        cb.fit(X_train, y_train)\n",
    "        val_prob = cb.predict_proba(X_val)[:,1]\n",
    "        auc_val  = compute_auc_score(y_val, val_prob)\n",
    "        if auc_val > best_auc:\n",
    "            best_auc   = auc_val\n",
    "            best_model = cb\n",
    "            best_name  = f\"CatBoost_{params}\"\n",
    "    \n",
    "    return best_model, best_auc, best_name\n",
    "\n",
    "def to_bucket(prob):\n",
    "    \"\"\"Simple function to map prob into a 5-bucket scale [0..4].\"\"\"\n",
    "    b = int(prob * 5)\n",
    "    return min(b, 4)\n",
    "\n",
    "###############################################################################\n",
    "# 3. CAPACITATED SIMULATION\n",
    "###############################################################################\n",
    "def simulate_capacitated_policy(df, policy_func, capacity_factor=0.5):\n",
    "    \"\"\"\n",
    "    df must contain columns: [patient_id, time, risk_score, label].\n",
    "    `policy_func(df) -> dict {pid: treatment_time}` where each patient is mapped\n",
    "    to the time step they get treated. Then we compute cost as:\n",
    "       - If patient is treated and label=1 => cost = (D_COST * treat_time).\n",
    "       - If patient is treated and label=0 => cost = FP_COST.\n",
    "       - If patient is never treated and label=1 => cost = FN_COST.\n",
    "       - If never treated and label=0 => cost = 0.\n",
    "    We also compute precision, recall, and average treatment time.\n",
    "    \"\"\"\n",
    "    treatment_dict = policy_func(df)\n",
    "    \n",
    "    results = []\n",
    "    for pid, grp in df.groupby('patient_id'):\n",
    "        grp = grp.sort_values('time')\n",
    "        label = grp['label'].iloc[0]\n",
    "        \n",
    "        if pid in treatment_dict:\n",
    "            ttime = treatment_dict[pid]\n",
    "            if label == 1:\n",
    "                cost = D_COST * ttime\n",
    "                tp = 1\n",
    "                fp = 0\n",
    "            else:\n",
    "                cost = FP_COST\n",
    "                tp = 0\n",
    "                fp = 1\n",
    "            treated_flag = 1\n",
    "        else:\n",
    "            # not treated\n",
    "            ttime = None\n",
    "            if label == 1:\n",
    "                cost = FN_COST\n",
    "                tp = 0\n",
    "                fp = 0\n",
    "            else:\n",
    "                cost = 0\n",
    "                tp = 0\n",
    "                fp = 0\n",
    "            treated_flag = 0\n",
    "        \n",
    "        results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': treated_flag,\n",
    "            'treat_time': ttime,\n",
    "            'cost': cost,\n",
    "            'tp': tp,\n",
    "            'fp': fp\n",
    "        })\n",
    "    \n",
    "    df_res = pd.DataFrame(results)\n",
    "    total_cost = df_res['cost'].sum()\n",
    "    \n",
    "    treated_df = df_res[df_res['treated'] == 1]\n",
    "    tp_sum = treated_df['tp'].sum()\n",
    "    fp_sum = treated_df['fp'].sum()\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        precision = tp_sum / (tp_sum + fp_sum)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "    \n",
    "    sick_df = df_res[df_res['label'] == 1]\n",
    "    if len(sick_df) > 0:\n",
    "        recall = tp_sum / len(sick_df)\n",
    "    else:\n",
    "        recall = 0.0\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        valid_tt = treated_df['treat_time'].dropna()\n",
    "        avg_tt = valid_tt.mean() if len(valid_tt) else 0.0\n",
    "    else:\n",
    "        avg_tt = 0.0\n",
    "    \n",
    "    return {\n",
    "        'cost': total_cost,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'avg_treatment_time': avg_tt\n",
    "    }\n",
    "\n",
    "###############################################################################\n",
    "# 4. THRESHOLD-BASED CAPACITATED POLICIES\n",
    "###############################################################################\n",
    "def make_capacitated_constant_threshold_policy(thr, capacity_factor=0.5):\n",
    "    def policy_func(df):\n",
    "        # capacity = 0.5 * # of distinct sick patients\n",
    "        n_sick_patients = df.groupby('patient_id')['label'].max().sum()\n",
    "        max_capacity = int(capacity_factor * n_sick_patients)\n",
    "        \n",
    "        treatment_dict = {}\n",
    "        remaining_capacity = max_capacity\n",
    "        \n",
    "        for t in range(T_MAX):\n",
    "            if remaining_capacity <= 0:\n",
    "                break\n",
    "            \n",
    "            patients_at_t = df[df['time'] == t]\n",
    "            if len(patients_at_t) == 0:\n",
    "                continue\n",
    "            \n",
    "            # eligible = risk_score >= thr\n",
    "            eligible = patients_at_t[patients_at_t['risk_score'] >= thr]\n",
    "            if len(eligible) == 0:\n",
    "                continue\n",
    "            \n",
    "            eligible = eligible.sort_values('risk_score', ascending=False)\n",
    "            # treat up to remaining_capacity\n",
    "            to_treat = min(remaining_capacity, len(eligible))\n",
    "            chosen = eligible.iloc[:to_treat]\n",
    "            for pid in chosen['patient_id']:\n",
    "                treatment_dict[pid] = t\n",
    "            \n",
    "            remaining_capacity -= to_treat\n",
    "        \n",
    "        return treatment_dict\n",
    "    return policy_func\n",
    "\n",
    "def make_capacitated_linear_threshold_policy(A, B, capacity_factor=0.5):\n",
    "    def policy_func(df):\n",
    "        n_sick_patients = df.groupby('patient_id')['label'].max().sum()\n",
    "        max_capacity = int(capacity_factor * n_sick_patients)\n",
    "        \n",
    "        treatment_dict = {}\n",
    "        remaining_capacity = max_capacity\n",
    "        \n",
    "        for t in range(T_MAX):\n",
    "            if remaining_capacity <= 0:\n",
    "                break\n",
    "            patients_at_t = df[df['time'] == t]\n",
    "            if len(patients_at_t) == 0:\n",
    "                continue\n",
    "            \n",
    "            # threshold = clamp(A * t + B between [0,1])\n",
    "            thr = max(0, min(1, A * t + B))\n",
    "            eligible = patients_at_t[patients_at_t['risk_score'] >= thr]\n",
    "            if len(eligible) == 0:\n",
    "                continue\n",
    "            \n",
    "            eligible = eligible.sort_values('risk_score', ascending=False)\n",
    "            to_treat = min(remaining_capacity, len(eligible))\n",
    "            chosen = eligible.iloc[:to_treat]\n",
    "            for pid in chosen['patient_id']:\n",
    "                treatment_dict[pid] = t\n",
    "            \n",
    "            remaining_capacity -= to_treat\n",
    "        \n",
    "        return treatment_dict\n",
    "    return policy_func\n",
    "\n",
    "def make_capacitated_wait_till_end_policy(thr, capacity_factor=0.5):\n",
    "    def policy_func(df):\n",
    "        n_sick_patients = df.groupby('patient_id')['label'].max().sum()\n",
    "        max_capacity = int(capacity_factor * n_sick_patients)\n",
    "        \n",
    "        treatment_dict = {}\n",
    "        # wait until final time\n",
    "        final_t = df['time'].max()\n",
    "        final_patients = df[df['time'] == final_t]\n",
    "        \n",
    "        eligible = final_patients[final_patients['risk_score'] >= thr]\n",
    "        if len(eligible):\n",
    "            eligible = eligible.sort_values('risk_score', ascending=False)\n",
    "            to_treat = min(max_capacity, len(eligible))\n",
    "            chosen = eligible.iloc[:to_treat]\n",
    "            for pid in chosen['patient_id']:\n",
    "                treatment_dict[pid] = final_t\n",
    "        \n",
    "        return treatment_dict\n",
    "    return policy_func\n",
    "\n",
    "###############################################################################\n",
    "# 5. TRAINING AN ADP MODEL WITH EPSILON-GREEDY\n",
    "###############################################################################\n",
    "def train_adp_linear_epsilon_greedy(\n",
    "    df_train, \n",
    "    capacity_factor=0.5, \n",
    "    n_episodes=1000, \n",
    "    learning_rate=0.01, \n",
    "    gamma=0.99, \n",
    "    T=21,\n",
    "    epsilon=0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Q-learning with linear function approximation and epsilon-greedy exploration.\n",
    "    We do not \"free\" capacity each step. Once we treat a patient, capacity is permanently reduced.\n",
    "    We also ensure we never treat the same patient more than once by tracking a set of treated IDs.\n",
    "\n",
    "    :param df_train: DataFrame with columns [patient_id, time, risk_bucket, label, risk_score].\n",
    "                     Must have 0 <= time < T.\n",
    "    :param capacity_factor: fraction of (distinct) sick patients we can treat in total\n",
    "    :param n_episodes: number of episodes\n",
    "    :param learning_rate: step size\n",
    "    :param gamma: discount factor\n",
    "    :param T: number of time steps (21 by default)\n",
    "    :param epsilon: exploration rate\n",
    "    :return: learned weight vector (shape = [8])\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Distinct sick patients => define max_capacity\n",
    "    n_sick_patients = df_train.groupby('patient_id')['label'].max().sum()\n",
    "    max_capacity = int(capacity_factor * n_sick_patients)\n",
    "    print(f\"Training ADP with max capacity = {max_capacity} (distinct sick)\")\n",
    "\n",
    "    # 2) We define Q(s,a) = dot(weights, features), where features = \n",
    "    #    [bucket0_frac, bucket1_frac, ..., bucket4_frac, remain_cap_frac, sick_treated_frac, action_frac]\n",
    "\n",
    "    n_features = 8\n",
    "    weights = np.zeros(n_features)\n",
    "\n",
    "    # Pre-group by time (for efficiency)\n",
    "    patients_by_time = {}\n",
    "    for tstep in range(T):\n",
    "        subset = df_train[df_train['time'] == tstep].copy()\n",
    "        # no need to sort here, but we can\n",
    "        subset.sort_values('risk_score', ascending=False, inplace=True)\n",
    "        patients_by_time[tstep] = subset\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        # Start a new \"episode\" with full capacity\n",
    "        remaining_capacity = max_capacity\n",
    "        treated_pid_set = set()       # patients we have already treated\n",
    "        sick_treated_so_far = 0       # how many sick patients we've treated\n",
    "\n",
    "        for t in range(T):\n",
    "            # If we are out of capacity, we can only choose action=0\n",
    "            if remaining_capacity <= 0:\n",
    "                # we can do a quick terminal update:\n",
    "                # We still have to pay FN_COST for untreated sick patients\n",
    "                if t == T-1:\n",
    "                    # final step anyway\n",
    "                    pass\n",
    "                else:\n",
    "                    # skip to end\n",
    "                    pass\n",
    "                break\n",
    "\n",
    "            # Filter out patients who were already treated\n",
    "            candidates = patients_by_time[t]\n",
    "            candidates = candidates[~candidates['patient_id'].isin(treated_pid_set)]\n",
    "            n_candidates = len(candidates)\n",
    "            if n_candidates == 0:\n",
    "                # no one to treat at this time\n",
    "                continue\n",
    "\n",
    "            # state features\n",
    "            # 1) risk bucket fractions among these candidates\n",
    "            bucket_counts = np.zeros(5)\n",
    "            for b in range(5):\n",
    "                bucket_counts[b] = (candidates['risk_bucket'] == b).mean()\n",
    "            \n",
    "            remain_cap_frac = (remaining_capacity / max_capacity) if max_capacity>0 else 0\n",
    "            sick_treated_frac = (sick_treated_so_far / n_sick_patients) if n_sick_patients>0 else 0\n",
    "\n",
    "            # possible actions = how many patients to treat from [0.. min(remaining_capacity, n_candidates)]\n",
    "            possible_actions = list(range(min(remaining_capacity, n_candidates) + 1))\n",
    "            \n",
    "            # Q-value for each possible action\n",
    "            q_vals = []\n",
    "            for a in possible_actions:\n",
    "                # features\n",
    "                feat = np.concatenate([\n",
    "                    bucket_counts,\n",
    "                    [remain_cap_frac, sick_treated_frac, a / max_capacity if max_capacity>0 else 0]\n",
    "                ])\n",
    "                q_val = np.dot(weights, feat)\n",
    "                q_vals.append(q_val)\n",
    "            \n",
    "            # pick action using epsilon-greedy\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = np.random.choice(possible_actions)\n",
    "            else:\n",
    "                best_a_idx = np.argmax(q_vals)\n",
    "                action = possible_actions[best_a_idx]\n",
    "\n",
    "            # (a) immediate cost => negative reward\n",
    "            if action > 0:\n",
    "                # treat top `action` patients by risk_score\n",
    "                # patients_by_time[t] is sorted descending by risk_score\n",
    "                chosen = candidates.iloc[:action]\n",
    "                fp_cost = (chosen['label'] == 0).sum() * FP_COST\n",
    "                tp_cost = (chosen['label'] == 1).sum() * (D_COST * t)\n",
    "                reward = -(fp_cost + tp_cost)\n",
    "\n",
    "                # update environment\n",
    "                newly_treated_pids = chosen['patient_id'].unique()\n",
    "                treated_pid_set.update(newly_treated_pids)\n",
    "                sick_treated_now = (chosen['label'] == 1).sum()\n",
    "                sick_treated_so_far += sick_treated_now\n",
    "                remaining_capacity -= action\n",
    "            else:\n",
    "                reward = 0.0\n",
    "\n",
    "            # Next state Q\n",
    "            if t < T-1:\n",
    "                # we look at time t+1\n",
    "                # if we have capacity left, we can do a next-state Q\n",
    "                # if capacity is 0, we'd be forced to do action=0 anyway\n",
    "                next_t = t + 1\n",
    "                next_candidates = patients_by_time[next_t]\n",
    "                next_candidates = next_candidates[~next_candidates['patient_id'].isin(treated_pid_set)]\n",
    "                if len(next_candidates) == 0:\n",
    "                    # no next Q\n",
    "                    target = reward\n",
    "                else:\n",
    "                    next_bucket = np.zeros(5)\n",
    "                    for b in range(5):\n",
    "                        next_bucket[b] = (next_candidates['risk_bucket'] == b).mean()\n",
    "                    next_remcap_frac = (remaining_capacity / max_capacity) if max_capacity>0 else 0\n",
    "                    next_sicktreated_frac = (sick_treated_so_far / n_sick_patients) if n_sick_patients>0 else 0\n",
    "\n",
    "                    next_possible_actions = list(range(min(remaining_capacity, len(next_candidates)) + 1))\n",
    "                    if not next_possible_actions:\n",
    "                        # no next Q\n",
    "                        target = reward\n",
    "                    else:\n",
    "                        next_qvals = []\n",
    "                        for a2 in next_possible_actions:\n",
    "                            feat2 = np.concatenate([\n",
    "                                next_bucket,\n",
    "                                [next_remcap_frac, next_sicktreated_frac, a2 / max_capacity if max_capacity>0 else 0]\n",
    "                            ])\n",
    "                            val2 = np.dot(weights, feat2)\n",
    "                            next_qvals.append(val2)\n",
    "                        best_future_q = np.max(next_qvals)\n",
    "                        target = reward + gamma * best_future_q\n",
    "            else:\n",
    "                # final time step => pay FN_COST for all untreated sick\n",
    "                # figure out how many distinct sick patients are not in treated_pid_set\n",
    "                all_sick_pids = (\n",
    "                    df_train.groupby('patient_id')['label'].max()\n",
    "                    .loc[lambda s: s == 1].index\n",
    "                )\n",
    "                untreated_sick_pids = set(all_sick_pids) - set(treated_pid_set)\n",
    "                final_cost = len(untreated_sick_pids) * FN_COST\n",
    "                final_reward = -final_cost\n",
    "                target = reward + final_reward\n",
    "            \n",
    "            # TD update\n",
    "            # recompute the current state-action feature\n",
    "            feat_curr = np.concatenate([\n",
    "                bucket_counts,\n",
    "                [remain_cap_frac, sick_treated_frac, action / max_capacity if max_capacity>0 else 0]\n",
    "            ])\n",
    "            pred = np.dot(weights, feat_curr)\n",
    "            td_error = target - pred\n",
    "            weights += learning_rate * td_error * feat_curr\n",
    "        \n",
    "        # end for t\n",
    "        if episode % 100 == 0:\n",
    "            print(f\"Episode {episode}/{n_episodes}\")\n",
    "    # end for episode\n",
    "\n",
    "    return weights\n",
    "\n",
    "###############################################################################\n",
    "# 6. MAKING AN ADP POLICY (TEST-TIME) FROM LEARNED WEIGHTS\n",
    "###############################################################################\n",
    "def make_adp_policy_linear(weights, capacity_factor=0.5, T=21):\n",
    "    \"\"\"\n",
    "    Create a policy_func(df) that picks actions by argmax Q(s,a), \n",
    "    with NO exploration (epsilon=0).\n",
    "    \"\"\"\n",
    "    def policy_func(df_in):\n",
    "        # capacity from distinct sick\n",
    "        n_sick_patients = df_in.groupby('patient_id')['label'].max().sum()\n",
    "        max_capacity = int(capacity_factor * n_sick_patients)\n",
    "        remaining_capacity = max_capacity\n",
    "        \n",
    "        # we will produce a dictionary: patient_id -> treat_time\n",
    "        treatment_dict = {}\n",
    "        \n",
    "        # track which patients are already treated\n",
    "        treated_pid_set = set()\n",
    "        # how many sick have we treated\n",
    "        sick_treated_so_far = 0\n",
    "        \n",
    "        # group by time so we can get subsets quickly\n",
    "        patients_by_time = {}\n",
    "        for tstep in range(T):\n",
    "            pts = df_in[df_in['time'] == tstep].copy()\n",
    "            pts.sort_values('risk_score', ascending=False, inplace=True)\n",
    "            patients_by_time[tstep] = pts\n",
    "        \n",
    "        for t in range(T):\n",
    "            if remaining_capacity <= 0:\n",
    "                break\n",
    "            \n",
    "            candidates = patients_by_time[t]\n",
    "            # remove those already treated\n",
    "            candidates = candidates[~candidates['patient_id'].isin(treated_pid_set)]\n",
    "            n_candidates = len(candidates)\n",
    "            if n_candidates == 0:\n",
    "                continue\n",
    "            \n",
    "            # bucket fractions\n",
    "            bucket_counts = np.zeros(5)\n",
    "            for b in range(5):\n",
    "                bucket_counts[b] = (candidates['risk_bucket'] == b).mean()\n",
    "            \n",
    "            remain_cap_frac = (remaining_capacity / max_capacity) if max_capacity>0 else 0\n",
    "            sick_treated_frac = (sick_treated_so_far / n_sick_patients) if n_sick_patients>0 else 0\n",
    "\n",
    "            possible_actions = list(range(min(remaining_capacity, n_candidates) + 1))\n",
    "            if not possible_actions:\n",
    "                continue\n",
    "            \n",
    "            q_vals = []\n",
    "            for a in possible_actions:\n",
    "                feat = np.concatenate([\n",
    "                    bucket_counts,\n",
    "                    [remain_cap_frac, sick_treated_frac, a / max_capacity if max_capacity>0 else 0]\n",
    "                ])\n",
    "                q_vals.append(np.dot(weights, feat))\n",
    "            \n",
    "            best_a_idx = np.argmax(q_vals)\n",
    "            action = possible_actions[best_a_idx]\n",
    "            if action > 0:\n",
    "                chosen = candidates.iloc[:action]\n",
    "                # treat them at time t\n",
    "                for pid in chosen['patient_id']:\n",
    "                    treatment_dict[pid] = t\n",
    "                # update environment\n",
    "                sick_now = (chosen['label'] == 1).sum()\n",
    "                sick_treated_so_far += sick_now\n",
    "                remaining_capacity -= action\n",
    "        \n",
    "        return treatment_dict\n",
    "    return policy_func\n",
    "\n",
    "###############################################################################\n",
    "# 7. ALGORITHM 0 FOR CAPACITATED SCENARIO\n",
    "###############################################################################\n",
    "def run_algorithm0_capacitated(df_all, capacity_factor=0.5, seed=0):\n",
    "    \"\"\"\n",
    "    1) Split df_all -> G1, G2, G3, G4\n",
    "    2) ML hyperparam search on (G1->G2)\n",
    "    3) Retrain best ML on G1+G2\n",
    "    4) On G3, tune:\n",
    "         - ADP with (n_episodes, etc.)\n",
    "         - threshold-based (thr, A,B, etc.)\n",
    "    5) Evaluate all tuned policies on G4\n",
    "    \"\"\"\n",
    "    # 1) Split\n",
    "    G1, G2, G3, G4 = split_into_four_groups(df_all, seed=seed)\n",
    "\n",
    "    # 2) ML hyperparam search on (G1->G2)\n",
    "    X_train = G1[['EIT','NIRS','EIS']].values\n",
    "    y_train = G1['label'].values\n",
    "    \n",
    "    X_val = G2[['EIT','NIRS','EIS']].values\n",
    "    y_val = G2['label'].values\n",
    "    \n",
    "    best_model, best_auc, best_name = train_and_select_best_model(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    # 3) Retrain best ML on G1+G2\n",
    "    G12 = pd.concat([G1, G2], ignore_index=True)\n",
    "    X_12 = G12[['EIT','NIRS','EIS']].values\n",
    "    y_12 = G12['label'].values\n",
    "    best_model.fit(X_12, y_12)\n",
    "    \n",
    "    # Add risk_score + risk_bucket to G12, G3, G4\n",
    "    G12 = G12.copy()\n",
    "    G3 = G3.copy()\n",
    "    G4 = G4.copy()\n",
    "    \n",
    "    prob_12 = best_model.predict_proba(G12[['EIT','NIRS','EIS']])[:,1]\n",
    "    prob_3  = best_model.predict_proba(G3[['EIT','NIRS','EIS']])[:,1]\n",
    "    prob_4  = best_model.predict_proba(G4[['EIT','NIRS','EIS']])[:,1]\n",
    "    \n",
    "    G12['risk_score'] = prob_12\n",
    "    G3['risk_score']  = prob_3\n",
    "    G4['risk_score']  = prob_4\n",
    "    \n",
    "    G12['risk_bucket'] = G12['risk_score'].apply(to_bucket)\n",
    "    G3['risk_bucket']  = G3['risk_score'].apply(to_bucket)\n",
    "    G4['risk_bucket']  = G4['risk_score'].apply(to_bucket)\n",
    "    \n",
    "    # (A) TUNE THRESHOLD-BASED ON G3\n",
    "    best_thr_const = None\n",
    "    best_cost_const = float('inf')\n",
    "    for thr in np.linspace(0,1,21):\n",
    "        policy_const = make_capacitated_constant_threshold_policy(thr, capacity_factor)\n",
    "        stats_const = simulate_capacitated_policy(G3, policy_const, capacity_factor)\n",
    "        if stats_const['cost'] < best_cost_const:\n",
    "            best_cost_const = stats_const['cost']\n",
    "            best_thr_const = thr\n",
    "    \n",
    "    best_lin_params = None\n",
    "    best_cost_lin = float('inf')\n",
    "    for A in np.linspace(-0.05, 0.01, 7):\n",
    "        for B in np.linspace(0, 0.8, 7):\n",
    "            policy_lin = make_capacitated_linear_threshold_policy(A, B, capacity_factor)\n",
    "            stats_lin = simulate_capacitated_policy(G3, policy_lin, capacity_factor)\n",
    "            if stats_lin['cost'] < best_cost_lin:\n",
    "                best_cost_lin = stats_lin['cost']\n",
    "                best_lin_params = (A, B)\n",
    "    \n",
    "    best_thr_wte = None\n",
    "    best_cost_wte = float('inf')\n",
    "    for thr in np.linspace(0,1,21):\n",
    "        policy_wte = make_capacitated_wait_till_end_policy(thr, capacity_factor)\n",
    "        stats_wte = simulate_capacitated_policy(G3, policy_wte, capacity_factor)\n",
    "        if stats_wte['cost'] < best_cost_wte:\n",
    "            best_cost_wte = stats_wte['cost']\n",
    "            best_thr_wte = thr\n",
    "    \n",
    "    # (B) TRAIN ADP ON G12\n",
    "    adp_weights = train_adp_linear_epsilon_greedy(\n",
    "        df_train=G12, \n",
    "        capacity_factor=capacity_factor,\n",
    "        n_episodes=1000,\n",
    "        learning_rate=0.01,\n",
    "        gamma=0.99,\n",
    "        T=T_MAX,\n",
    "        epsilon=0.1\n",
    "    )\n",
    "    \n",
    "    # Evaluate on G4\n",
    "    # Threshold-based\n",
    "    policy_const_g4 = make_capacitated_constant_threshold_policy(best_thr_const, capacity_factor)\n",
    "    stats_const_g4  = simulate_capacitated_policy(G4, policy_const_g4, capacity_factor)\n",
    "    \n",
    "    A_best, B_best = best_lin_params\n",
    "    policy_lin_g4 = make_capacitated_linear_threshold_policy(A_best, B_best, capacity_factor)\n",
    "    stats_lin_g4 = simulate_capacitated_policy(G4, policy_lin_g4, capacity_factor)\n",
    "    \n",
    "    policy_wte_g4 = make_capacitated_wait_till_end_policy(best_thr_wte, capacity_factor)\n",
    "    stats_wte_g4 = simulate_capacitated_policy(G4, policy_wte_g4, capacity_factor)\n",
    "    \n",
    "    # ADP\n",
    "    adp_policy_g4 = make_adp_policy_linear(adp_weights, capacity_factor=capacity_factor, T=T_MAX)\n",
    "    stats_adp_g4 = simulate_capacitated_policy(G4, adp_policy_g4, capacity_factor)\n",
    "    \n",
    "    table = pd.DataFrame({\n",
    "        'Method': [\n",
    "            'Capacitated Constant Threshold',\n",
    "            'Capacitated Linear Threshold',\n",
    "            'Capacitated Wait Till End',\n",
    "            'Capacitated ADP'\n",
    "        ],\n",
    "        'Cost': [\n",
    "            stats_const_g4['cost'],\n",
    "            stats_lin_g4['cost'],\n",
    "            stats_wte_g4['cost'],\n",
    "            stats_adp_g4['cost']\n",
    "        ],\n",
    "        'Precision (%)': [\n",
    "            100*stats_const_g4['precision'],\n",
    "            100*stats_lin_g4['precision'],\n",
    "            100*stats_wte_g4['precision'],\n",
    "            100*stats_adp_g4['precision']\n",
    "        ],\n",
    "        'Recall (%)': [\n",
    "            100*stats_const_g4['recall'],\n",
    "            100*stats_lin_g4['recall'],\n",
    "            100*stats_wte_g4['recall'],\n",
    "            100*stats_adp_g4['recall']\n",
    "        ],\n",
    "        'Avg Treat Time': [\n",
    "            stats_const_g4['avg_treatment_time'],\n",
    "            stats_lin_g4['avg_treatment_time'],\n",
    "            stats_wte_g4['avg_treatment_time'],\n",
    "            stats_adp_g4['avg_treatment_time']\n",
    "        ]\n",
    "    })\n",
    "    return table\n",
    "\n",
    "###############################################################################\n",
    "# 8. MAIN\n",
    "###############################################################################\n",
    "def main():\n",
    "    df_all = pd.read_csv(\"synthetic_patients_with_features.csv\")\n",
    "\n",
    "    # filter time if needed\n",
    "    df_all = df_all[df_all['time'] < T_MAX].copy()\n",
    "\n",
    "    # check required columns:\n",
    "    required = {'patient_id','time','EIT','NIRS','EIS','label'}\n",
    "    if not required.issubset(df_all.columns):\n",
    "        raise ValueError(f\"CSV must have columns {required}, found {df_all.columns}.\")\n",
    "    \n",
    "    print(f\"\\n=== ALGORITHM 0 RESULTS (CAPACITATED - {int(CAPACITY_FACTOR*100)}% capacity) ===\")\n",
    "    final_table = run_algorithm0_capacitated(df_all, capacity_factor=CAPACITY_FACTOR, seed=4)\n",
    "    print(final_table.to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da5042d-9d90-4fb4-869c-2c2127fe79bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
