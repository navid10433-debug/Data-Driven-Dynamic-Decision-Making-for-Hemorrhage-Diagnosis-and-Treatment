{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc6ef5a5-15d8-4c22-b513-e756cdbe0085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUN 1/30, seed=1000 ===\n",
      "\n",
      "=== RUN 2/30, seed=1001 ===\n",
      "\n",
      "=== RUN 3/30, seed=1002 ===\n",
      "\n",
      "=== RUN 4/30, seed=1003 ===\n",
      "\n",
      "=== RUN 5/30, seed=1004 ===\n",
      "\n",
      "=== RUN 6/30, seed=1005 ===\n",
      "\n",
      "=== RUN 7/30, seed=1006 ===\n",
      "\n",
      "=== RUN 8/30, seed=1007 ===\n",
      "\n",
      "=== RUN 9/30, seed=1008 ===\n",
      "\n",
      "=== RUN 10/30, seed=1009 ===\n",
      "\n",
      "=== RUN 11/30, seed=1010 ===\n",
      "\n",
      "=== RUN 12/30, seed=1011 ===\n",
      "\n",
      "=== RUN 13/30, seed=1012 ===\n",
      "\n",
      "=== RUN 14/30, seed=1013 ===\n",
      "\n",
      "=== RUN 15/30, seed=1014 ===\n",
      "\n",
      "=== RUN 16/30, seed=1015 ===\n",
      "\n",
      "=== RUN 17/30, seed=1016 ===\n",
      "\n",
      "=== RUN 18/30, seed=1017 ===\n",
      "\n",
      "=== RUN 19/30, seed=1018 ===\n",
      "\n",
      "=== RUN 20/30, seed=1019 ===\n",
      "\n",
      "=== RUN 21/30, seed=1020 ===\n",
      "\n",
      "=== RUN 22/30, seed=1021 ===\n",
      "\n",
      "=== RUN 23/30, seed=1022 ===\n",
      "\n",
      "=== RUN 24/30, seed=1023 ===\n",
      "\n",
      "=== RUN 25/30, seed=1024 ===\n",
      "\n",
      "=== RUN 26/30, seed=1025 ===\n",
      "\n",
      "=== RUN 27/30, seed=1026 ===\n",
      "\n",
      "=== RUN 28/30, seed=1027 ===\n",
      "\n",
      "=== RUN 29/30, seed=1028 ===\n",
      "\n",
      "=== RUN 30/30, seed=1029 ===\n",
      "\n",
      "=== FINAL RESULTS (Mean ± Std Dev over 30 Replications) ===\n",
      "Method                             Precision(%)               Cost          Recall(%)           Avg Time\n",
      "Constant Threshold                65.92 ± 10.27     265.87 ± 42.29      100.00 ± 0.00        6.58 ± 0.76\n",
      "Dynamic Threshold-R                57.33 ± 9.62     333.00 ± 38.06      100.00 ± 0.00        7.54 ± 1.03\n",
      "Linear Threshold                   79.46 ± 8.61     207.77 ± 28.90      100.00 ± 0.00        5.75 ± 0.70\n",
      "Wait Till End                     100.00 ± 0.00     467.00 ± 80.42       99.58 ± 1.28       20.00 ± 0.00\n",
      "Dynamic Threshold-DP (DataDriven)       86.47 ± 9.20     229.77 ± 37.94      100.00 ± 0.00        8.23 ± 1.32\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 1. GLOBAL PARAMETERS & SETTINGS\n",
    "###############################################################################\n",
    "FP_COST = 10    # Penalty for false positive treatment\n",
    "FN_COST = 50    # Penalty for false negative (never treated but was sick)\n",
    "D_COST  = 1     # Penalty per time-step of delay before treating a sick patient\n",
    "GAMMA   = 0.99  # Discount factor\n",
    "T_MAX   = 20    # Time horizon (discrete steps 0..T_MAX-1 for each patient)\n",
    "\n",
    "# Example features\n",
    "FEATURE_COLS = [\"time\", \"EIT\", \"NIRS\", \"EIS\"]\n",
    "\n",
    "###############################################################################\n",
    "# 2. HELPER FUNCTIONS: SPLITTING & FILTERING\n",
    "###############################################################################\n",
    "def split_patients_kfold(df, n_splits=4, seed=0):\n",
    "    \"\"\"\n",
    "    Shuffle unique patient IDs, then split into (n_splits+1) groups:\n",
    "       G1,...,G_{n_splits}, G_{n_splits+1} (the final holdout).\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    unique_pts = df['patient_id'].unique()\n",
    "    rng.shuffle(unique_pts)\n",
    "    \n",
    "    n = len(unique_pts)\n",
    "    splits = {}\n",
    "    \n",
    "    for i in range(n_splits + 1):\n",
    "        start_idx = int(i * n / (n_splits + 1))\n",
    "        end_idx   = int((i + 1) * n / (n_splits + 1))\n",
    "        group_name = f\"G{i+1}\"\n",
    "        splits[group_name] = set(unique_pts[start_idx:end_idx])\n",
    "    \n",
    "    return splits\n",
    "\n",
    "def filter_by_group(df, pid_set):\n",
    "    \"\"\"Return the rows of df whose patient_id is in pid_set.\"\"\"\n",
    "    return df[df['patient_id'].isin(pid_set)].copy()\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 3. ML TRAINING & RISK-SCORE PREDICTIONS\n",
    "###############################################################################\n",
    "def train_and_predict_model(model_type, hyperparams, df_train, df_val, feature_cols=FEATURE_COLS):\n",
    "    \"\"\"\n",
    "    Train a classification model (model_type in {catboost, rf, gb})\n",
    "    with given hyperparams on df_train. Then return predicted probabilities\n",
    "    (risk scores) for df_val (aligned with df_val).\n",
    "    \"\"\"\n",
    "    X_train = df_train[feature_cols]\n",
    "    y_train = df_train['label']\n",
    "    \n",
    "    if model_type == \"catboost\":\n",
    "        model = CatBoostClassifier(**hyperparams, verbose=False)\n",
    "        model.fit(X_train, y_train)\n",
    "    elif model_type == \"rf\":\n",
    "        model = RandomForestClassifier(**hyperparams, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "    elif model_type == \"gb\":\n",
    "        model = GradientBoostingClassifier(**hyperparams, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_type={model_type}\")\n",
    "    \n",
    "    X_val = df_val[feature_cols]\n",
    "    risk_scores = model.predict_proba(X_val)[:, 1]  # Probability that label=1\n",
    "    return risk_scores\n",
    "\n",
    "def generate_risk_scores_via_cv(df_train_splits, i_val, model_list, param_grid_dict, feature_cols=FEATURE_COLS):\n",
    "    \"\"\"\n",
    "    For cross-validation fold i_val, pick the best (model_type, hyperparams) by AUC.\n",
    "    \n",
    "    Returns:\n",
    "      best_val_scores (np.array): risk scores for df_train_splits[i_val]\n",
    "      best_model_type, best_hparams, best_auc\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    df_val = df_train_splits[i_val]\n",
    "    X_val  = df_val[feature_cols]\n",
    "    y_val  = df_val['label'].values\n",
    "    \n",
    "    # Build a single training set = union of all G_j except G_i_val\n",
    "    train_parts = []\n",
    "    for k, v_df in df_train_splits.items():\n",
    "        if k != i_val:\n",
    "            train_parts.append(v_df)\n",
    "    df_train_full = pd.concat(train_parts, ignore_index=True)\n",
    "    \n",
    "    best_model_type = None\n",
    "    best_hparams    = None\n",
    "    best_auc        = -999\n",
    "    best_val_scores = None\n",
    "    \n",
    "    # Evaluate each combination\n",
    "    for m_type in model_list:\n",
    "        for hyperparams in param_grid_dict[m_type]:\n",
    "            scores_val = train_and_predict_model(m_type, hyperparams, df_train_full, df_val, feature_cols=feature_cols)\n",
    "            auc_val = roc_auc_score(y_val, scores_val)\n",
    "            if auc_val > best_auc:\n",
    "                best_auc = auc_val\n",
    "                best_model_type = m_type\n",
    "                best_hparams    = hyperparams\n",
    "                best_val_scores = scores_val\n",
    "    \n",
    "    return best_val_scores, best_model_type, best_hparams, best_auc\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 4. SIMULATE POLICIES\n",
    "###############################################################################\n",
    "def simulate_policy(df, policy_func):\n",
    "    \"\"\"\n",
    "    df has columns: patient_id, time, label, predicted_risk (optionally),\n",
    "    policy_func(patient_rows) -> treat_time (int) or None.\n",
    "\n",
    "    Returns: dict of {cost, precision, recall, avg_treatment_time}.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for pid, rows in df.groupby('patient_id'):\n",
    "        rows = rows.sort_values('time')\n",
    "        label = rows['label'].iloc[0]  # 0 or 1\n",
    "        treat_time = policy_func(rows)\n",
    "        \n",
    "        if treat_time is None:\n",
    "            treated_flag = 0\n",
    "            if label == 1:\n",
    "                cost = FN_COST\n",
    "            else:\n",
    "                cost = 0\n",
    "            tp = 0\n",
    "            fp = 0\n",
    "            tt = None\n",
    "        else:\n",
    "            treated_flag = 1\n",
    "            if label == 1:\n",
    "                cost = D_COST * treat_time\n",
    "                tp   = 1\n",
    "                fp   = 0\n",
    "            else:\n",
    "                cost = FP_COST\n",
    "                tp   = 0\n",
    "                fp   = 1\n",
    "            tt = treat_time\n",
    "        \n",
    "        results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': treated_flag,\n",
    "            'treat_time': tt,\n",
    "            'cost': cost,\n",
    "            'tp': tp,\n",
    "            'fp': fp\n",
    "        })\n",
    "    \n",
    "    df_res   = pd.DataFrame(results)\n",
    "    total_cost = df_res['cost'].sum()\n",
    "    \n",
    "    treated_df = df_res[df_res['treated'] == 1]\n",
    "    tp_sum = treated_df['tp'].sum()\n",
    "    fp_sum = treated_df['fp'].sum()\n",
    "    \n",
    "    precision = tp_sum / (tp_sum + fp_sum) if (tp_sum+fp_sum) > 0 else 0.0\n",
    "    sick_df = df_res[df_res['label'] == 1]\n",
    "    recall = tp_sum / len(sick_df) if len(sick_df) > 0 else 0.0\n",
    "    \n",
    "    if len(treated_df) > 0:\n",
    "        valid_tt = treated_df['treat_time'].dropna()\n",
    "        avg_tt = valid_tt.mean() if len(valid_tt) > 0 else 0.0\n",
    "    else:\n",
    "        avg_tt = 0.0\n",
    "    \n",
    "    return {\n",
    "        'cost': total_cost,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'avg_treatment_time': avg_tt\n",
    "    }\n",
    "\n",
    "###############################################################################\n",
    "# 5. BENCHMARK DECISION POLICIES\n",
    "###############################################################################\n",
    "def constant_threshold_search(df, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0,0.5,10)\n",
    "    best_thr, best_cost = None, float('inf')\n",
    "    best_stats = None\n",
    "    \n",
    "    for thr in thresholds:\n",
    "        def policy_func(rows):\n",
    "            for _, row in rows.iterrows():\n",
    "                if row['predicted_risk'] >= thr:\n",
    "                    return int(row['time'])\n",
    "            return None\n",
    "        \n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_thr  = thr\n",
    "            best_stats= stats\n",
    "    \n",
    "    return best_thr, best_stats\n",
    "\n",
    "def dynamic_threshold_random_search(df,\n",
    "                                    time_steps=T_MAX,\n",
    "                                    threshold_candidates=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "                                    n_samples=200,\n",
    "                                    seed=0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    best_vec = None\n",
    "    best_cost= float('inf')\n",
    "    best_stats= None\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        thr_vec = rng.choice(threshold_candidates, size=time_steps)\n",
    "        \n",
    "        def policy_func(rows):\n",
    "            for _, row in rows.iterrows():\n",
    "                t = int(row['time'])\n",
    "                if t < time_steps and row['predicted_risk'] >= thr_vec[t]:\n",
    "                    return t\n",
    "            return None\n",
    "        \n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_vec  = thr_vec.copy()\n",
    "            best_stats= stats\n",
    "    return best_vec, best_stats\n",
    "\n",
    "def linear_threshold_search(df, A_candidates=None, B_candidates=None):\n",
    "    if A_candidates is None:\n",
    "        A_candidates = np.linspace(-0.05, 0.05, 5)\n",
    "    if B_candidates is None:\n",
    "        B_candidates = np.linspace(0, 0.5, 6)\n",
    "    \n",
    "    best_A, best_B = None, None\n",
    "    best_cost, best_stats = float('inf'), None\n",
    "    \n",
    "    for A in A_candidates:\n",
    "        for B in B_candidates:\n",
    "            def policy_func(rows):\n",
    "                for _, row in rows.iterrows():\n",
    "                    t = row['time']\n",
    "                    thr = np.clip(A*t + B, 0, 1)\n",
    "                    if row['predicted_risk'] >= thr:\n",
    "                        return int(t)\n",
    "                return None\n",
    "            \n",
    "            stats = simulate_policy(df, policy_func)\n",
    "            if stats['cost'] < best_cost:\n",
    "                best_cost = stats['cost']\n",
    "                best_stats= stats\n",
    "                best_A    = A\n",
    "                best_B    = B\n",
    "    \n",
    "    return (best_A,best_B), best_stats\n",
    "\n",
    "def wait_till_end_search(df, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0,1,21)\n",
    "    best_thr, best_cost = None, float('inf')\n",
    "    best_stats = None\n",
    "    \n",
    "    for thr in thresholds:\n",
    "        def policy_func(rows):\n",
    "            final_row = rows.loc[rows['time'].idxmax()]\n",
    "            if final_row['predicted_risk'] >= thr:\n",
    "                return int(final_row['time'])\n",
    "            return None\n",
    "        \n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_thr  = thr\n",
    "            best_stats= stats\n",
    "    \n",
    "    return best_thr, best_stats\n",
    "\n",
    "###############################################################################\n",
    "# 6. DATA-DRIVEN DP\n",
    "###############################################################################\n",
    "def assign_buckets(prob, n_buckets=5):\n",
    "    edges = np.linspace(0,1,n_buckets+1)\n",
    "    for b in range(n_buckets):\n",
    "        if edges[b] <= prob < edges[b+1]:\n",
    "            return b\n",
    "    return n_buckets - 1\n",
    "\n",
    "def estimate_transition_and_sick_probs(df_train, T=T_MAX, n_buckets=5):\n",
    "    transition_counts = np.zeros((T-1, n_buckets, n_buckets), dtype=float)\n",
    "    bucket_counts     = np.zeros((T, n_buckets), dtype=float)\n",
    "    sick_counts       = np.zeros((T, n_buckets), dtype=float)\n",
    "\n",
    "    df_sorted = df_train.sort_values(['patient_id','time'])\n",
    "    for pid, grp in df_sorted.groupby('patient_id'):\n",
    "        grp = grp.sort_values('time')\n",
    "        rows= grp.to_dict('records')\n",
    "        \n",
    "        for i, row in enumerate(rows):\n",
    "            t = int(row['time'])\n",
    "            b = int(row['risk_bucket'])\n",
    "            lbl = row['label']\n",
    "            \n",
    "            if t < T:\n",
    "                bucket_counts[t,b] += 1\n",
    "                sick_counts[t,b]   += lbl\n",
    "            \n",
    "            if i < len(rows)-1:\n",
    "                nxt = rows[i+1]\n",
    "                t_next = int(nxt['time'])\n",
    "                b_next = int(nxt['risk_bucket'])\n",
    "                if (t_next == t+1) and (t < T-1):\n",
    "                    transition_counts[t,b,b_next] += 1\n",
    "\n",
    "    p_trans = np.zeros((T-1, n_buckets, n_buckets), dtype=float)\n",
    "    for t_ in range(T-1):\n",
    "        for b_ in range(n_buckets):\n",
    "            denom = transition_counts[t_, b_, :].sum()\n",
    "            if denom > 0:\n",
    "                p_trans[t_, b_, :] = transition_counts[t_, b_, :] / denom\n",
    "            else:\n",
    "                p_trans[t_, b_, b_] = 1.0  # fallback\n",
    "\n",
    "    p_sick = np.zeros((T, n_buckets), dtype=float)\n",
    "    for t_ in range(T):\n",
    "        for b_ in range(n_buckets):\n",
    "            denom = bucket_counts[t_, b_]\n",
    "            if denom > 0:\n",
    "                p_sick[t_, b_] = sick_counts[t_, b_] / denom\n",
    "            else:\n",
    "                p_sick[t_, b_] = 0.0\n",
    "    \n",
    "    return p_trans, p_sick\n",
    "\n",
    "def train_data_driven_dp(p_trans, p_sick,\n",
    "                         FP=FP_COST, FN=FN_COST, D=D_COST, gamma=GAMMA, T=T_MAX):\n",
    "    n_buckets = p_sick.shape[1]\n",
    "    V = np.zeros((T+1, n_buckets))\n",
    "    pi_ = np.zeros((T, n_buckets), dtype=int)\n",
    "    \n",
    "    for b in range(n_buckets):\n",
    "        cost_treat   = p_sick[T-1,b]*(D*(T-1)) + (1 - p_sick[T-1,b])*FP\n",
    "        cost_notreat = p_sick[T-1,b]*FN\n",
    "        V[T,b] = min(cost_treat, cost_notreat)\n",
    "    \n",
    "    for t in reversed(range(T)):\n",
    "        for b in range(n_buckets):\n",
    "            cost_treat = p_sick[t,b]*(D*t) + (1 - p_sick[t,b])*FP\n",
    "            if t == T-1:\n",
    "                cost_wait = gamma * V[T,b]\n",
    "            else:\n",
    "                exp_future = 0.0\n",
    "                for b_next in range(n_buckets):\n",
    "                    exp_future += p_trans[t,b,b_next] * V[t+1,b_next]\n",
    "                cost_wait = gamma * exp_future\n",
    "            \n",
    "            if cost_treat <= cost_wait:\n",
    "                V[t,b]   = cost_treat\n",
    "                pi_[t,b] = 1\n",
    "            else:\n",
    "                V[t,b]   = cost_wait\n",
    "                pi_[t,b] = 0\n",
    "    return V, pi_\n",
    "\n",
    "def make_data_driven_dp_policy(V, pi_, T=T_MAX):\n",
    "    def policy_func(rows):\n",
    "        for _, row in rows.iterrows():\n",
    "            t = int(row['time'])\n",
    "            if t < T:\n",
    "                b = int(row['risk_bucket'])\n",
    "                if pi_[t,b] == 1:  # treat\n",
    "                    return t\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 7. ALGORITHM 2 (Full CV) IMPLEMENTATION\n",
    "###############################################################################\n",
    "def run_experiment_algorithm2(\n",
    "    df_all,\n",
    "    n_splits=4,\n",
    "    seed=42,\n",
    "    model_list=(\"catboost\",\"rf\",\"gb\"),\n",
    "    param_grid_dict=None):\n",
    "    \"\"\"\n",
    "    Implement Algorithm 2 (Full Cross-Validation) with integrated ML + DP.\n",
    "\n",
    "    Returns:\n",
    "      final_table (pd.DataFrame): results on G_{n_splits+1}\n",
    "      df_val_stats (pd.DataFrame): details per fold in cross-validation\n",
    "    \"\"\"\n",
    "    if param_grid_dict is None:\n",
    "        # Example small grids\n",
    "        param_grid_dict = {\n",
    "            \"catboost\": [\n",
    "                {\"iterations\":50, \"depth\":3, \"learning_rate\":0.1},\n",
    "                {\"iterations\":50, \"depth\":4, \"learning_rate\":0.05},\n",
    "            ],\n",
    "            \"rf\": [\n",
    "                {\"n_estimators\":50, \"max_depth\":3},\n",
    "                {\"n_estimators\":100, \"max_depth\":5},\n",
    "            ],\n",
    "            \"gb\": [\n",
    "                {\"n_estimators\":50, \"max_depth\":3, \"learning_rate\":0.1},\n",
    "                {\"n_estimators\":100,\"max_depth\":3, \"learning_rate\":0.05},\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # 1) Split => G1..G_{n_splits}, G_{n_splits+1}\n",
    "    splits = split_patients_kfold(df_all, n_splits=n_splits, seed=seed)\n",
    "    group_dfs = {}\n",
    "    for group_name, pid_set in splits.items():\n",
    "        sub_df = filter_by_group(df_all, pid_set)\n",
    "        group_dfs[group_name] = sub_df\n",
    "    \n",
    "    test_name = f\"G{n_splits+1}\"\n",
    "    df_test   = group_dfs[test_name]\n",
    "\n",
    "    # 2) Cross-validation on folds {G1..G_n}\n",
    "    all_val_stats = []\n",
    "    for i_val in range(1, n_splits+1):\n",
    "        val_name = f\"G{i_val}\"\n",
    "        df_val = group_dfs[val_name]\n",
    "\n",
    "        # pick best ML\n",
    "        val_scores, best_model_type, best_hparams, best_auc = generate_risk_scores_via_cv(\n",
    "            df_train_splits=group_dfs,\n",
    "            i_val=val_name,\n",
    "            model_list=model_list,\n",
    "            param_grid_dict=param_grid_dict,\n",
    "            feature_cols=FEATURE_COLS\n",
    "        )\n",
    "        df_val = df_val.copy()\n",
    "        df_val[\"predicted_risk\"] = val_scores\n",
    "        group_dfs[val_name] = df_val  # store predictions\n",
    "\n",
    "        # Evaluate benchmark policies on this fold\n",
    "        # (a) Constant\n",
    "        thr_const, stats_const = constant_threshold_search(df_val)\n",
    "        # (b) Dynamic threshold\n",
    "        thr_vec, stats_dyn = dynamic_threshold_random_search(df_val, seed=999+ i_val)\n",
    "        # (c) Linear threshold\n",
    "        (A_lin,B_lin), stats_lin = linear_threshold_search(df_val)\n",
    "        # (d) Wait-till-end\n",
    "        thr_wte, stats_wte = wait_till_end_search(df_val)\n",
    "        # (e) DP\n",
    "        #     1) train final_model on training folds => get risk for that training set => DP => apply to val\n",
    "        train_parts = []\n",
    "        for j in range(1, n_splits+1):\n",
    "            if j != i_val:\n",
    "                train_parts.append(group_dfs[f\"G{j}\"])\n",
    "        df_train_fold = pd.concat(train_parts, ignore_index=True).copy()\n",
    "        \n",
    "        # Retrain \"best model\" on df_train_fold => produce risk => bucket => DP\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        X_train_f = df_train_fold[FEATURE_COLS]\n",
    "        y_train_f = df_train_fold['label']\n",
    "        if best_model_type == \"catboost\":\n",
    "            final_model = CatBoostClassifier(**best_hparams, verbose=False)\n",
    "            final_model.fit(X_train_f, y_train_f)\n",
    "        elif best_model_type == \"rf\":\n",
    "            final_model = RandomForestClassifier(**best_hparams, random_state=42)\n",
    "            final_model.fit(X_train_f, y_train_f)\n",
    "        else:\n",
    "            final_model = GradientBoostingClassifier(**best_hparams, random_state=42)\n",
    "            final_model.fit(X_train_f, y_train_f)\n",
    "        \n",
    "        df_train_fold[\"predicted_risk\"] = final_model.predict_proba(X_train_f)[:,1]\n",
    "        df_train_fold[\"risk_bucket\"]    = df_train_fold[\"predicted_risk\"].apply(assign_buckets)\n",
    "        \n",
    "        p_trans, p_sick = estimate_transition_and_sick_probs(df_train_fold, T=T_MAX, n_buckets=5)\n",
    "        V, pi_ = train_data_driven_dp(p_trans, p_sick, \n",
    "                                      FP=FP_COST, FN=FN_COST, D=D_COST, gamma=GAMMA, T=T_MAX)\n",
    "        df_val_dp = df_val.copy()\n",
    "        df_val_dp[\"risk_bucket\"] = df_val_dp[\"predicted_risk\"].apply(assign_buckets)\n",
    "        dp_policy = make_data_driven_dp_policy(V, pi_, T=T_MAX)\n",
    "        stats_dp = simulate_policy(df_val_dp, dp_policy)\n",
    "        \n",
    "        all_val_stats.append({\n",
    "            \"fold\": i_val,\n",
    "            \"best_model_type\": best_model_type,\n",
    "            \"best_hparams\": best_hparams,\n",
    "            \"AUC_val\": roc_auc_score(df_val['label'], df_val['predicted_risk']),\n",
    "\n",
    "            \"const_cost\": stats_const[\"cost\"],\n",
    "            \"dyn_cost\":   stats_dyn[\"cost\"],\n",
    "            \"lin_cost\":   stats_lin[\"cost\"],\n",
    "            \"wte_cost\":   stats_wte[\"cost\"],\n",
    "            \"dp_cost\":    stats_dp[\"cost\"],\n",
    "        })\n",
    "    \n",
    "    df_val_stats = pd.DataFrame(all_val_stats)\n",
    "\n",
    "    # 3) Pick a single final model from among folds or do a separate logic.\n",
    "    #    For simplicity, pick the fold that had the best dp_cost:\n",
    "    best_fold_idx = df_val_stats[\"dp_cost\"].idxmin()\n",
    "    fold_rec = df_val_stats.loc[best_fold_idx]\n",
    "    final_model_type = fold_rec[\"best_model_type\"]\n",
    "    final_hparams    = fold_rec[\"best_hparams\"]\n",
    "    \n",
    "    # 4) Retrain on G1..G_n => evaluate on G_{n+1}\n",
    "    train_all = []\n",
    "    for i in range(1, n_splits+1):\n",
    "        train_all.append(group_dfs[f\"G{i}\"])\n",
    "    df_train_all = pd.concat(train_all, ignore_index=True).copy()\n",
    "    \n",
    "    X_train_all = df_train_all[FEATURE_COLS]\n",
    "    y_train_all = df_train_all[\"label\"]\n",
    "    \n",
    "    if final_model_type == \"catboost\":\n",
    "        final_model = CatBoostClassifier(**final_hparams, verbose=False)\n",
    "        final_model.fit(X_train_all, y_train_all)\n",
    "    elif final_model_type == \"rf\":\n",
    "        final_model = RandomForestClassifier(**final_hparams, random_state=42)\n",
    "        final_model.fit(X_train_all, y_train_all)\n",
    "    else:\n",
    "        final_model = GradientBoostingClassifier(**final_hparams, random_state=42)\n",
    "        final_model.fit(X_train_all, y_train_all)\n",
    "\n",
    "    df_test = df_test.copy()\n",
    "    df_test[\"predicted_risk\"] = final_model.predict_proba(df_test[FEATURE_COLS])[:,1]\n",
    "    \n",
    "    # Evaluate final table\n",
    "    # (a) Constant\n",
    "    thr_const, stats_const = constant_threshold_search(df_test)\n",
    "    # (b) Dynamic\n",
    "    thr_vec, stats_dyn = dynamic_threshold_random_search(df_test)\n",
    "    # (c) Linear\n",
    "    (A_lin,B_lin), stats_lin = linear_threshold_search(df_test)\n",
    "    # (d) Wait-till-end\n",
    "    thr_wte, stats_wte = wait_till_end_search(df_test)\n",
    "    # (e) DP\n",
    "    df_train_all[\"predicted_risk\"] = final_model.predict_proba(df_train_all[FEATURE_COLS])[:,1]\n",
    "    df_train_all[\"risk_bucket\"]    = df_train_all[\"predicted_risk\"].apply(assign_buckets)\n",
    "    p_trans, p_sick = estimate_transition_and_sick_probs(df_train_all, T=T_MAX, n_buckets=5)\n",
    "    V, pi_ = train_data_driven_dp(p_trans, p_sick, \n",
    "                                  FP=FP_COST, FN=FN_COST, D=D_COST, gamma=GAMMA, T=T_MAX)\n",
    "    df_test_dp = df_test.copy()\n",
    "    df_test_dp[\"risk_bucket\"] = df_test_dp[\"predicted_risk\"].apply(assign_buckets)\n",
    "    dp_policy_func = make_data_driven_dp_policy(V, pi_, T=T_MAX)\n",
    "    stats_dp = simulate_policy(df_test_dp, dp_policy_func)\n",
    "\n",
    "    final_table = pd.DataFrame({\n",
    "        \"Method\": [\n",
    "            \"Constant Threshold\",\n",
    "            \"Dynamic Threshold-R\",\n",
    "            \"Linear Threshold\",\n",
    "            \"Wait Till End\",\n",
    "            \"Dynamic Threshold-DP (DataDriven)\"\n",
    "        ],\n",
    "        \"Precision (%)\": [\n",
    "            100*stats_const['precision'],\n",
    "            100*stats_dyn['precision'],\n",
    "            100*stats_lin['precision'],\n",
    "            100*stats_wte['precision'],\n",
    "            100*stats_dp['precision']\n",
    "        ],\n",
    "        \"Cost\": [\n",
    "            stats_const['cost'],\n",
    "            stats_dyn['cost'],\n",
    "            stats_lin['cost'],\n",
    "            stats_wte['cost'],\n",
    "            stats_dp['cost']\n",
    "        ],\n",
    "        \"Recall (%)\": [\n",
    "            100*stats_const['recall'],\n",
    "            100*stats_dyn['recall'],\n",
    "            100*stats_lin['recall'],\n",
    "            100*stats_wte['recall'],\n",
    "            100*stats_dp['recall']\n",
    "        ],\n",
    "        \"Treatment Time\": [\n",
    "            stats_const['avg_treatment_time'],\n",
    "            stats_dyn['avg_treatment_time'],\n",
    "            stats_lin['avg_treatment_time'],\n",
    "            stats_wte['avg_treatment_time'],\n",
    "            stats_dp['avg_treatment_time']\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    return final_table, df_val_stats\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 8. RUN-ONCE FUNCTION (with a given seed)\n",
    "###############################################################################\n",
    "def run_experiment_once(df_all, seed=42, n_splits=4):\n",
    "    \"\"\"\n",
    "    Runs the full Algorithm 2 cross-validation approach for a single random seed.\n",
    "    Returns the final test table (5 methods) and the cross-validation details.\n",
    "    \"\"\"\n",
    "    final_table, df_cv_details = run_experiment_algorithm2(\n",
    "        df_all=df_all,\n",
    "        n_splits=n_splits,\n",
    "        seed=seed,\n",
    "        model_list=(\"catboost\",\"rf\",\"gb\"),\n",
    "        param_grid_dict=None  # default small grid\n",
    "    )\n",
    "    return final_table, df_cv_details\n",
    "\n",
    "###############################################################################\n",
    "# 9. MAIN: 30 Replications\n",
    "###############################################################################\n",
    "def main():\n",
    "    # 1) Load the data once\n",
    "    df_all = pd.read_csv(\"synthetic_patients_with_features.csv\")\n",
    "\n",
    "    # df_all = df_all[df_all['time'] < T_MAX].copy()\n",
    "\n",
    "    N_REPS = 30\n",
    "    methods = [\n",
    "        \"Constant Threshold\",\n",
    "        \"Dynamic Threshold-R\",\n",
    "        \"Linear Threshold\",\n",
    "        \"Wait Till End\",\n",
    "        \"Dynamic Threshold-DP (DataDriven)\"\n",
    "    ]\n",
    "    \n",
    "    # 2) Data structure to hold results across runs\n",
    "    results_over_runs = {\n",
    "        m: {'precision': [], 'cost': [], 'recall': [], 'time': []}\n",
    "        for m in methods\n",
    "    }\n",
    "    \n",
    "    # 3) Loop over 30 seeds\n",
    "    for rep in range(N_REPS):\n",
    "        seed_value = 1000 + rep  # or any scheme you like\n",
    "        print(f\"\\n=== RUN {rep+1}/{N_REPS}, seed={seed_value} ===\")\n",
    "        \n",
    "        final_table, _ = run_experiment_once(df_all, seed=seed_value, n_splits=4)\n",
    "        \n",
    "        # final_table has columns: Method, Precision (%), Cost, Recall (%), Treatment Time\n",
    "        # We'll accumulate them in results_over_runs\n",
    "        for idx, row in final_table.iterrows():\n",
    "            m = row[\"Method\"]\n",
    "            results_over_runs[m][\"precision\"].append(row[\"Precision (%)\"])\n",
    "            results_over_runs[m][\"cost\"].append(row[\"Cost\"])\n",
    "            results_over_runs[m][\"recall\"].append(row[\"Recall (%)\"])\n",
    "            results_over_runs[m][\"time\"].append(row[\"Treatment Time\"])\n",
    "    \n",
    "    # 4) Compute mean ± std dev across the 30 runs\n",
    "    final_rows = []\n",
    "    for i, m in enumerate(methods):\n",
    "        prec_arr = np.array(results_over_runs[m][\"precision\"])\n",
    "        cost_arr = np.array(results_over_runs[m][\"cost\"])\n",
    "        rec_arr  = np.array(results_over_runs[m][\"recall\"])\n",
    "        time_arr = np.array(results_over_runs[m][\"time\"])\n",
    "        \n",
    "        prec_mean, prec_std = prec_arr.mean(), prec_arr.std()\n",
    "        cost_mean, cost_std = cost_arr.mean(), cost_arr.std()\n",
    "        rec_mean,  rec_std  = rec_arr.mean(),  rec_arr.std()\n",
    "        time_mean, time_std = time_arr.mean(), time_arr.std()\n",
    "        \n",
    "        final_rows.append([\n",
    "            m,\n",
    "            f\"{prec_mean:.2f} ± {prec_std:.2f}\",\n",
    "            f\"{cost_mean:.2f} ± {cost_std:.2f}\",\n",
    "            f\"{rec_mean:.2f} ± {rec_std:.2f}\",\n",
    "            f\"{time_mean:.2f} ± {time_std:.2f}\"\n",
    "        ])\n",
    "    \n",
    "    # 5) Print final summary\n",
    "    print(\"\\n=== FINAL RESULTS (Mean ± Std Dev over 30 Replications) ===\")\n",
    "    print(\"{:<28s} {:>18s} {:>18s} {:>18s} {:>18s}\".format(\n",
    "        \"Method\", \"Precision(%)\", \"Cost\", \"Recall(%)\", \"Avg Time\"))\n",
    "    for row in final_rows:\n",
    "        m, prec_str, cost_str, rec_str, time_str = row\n",
    "        print(f\"{m:<28s} {prec_str:>18s} {cost_str:>18s} {rec_str:>18s} {time_str:>18s}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74fe243e-dcc3-4e7c-9e36-943ab6a6d499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUN 1/30, seed=100 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05}, avg AUC=0.9287\n",
      "\n",
      "=== RUN 2/30, seed=101 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1}, avg AUC=0.9238\n",
      "\n",
      "=== RUN 3/30, seed=102 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1}, avg AUC=0.9270\n",
      "\n",
      "=== RUN 4/30, seed=103 ===\n",
      "[INFO] Best ML: catboost {'iterations': 50, 'depth': 3, 'learning_rate': 0.1}, avg AUC=0.9293\n",
      "\n",
      "=== RUN 5/30, seed=104 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05}, avg AUC=0.9247\n",
      "\n",
      "=== RUN 6/30, seed=105 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05}, avg AUC=0.9276\n",
      "\n",
      "=== RUN 7/30, seed=106 ===\n",
      "[INFO] Best ML: catboost {'iterations': 50, 'depth': 3, 'learning_rate': 0.1}, avg AUC=0.9280\n",
      "\n",
      "=== RUN 8/30, seed=107 ===\n",
      "[INFO] Best ML: catboost {'iterations': 50, 'depth': 3, 'learning_rate': 0.1}, avg AUC=0.9225\n",
      "\n",
      "=== RUN 9/30, seed=108 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1}, avg AUC=0.9243\n",
      "\n",
      "=== RUN 10/30, seed=109 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1}, avg AUC=0.9239\n",
      "\n",
      "=== RUN 11/30, seed=110 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1}, avg AUC=0.9283\n",
      "\n",
      "=== RUN 12/30, seed=111 ===\n",
      "[INFO] Best ML: catboost {'iterations': 50, 'depth': 3, 'learning_rate': 0.1}, avg AUC=0.9248\n",
      "\n",
      "=== RUN 13/30, seed=112 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1}, avg AUC=0.9218\n",
      "\n",
      "=== RUN 14/30, seed=113 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1}, avg AUC=0.9233\n",
      "\n",
      "=== RUN 15/30, seed=114 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1}, avg AUC=0.9244\n",
      "\n",
      "=== RUN 16/30, seed=115 ===\n",
      "[INFO] Best ML: catboost {'iterations': 50, 'depth': 3, 'learning_rate': 0.1}, avg AUC=0.9240\n",
      "\n",
      "=== RUN 17/30, seed=116 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1}, avg AUC=0.9283\n",
      "\n",
      "=== RUN 18/30, seed=117 ===\n",
      "[INFO] Best ML: catboost {'iterations': 50, 'depth': 3, 'learning_rate': 0.1}, avg AUC=0.9248\n",
      "\n",
      "=== RUN 19/30, seed=118 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05}, avg AUC=0.9270\n",
      "\n",
      "=== RUN 20/30, seed=119 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05}, avg AUC=0.9277\n",
      "\n",
      "=== RUN 21/30, seed=120 ===\n",
      "[INFO] Best ML: catboost {'iterations': 50, 'depth': 3, 'learning_rate': 0.1}, avg AUC=0.9231\n",
      "\n",
      "=== RUN 22/30, seed=121 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05}, avg AUC=0.9233\n",
      "\n",
      "=== RUN 23/30, seed=122 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05}, avg AUC=0.9285\n",
      "\n",
      "=== RUN 24/30, seed=123 ===\n",
      "[INFO] Best ML: catboost {'iterations': 50, 'depth': 3, 'learning_rate': 0.1}, avg AUC=0.9252\n",
      "\n",
      "=== RUN 25/30, seed=124 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05}, avg AUC=0.9250\n",
      "\n",
      "=== RUN 26/30, seed=125 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05}, avg AUC=0.9246\n",
      "\n",
      "=== RUN 27/30, seed=126 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1}, avg AUC=0.9319\n",
      "\n",
      "=== RUN 28/30, seed=127 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05}, avg AUC=0.9287\n",
      "\n",
      "=== RUN 29/30, seed=128 ===\n",
      "[INFO] Best ML: gb {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05}, avg AUC=0.9257\n",
      "\n",
      "=== RUN 30/30, seed=129 ===\n",
      "[INFO] Best ML: catboost {'iterations': 50, 'depth': 3, 'learning_rate': 0.1}, avg AUC=0.9278\n",
      "\n",
      "=== FINAL RESULTS (Mean ± Std Dev over 30 Replications, Fixed Alg 2) ===\n",
      "              Method Precision (%)           Cost    Recall (%) Treatment Time\n",
      "  Constant Threshold  96.83 ± 3.50 176.43 ± 31.73 100.00 ± 0.00    6.90 ± 0.79\n",
      " Dynamic Threshold-R  80.75 ± 8.50 227.23 ± 41.46 100.00 ± 0.00    6.99 ± 0.89\n",
      "    Linear Threshold  95.54 ± 4.24 172.37 ± 31.98 100.00 ± 0.00    6.51 ± 0.93\n",
      "       Wait Till End  99.27 ± 1.67 497.67 ± 88.49  99.31 ± 1.61   20.00 ± 0.00\n",
      "Dynamic Threshold-DP  85.25 ± 6.94 252.13 ± 52.38 100.00 ± 0.00    8.53 ± 1.33\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "###############################################################################\n",
    "# GLOBAL PARAMETERS\n",
    "###############################################################################\n",
    "FP_COST = 10\n",
    "FN_COST = 50\n",
    "D_COST  = 1\n",
    "GAMMA   = 0.99\n",
    "T_MAX   = 20\n",
    "FEATURE_COLS = [\"time\", \"EIT\", \"NIRS\", \"EIS\"]  # adapt to your CSV columns\n",
    "\n",
    "###############################################################################\n",
    "# DATA SPLITTING\n",
    "###############################################################################\n",
    "def split_patients_kfold(df, n_splits=4, seed=0):\n",
    "    \"\"\"\n",
    "    Shuffle unique patient IDs, then split into (n_splits+1) groups:\n",
    "       G1,...,G_{n_splits}, G_{n_splits+1}.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    unique_pts = df['patient_id'].unique()\n",
    "    rng.shuffle(unique_pts)\n",
    "\n",
    "    n = len(unique_pts)\n",
    "    splits = {}\n",
    "    for i in range(n_splits + 1):\n",
    "        start_idx = int(i * n / (n_splits + 1))\n",
    "        end_idx   = int((i + 1) * n / (n_splits + 1))\n",
    "        group_name = f\"G{i+1}\"\n",
    "        pid_subset = unique_pts[start_idx:end_idx]\n",
    "        splits[group_name] = set(pid_subset)\n",
    "    return splits\n",
    "\n",
    "def filter_by_group(df, pid_set):\n",
    "    return df[df['patient_id'].isin(pid_set)].copy()\n",
    "\n",
    "###############################################################################\n",
    "# ML TRAINING & PREDICTIONS\n",
    "###############################################################################\n",
    "def train_model(model_type, hyperparams, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train a classification model (catboost, rf, or gb) with given hyperparams.\n",
    "    Returns the trained model object.\n",
    "    \"\"\"\n",
    "    if model_type == \"catboost\":\n",
    "        model = CatBoostClassifier(**hyperparams, verbose=False, random_state=42)\n",
    "    elif model_type == \"rf\":\n",
    "        model = RandomForestClassifier(**hyperparams, random_state=42)\n",
    "    elif model_type == \"gb\":\n",
    "        model = GradientBoostingClassifier(**hyperparams, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_type={model_type}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def predict_risk(model, X):\n",
    "    \"\"\"Return predicted probabilities of label=1.\"\"\"\n",
    "    return model.predict_proba(X)[:,1]\n",
    "\n",
    "###############################################################################\n",
    "# SIMULATE POLICY (COST, PRECISION, RECALL, etc.)\n",
    "###############################################################################\n",
    "def simulate_policy(df, policy_func):\n",
    "    results = []\n",
    "    for pid, rows in df.groupby('patient_id'):\n",
    "        rows = rows.sort_values('time')\n",
    "        label = rows['label'].iloc[0]  # 0 or 1\n",
    "        treat_time = policy_func(rows)\n",
    "        if treat_time is None:\n",
    "            # never treated\n",
    "            if label == 1:\n",
    "                cost = FN_COST\n",
    "            else:\n",
    "                cost = 0\n",
    "            tp = 0\n",
    "            fp = 0\n",
    "            treat_flag = 0\n",
    "            ttime = None\n",
    "        else:\n",
    "            treat_flag = 1\n",
    "            if label == 1:\n",
    "                cost = D_COST * treat_time\n",
    "                tp   = 1\n",
    "                fp   = 0\n",
    "            else:\n",
    "                cost = FP_COST\n",
    "                tp   = 0\n",
    "                fp   = 1\n",
    "            ttime = treat_time\n",
    "        results.append({\n",
    "            'patient_id': pid,\n",
    "            'label': label,\n",
    "            'treated': treat_flag,\n",
    "            'treat_time': ttime,\n",
    "            'cost': cost,\n",
    "            'tp': tp,\n",
    "            'fp': fp\n",
    "        })\n",
    "    df_res = pd.DataFrame(results)\n",
    "    total_cost = df_res['cost'].sum()\n",
    "\n",
    "    treated_df = df_res[df_res['treated']==1]\n",
    "    tp_sum = treated_df['tp'].sum()\n",
    "    fp_sum = treated_df['fp'].sum()\n",
    "    precision = tp_sum / (tp_sum + fp_sum) if (tp_sum+fp_sum)>0 else 0.0\n",
    "\n",
    "    sick_df = df_res[df_res['label']==1]\n",
    "    total_sick = len(sick_df)\n",
    "    recall = tp_sum / total_sick if total_sick>0 else 0.0\n",
    "\n",
    "    if len(treated_df)>0:\n",
    "        valid_tt = treated_df['treat_time'].dropna()\n",
    "        avg_tt   = valid_tt.mean() if len(valid_tt)>0 else 0.0\n",
    "    else:\n",
    "        avg_tt = 0.0\n",
    "\n",
    "    return {\n",
    "        'cost': total_cost,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'avg_treatment_time': avg_tt\n",
    "    }\n",
    "\n",
    "###############################################################################\n",
    "# BENCHMARK THRESHOLD POLICIES\n",
    "###############################################################################\n",
    "def constant_threshold_search(df, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0,1,21)\n",
    "    best_thr, best_cost = None, float('inf')\n",
    "    best_stats = None\n",
    "    for thr in thresholds:\n",
    "        def policy_func(rows):\n",
    "            for _, row in rows.iterrows():\n",
    "                if row['predicted_risk'] >= thr:\n",
    "                    return int(row['time'])\n",
    "            return None\n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_thr  = thr\n",
    "            best_stats= stats\n",
    "    return best_thr, best_stats\n",
    "\n",
    "def dynamic_threshold_random_search(df,\n",
    "                                    time_steps=T_MAX,\n",
    "                                    threshold_candidates=[0.0,0.2,0.4,0.6,0.8,1.0],\n",
    "                                    n_samples=200,\n",
    "                                    seed=0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    best_vec = None\n",
    "    best_cost= float('inf')\n",
    "    best_stats= None\n",
    "    for _ in range(n_samples):\n",
    "        thr_vec = rng.choice(threshold_candidates, size=time_steps)\n",
    "        def policy_func(rows):\n",
    "            for _, row in rows.iterrows():\n",
    "                t = int(row['time'])\n",
    "                if t<time_steps and row['predicted_risk']>=thr_vec[t]:\n",
    "                    return t\n",
    "            return None\n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_vec  = thr_vec.copy()\n",
    "            best_stats= stats\n",
    "    return best_vec, best_stats\n",
    "\n",
    "def linear_threshold_search(df, A_candidates=None, B_candidates=None):\n",
    "    if A_candidates is None:\n",
    "        A_candidates = np.linspace(-0.05, 0.05, 5)\n",
    "    if B_candidates is None:\n",
    "        B_candidates = np.linspace(0, 0.5, 6)\n",
    "    best_A, best_B = None, None\n",
    "    best_cost = float('inf')\n",
    "    best_stats= None\n",
    "    for A in A_candidates:\n",
    "        for B in B_candidates:\n",
    "            def policy_func(rows):\n",
    "                for _, row in rows.iterrows():\n",
    "                    t = row['time']\n",
    "                    thr = np.clip(A*t + B, 0, 1)\n",
    "                    if row['predicted_risk'] >= thr:\n",
    "                        return int(t)\n",
    "                return None\n",
    "            stats = simulate_policy(df, policy_func)\n",
    "            if stats['cost'] < best_cost:\n",
    "                best_cost = stats['cost']\n",
    "                best_A    = A\n",
    "                best_B    = B\n",
    "                best_stats= stats\n",
    "    return (best_A,best_B), best_stats\n",
    "\n",
    "def wait_till_end_search(df, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0,1,21)\n",
    "    best_thr, best_cost = None, float('inf')\n",
    "    best_stats= None\n",
    "    for thr in thresholds:\n",
    "        def policy_func(rows):\n",
    "            final_row = rows.loc[rows['time'].idxmax()]\n",
    "            if final_row['predicted_risk'] >= thr:\n",
    "                return int(final_row['time'])\n",
    "            return None\n",
    "        stats = simulate_policy(df, policy_func)\n",
    "        if stats['cost'] < best_cost:\n",
    "            best_cost = stats['cost']\n",
    "            best_thr  = thr\n",
    "            best_stats= stats\n",
    "    return best_thr, best_stats\n",
    "\n",
    "###############################################################################\n",
    "# DATA-DRIVEN DP\n",
    "###############################################################################\n",
    "def assign_buckets(prob, n_buckets=5):\n",
    "    edges = np.linspace(0,1,n_buckets+1)\n",
    "    for b in range(n_buckets):\n",
    "        if edges[b]<=prob<edges[b+1]:\n",
    "            return b\n",
    "    return n_buckets-1\n",
    "\n",
    "def estimate_transition_and_sick_probs(df_train, T=T_MAX, n_buckets=5):\n",
    "    transition_counts = np.zeros((T-1, n_buckets, n_buckets), dtype=float)\n",
    "    bucket_counts     = np.zeros((T, n_buckets), dtype=float)\n",
    "    sick_counts       = np.zeros((T, n_buckets), dtype=float)\n",
    "\n",
    "    df_sorted = df_train.sort_values(['patient_id','time'])\n",
    "    for pid, grp in df_sorted.groupby('patient_id'):\n",
    "        rows = grp.to_dict('records')\n",
    "        for i, row in enumerate(rows):\n",
    "            t  = int(row['time'])\n",
    "            b  = int(row['risk_bucket'])\n",
    "            lbl= int(row['label'])\n",
    "            if t < T:\n",
    "                bucket_counts[t,b]+=1\n",
    "                sick_counts[t,b]+=lbl\n",
    "            if i < len(rows)-1:\n",
    "                nxt = rows[i+1]\n",
    "                t_next = int(nxt['time'])\n",
    "                b_next = int(nxt['risk_bucket'])\n",
    "                if (t_next==t+1) and (t<T-1):\n",
    "                    transition_counts[t,b,b_next]+=1\n",
    "\n",
    "    p_trans = np.zeros((T-1,n_buckets,n_buckets))\n",
    "    for t_ in range(T-1):\n",
    "        for b_ in range(n_buckets):\n",
    "            denom = transition_counts[t_,b_,:].sum()\n",
    "            if denom>0:\n",
    "                p_trans[t_,b_,:] = transition_counts[t_,b_,:] / denom\n",
    "            else:\n",
    "                p_trans[t_,b_,b_] = 1.0\n",
    "\n",
    "    p_sick = np.zeros((T,n_buckets))\n",
    "    for t_ in range(T):\n",
    "        for b_ in range(n_buckets):\n",
    "            denom = bucket_counts[t_,b_]\n",
    "            if denom>0:\n",
    "                p_sick[t_,b_] = sick_counts[t_,b_] / denom\n",
    "            else:\n",
    "                p_sick[t_,b_] = 0.0\n",
    "    return p_trans, p_sick\n",
    "\n",
    "def train_data_driven_dp(p_trans, p_sick, \n",
    "                         FP=FP_COST, FN=FN_COST, D=D_COST, gamma=GAMMA, T=T_MAX):\n",
    "    n_buckets = p_sick.shape[1]\n",
    "    V = np.zeros((T+1, n_buckets))\n",
    "    pi_ = np.zeros((T, n_buckets), dtype=int)\n",
    "    # terminal at t=T\n",
    "    for b in range(n_buckets):\n",
    "        cost_treat   = p_sick[T-1,b]*(D*(T-1)) + (1-p_sick[T-1,b])*FP\n",
    "        cost_notreat = p_sick[T-1,b]*FN\n",
    "        V[T,b] = min(cost_treat, cost_notreat)\n",
    "    # backward\n",
    "    for t in reversed(range(T)):\n",
    "        for b in range(n_buckets):\n",
    "            cost_treat = p_sick[t,b]*(D*t) + (1-p_sick[t,b])*FP\n",
    "            if t==T-1:\n",
    "                cost_wait = gamma*V[T,b]\n",
    "            else:\n",
    "                exp_future=0.0\n",
    "                for b_next in range(n_buckets):\n",
    "                    exp_future+=p_trans[t,b,b_next]*V[t+1,b_next]\n",
    "                cost_wait = gamma*exp_future\n",
    "            if cost_treat<=cost_wait:\n",
    "                V[t,b]   = cost_treat\n",
    "                pi_[t,b] = 1\n",
    "            else:\n",
    "                V[t,b]   = cost_wait\n",
    "                pi_[t,b] = 0\n",
    "    return V, pi_\n",
    "\n",
    "def make_data_driven_dp_policy(V, pi_, T=T_MAX):\n",
    "    def policy_func(rows):\n",
    "        for _, row in rows.iterrows():\n",
    "            t = int(row['time'])\n",
    "            if t < T:\n",
    "                b = int(row['risk_bucket'])\n",
    "                if pi_[t,b]==1:\n",
    "                    return t\n",
    "        return None\n",
    "    return policy_func\n",
    "\n",
    "###############################################################################\n",
    "# ALGORITHM 2: \"Full Cross-Validation\" (FIXED VERSION)\n",
    "###############################################################################\n",
    "def run_experiment_algorithm2_fixed(df_all, n_splits=4, seed=42):\n",
    "    \"\"\"\n",
    "    Revised Algorithm 2 that ensures:\n",
    "      1) We do a full cross-val to find the best (model_type, hyperparams) by average AUC.\n",
    "      2) Then we retrain that final model on G1..Gn, re-estimate transitions from that\n",
    "         final model's predictions, and only then produce the final DP policy for G_{n+1}.\n",
    "      3) We do not pick 'the best fold's DP' but always do a final pass with the chosen ML.\n",
    "    \"\"\"\n",
    "    # 1) Split data => G1..G_{n_splits}, G_{n_splits+1}\n",
    "    splits = split_patients_kfold(df_all, n_splits=n_splits, seed=seed)\n",
    "    group_dfs = {}\n",
    "    for group_name, pidset in splits.items():\n",
    "        group_dfs[group_name] = filter_by_group(df_all, pidset)\n",
    "\n",
    "    # We have model_list + param_grid for demonstration\n",
    "    model_list = [\"catboost\",\"rf\",\"gb\"]\n",
    "    param_grid_dict = {\n",
    "        \"catboost\":[\n",
    "            {\"iterations\":50, \"depth\":3, \"learning_rate\":0.1},\n",
    "            {\"iterations\":50, \"depth\":4, \"learning_rate\":0.05},\n",
    "        ],\n",
    "        \"rf\":[\n",
    "            {\"n_estimators\":50, \"max_depth\":3},\n",
    "            {\"n_estimators\":100,\"max_depth\":5},\n",
    "        ],\n",
    "        \"gb\":[\n",
    "            {\"n_estimators\":50, \"max_depth\":3, \"learning_rate\":0.1},\n",
    "            {\"n_estimators\":100,\"max_depth\":3, \"learning_rate\":0.05},\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    # The final test set:\n",
    "    test_name = f\"G{n_splits+1}\"\n",
    "    df_test = group_dfs[test_name].copy()\n",
    "\n",
    "    # 2) For each candidate (model_type, hyperparams), do an n-fold CV for AUC\n",
    "    #    We'll store average AUC for each candidate\n",
    "    candidate_list = []\n",
    "    for mt in model_list:\n",
    "        for hp in param_grid_dict[mt]:\n",
    "            candidate_list.append((mt, hp))\n",
    "\n",
    "    results_cv = []\n",
    "    # We'll do standard \"full CV\" for each candidate => get average AUC\n",
    "    for (mtype, mparams) in candidate_list:\n",
    "        auc_vals = []\n",
    "        for i_val in range(1, n_splits+1):\n",
    "            val_name = f\"G{i_val}\"\n",
    "            train_parts = []\n",
    "            for j in range(1, n_splits+1):\n",
    "                if j!=i_val:\n",
    "                    train_parts.append(group_dfs[f\"G{j}\"])\n",
    "            df_train_fold = pd.concat(train_parts, ignore_index=True)\n",
    "            # Train\n",
    "            X_train = df_train_fold[FEATURE_COLS]\n",
    "            y_train = df_train_fold['label']\n",
    "            model = train_model(mtype, mparams, X_train, y_train)\n",
    "\n",
    "            # Predict on val\n",
    "            df_val = group_dfs[val_name]\n",
    "            X_val = df_val[FEATURE_COLS]\n",
    "            val_probs = predict_risk(model, X_val)\n",
    "            if len(np.unique(df_val['label']))<2:\n",
    "                # edge case => AUC = 0.5\n",
    "                auc_ = 0.5\n",
    "            else:\n",
    "                auc_ = roc_auc_score(df_val['label'], val_probs)\n",
    "            auc_vals.append(auc_)\n",
    "        # average across folds\n",
    "        avg_auc = np.mean(auc_vals)\n",
    "        results_cv.append({\n",
    "            \"model_type\": mtype,\n",
    "            \"hyperparams\": mparams,\n",
    "            \"avg_auc\": avg_auc\n",
    "        })\n",
    "\n",
    "    df_results_cv = pd.DataFrame(results_cv)\n",
    "    best_idx = df_results_cv[\"avg_auc\"].idxmax()\n",
    "    best_model_type = df_results_cv.loc[best_idx,\"model_type\"]\n",
    "    best_hparams    = df_results_cv.loc[best_idx,\"hyperparams\"]\n",
    "    best_avg_auc    = df_results_cv.loc[best_idx,\"avg_auc\"]\n",
    "\n",
    "    print(f\"[INFO] Best ML: {best_model_type} {best_hparams}, avg AUC={best_avg_auc:.4f}\")\n",
    "\n",
    "    # 3) Retrain that final ML on G1..G_{n_splits}\n",
    "    train_all = []\n",
    "    for i in range(1, n_splits+1):\n",
    "        train_all.append(group_dfs[f\"G{i}\"])\n",
    "    df_train_all = pd.concat(train_all, ignore_index=True)\n",
    "    X_train_all = df_train_all[FEATURE_COLS]\n",
    "    y_train_all = df_train_all['label']\n",
    "\n",
    "    final_model = train_model(best_model_type, best_hparams, X_train_all, y_train_all)\n",
    "\n",
    "    # 4) Produce final risk predictions on:\n",
    "    #    (A) The training union => to estimate transitions\n",
    "    df_train_all = df_train_all.copy()\n",
    "    train_probs = predict_risk(final_model, df_train_all[FEATURE_COLS])\n",
    "    df_train_all[\"predicted_risk\"] = train_probs\n",
    "    df_train_all[\"risk_bucket\"]    = df_train_all[\"predicted_risk\"].apply(assign_buckets)\n",
    "\n",
    "    p_trans, p_sick = estimate_transition_and_sick_probs(df_train_all, T=T_MAX, n_buckets=5)\n",
    "    V, pi_ = train_data_driven_dp(p_trans, p_sick,\n",
    "                                  FP=FP_COST, FN=FN_COST, D=D_COST, gamma=GAMMA, T=T_MAX)\n",
    "    dp_policy_func = make_data_driven_dp_policy(V, pi_, T=T_MAX)\n",
    "\n",
    "    #    (B) The final holdout => for cost evaluation\n",
    "    df_test = df_test.copy()\n",
    "    test_probs = predict_risk(final_model, df_test[FEATURE_COLS])\n",
    "    df_test[\"predicted_risk\"] = test_probs\n",
    "\n",
    "    # 5) Evaluate benchmark thresholds on df_test\n",
    "    thr_c, stats_c        = constant_threshold_search(df_test)\n",
    "    thr_vec, stats_dyn    = dynamic_threshold_random_search(df_test, seed=999)\n",
    "    (A_lin, B_lin), stats_lin = linear_threshold_search(df_test)\n",
    "    thr_wte, stats_wte    = wait_till_end_search(df_test)\n",
    "\n",
    "    # 6) Evaluate final DP on df_test\n",
    "    df_test[\"risk_bucket\"] = df_test[\"predicted_risk\"].apply(assign_buckets)\n",
    "    stats_dp = simulate_policy(df_test, dp_policy_func)\n",
    "\n",
    "    # Build final results table\n",
    "    final_table = pd.DataFrame({\n",
    "        \"Method\": [\n",
    "            \"Constant Threshold\",\n",
    "            \"Dynamic Threshold-R\",\n",
    "            \"Linear Threshold\",\n",
    "            \"Wait Till End\",\n",
    "            \"Dynamic Threshold-DP\"\n",
    "        ],\n",
    "        \"Precision (%)\": [\n",
    "            100*stats_c['precision'],\n",
    "            100*stats_dyn['precision'],\n",
    "            100*stats_lin['precision'],\n",
    "            100*stats_wte['precision'],\n",
    "            100*stats_dp['precision']\n",
    "        ],\n",
    "        \"Cost\": [\n",
    "            stats_c['cost'],\n",
    "            stats_dyn['cost'],\n",
    "            stats_lin['cost'],\n",
    "            stats_wte['cost'],\n",
    "            stats_dp['cost']\n",
    "        ],\n",
    "        \"Recall (%)\": [\n",
    "            100*stats_c['recall'],\n",
    "            100*stats_dyn['recall'],\n",
    "            100*stats_lin['recall'],\n",
    "            100*stats_wte['recall'],\n",
    "            100*stats_dp['recall']\n",
    "        ],\n",
    "        \"Treatment Time\": [\n",
    "            stats_c['avg_treatment_time'],\n",
    "            stats_dyn['avg_treatment_time'],\n",
    "            stats_lin['avg_treatment_time'],\n",
    "            stats_wte['avg_treatment_time'],\n",
    "            stats_dp['avg_treatment_time']\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    return final_table, df_results_cv\n",
    "\n",
    "###############################################################################\n",
    "# MAIN: MULTIPLE REPLICATIONS\n",
    "###############################################################################\n",
    "def main():\n",
    "    df_all = pd.read_csv(\"synthetic_patients_with_features.csv\")\n",
    "    # If needed, filter to time < T_MAX:\n",
    "    # df_all = df_all[df_all['time'] < T_MAX].copy()\n",
    "\n",
    "    N_REPS = 30\n",
    "    method_list = [\n",
    "        \"Constant Threshold\",\n",
    "        \"Dynamic Threshold-R\",\n",
    "        \"Linear Threshold\",\n",
    "        \"Wait Till End\",\n",
    "        \"Dynamic Threshold-DP\"\n",
    "    ]\n",
    "\n",
    "    # Collect stats for each replication\n",
    "    all_results = {m: {\n",
    "        \"precision\": [], \"cost\": [], \"recall\": [], \"time\": []\n",
    "    } for m in method_list}\n",
    "\n",
    "    for rep in range(N_REPS):\n",
    "        seed_val = 100 + rep\n",
    "        print(f\"\\n=== RUN {rep+1}/{N_REPS}, seed={seed_val} ===\")\n",
    "        final_table, df_cv_details = run_experiment_algorithm2_fixed(\n",
    "            df_all, n_splits=4, seed=seed_val\n",
    "        )\n",
    "        for idx, row in final_table.iterrows():\n",
    "            meth = row[\"Method\"]\n",
    "            all_results[meth][\"precision\"].append(row[\"Precision (%)\"])\n",
    "            all_results[meth][\"cost\"].append(row[\"Cost\"])\n",
    "            all_results[meth][\"recall\"].append(row[\"Recall (%)\"])\n",
    "            all_results[meth][\"time\"].append(row[\"Treatment Time\"])\n",
    "\n",
    "    # Summarize\n",
    "    summary_rows = []\n",
    "    for m in method_list:\n",
    "        prec_arr = np.array(all_results[m][\"precision\"])\n",
    "        cost_arr = np.array(all_results[m][\"cost\"])\n",
    "        rec_arr  = np.array(all_results[m][\"recall\"])\n",
    "        time_arr = np.array(all_results[m][\"time\"])\n",
    "\n",
    "        prec_str = f\"{prec_arr.mean():.2f} ± {prec_arr.std():.2f}\"\n",
    "        cost_str = f\"{cost_arr.mean():.2f} ± {cost_arr.std():.2f}\"\n",
    "        rec_str  = f\"{rec_arr.mean():.2f} ± {rec_arr.std():.2f}\"\n",
    "        time_str = f\"{time_arr.mean():.2f} ± {time_arr.std():.2f}\"\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"Method\": m,\n",
    "            \"Precision (%)\": prec_str,\n",
    "            \"Cost\": cost_str,\n",
    "            \"Recall (%)\": rec_str,\n",
    "            \"Treatment Time\": time_str\n",
    "        })\n",
    "\n",
    "    df_summary = pd.DataFrame(summary_rows)\n",
    "    print(\"\\n=== FINAL RESULTS (Mean ± Std Dev over 30 Replications, Fixed Alg 2) ===\")\n",
    "    print(df_summary.to_string(index=False))\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58b930-ac84-4bac-aeee-028acf2fe3a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
